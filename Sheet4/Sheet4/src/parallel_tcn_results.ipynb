{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "parallel_tcn_results.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il6JtP4xsJqz",
        "outputId": "500e1d97-2862-4e2d-b22a-41cb6abbf9e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "Il6JtP4xsJqz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG6MbAY6sKYD",
        "outputId": "8453399d-dbfd-48c2-de32-5a62faeb5bd5"
      },
      "source": [
        "!unzip \"/content/gdrive/MyDrive/data(1).zip\"\n"
      ],
      "id": "hG6MbAY6sKYD",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/MyDrive/data(1).zip\n",
            "   creating: data/\n",
            "   creating: data/features/\n",
            "  inflating: data/features/P03_cam01_P03_cereals.npy  \n",
            "  inflating: data/features/P03_cam01_P03_coffee.npy  \n",
            "  inflating: data/features/P03_cam01_P03_sandwich.npy  \n",
            "  inflating: data/features/P03_cam01_P03_tea.npy  \n",
            "  inflating: data/features/P03_stereo01_P03_cereals.npy  \n",
            "  inflating: data/features/P03_stereo01_P03_coffee.npy  \n",
            "  inflating: data/features/P03_stereo01_P03_sandwich.npy  \n",
            "  inflating: data/features/P03_stereo01_P03_tea.npy  \n",
            "  inflating: data/features/P03_webcam01_P03_cereals.npy  \n",
            "  inflating: data/features/P03_webcam01_P03_coffee.npy  \n",
            "  inflating: data/features/P03_webcam01_P03_sandwich.npy  \n",
            "  inflating: data/features/P03_webcam01_P03_tea.npy  \n",
            "  inflating: data/features/P03_webcam02_P03_cereals.npy  \n",
            "  inflating: data/features/P03_webcam02_P03_coffee.npy  \n",
            "  inflating: data/features/P03_webcam02_P03_sandwich.npy  \n",
            "  inflating: data/features/P03_webcam02_P03_tea.npy  \n",
            "  inflating: data/features/P04_cam01_P04_cereals.npy  \n",
            "  inflating: data/features/P04_cam01_P04_pancake.npy  \n",
            "  inflating: data/features/P04_cam01_P04_sandwich.npy  \n",
            "  inflating: data/features/P04_cam01_P04_tea.npy  \n",
            "  inflating: data/features/P04_stereo01_P04_cereals.npy  \n",
            "  inflating: data/features/P04_stereo01_P04_pancake.npy  \n",
            "  inflating: data/features/P04_stereo01_P04_sandwich.npy  \n",
            "  inflating: data/features/P04_stereo01_P04_tea.npy  \n",
            "  inflating: data/features/P04_webcam01_P04_cereals.npy  \n",
            "  inflating: data/features/P04_webcam01_P04_pancake.npy  \n",
            "  inflating: data/features/P04_webcam01_P04_sandwich.npy  \n",
            "  inflating: data/features/P04_webcam01_P04_tea.npy  \n",
            "  inflating: data/features/P04_webcam02_P04_cereals.npy  \n",
            "  inflating: data/features/P04_webcam02_P04_pancake.npy  \n",
            "  inflating: data/features/P04_webcam02_P04_sandwich.npy  \n",
            "  inflating: data/features/P04_webcam02_P04_tea.npy  \n",
            "  inflating: data/features/P05_cam01_P05_cereals.npy  \n",
            "  inflating: data/features/P05_cam01_P05_coffee.npy  \n",
            "  inflating: data/features/P05_cam01_P05_pancake.npy  \n",
            "  inflating: data/features/P05_cam01_P05_sandwich.npy  \n",
            "  inflating: data/features/P05_cam01_P05_tea.npy  \n",
            "  inflating: data/features/P06_cam01_P06_cereals.npy  \n",
            "  inflating: data/features/P06_cam01_P06_coffee.npy  \n",
            "  inflating: data/features/P06_cam01_P06_pancake.npy  \n",
            "  inflating: data/features/P06_cam01_P06_sandwich.npy  \n",
            "  inflating: data/features/P06_cam01_P06_tea.npy  \n",
            "  inflating: data/features/P07_stereo01_P07_sandwich.npy  \n",
            "  inflating: data/features/P07_stereo01_P07_tea.npy  \n",
            "  inflating: data/features/P07_webcam01_P07_cereals.npy  \n",
            "  inflating: data/features/P07_webcam01_P07_pancake.npy  \n",
            "  inflating: data/features/P07_webcam01_P07_sandwich.npy  \n",
            "  inflating: data/features/P07_webcam01_P07_tea.npy  \n",
            "  inflating: data/features/P08_cam01_P08_tea.npy  \n",
            "  inflating: data/features/P08_webcam01_P08_cereals.npy  \n",
            "  inflating: data/features/P08_webcam01_P08_coffee.npy  \n",
            "  inflating: data/features/P08_webcam01_P08_pancake.npy  \n",
            "  inflating: data/features/P08_webcam01_P08_sandwich.npy  \n",
            "  inflating: data/features/P08_webcam01_P08_tea.npy  \n",
            "  inflating: data/features/P09_cam01_P09_coffee.npy  \n",
            "  inflating: data/features/P09_cam01_P09_tea.npy  \n",
            "  inflating: data/features/P09_webcam01_P09_cereals.npy  \n",
            "  inflating: data/features/P09_webcam01_P09_coffee.npy  \n",
            "  inflating: data/features/P09_webcam01_P09_pancake.npy  \n",
            "  inflating: data/features/P09_webcam01_P09_sandwich.npy  \n",
            "  inflating: data/features/P09_webcam01_P09_tea.npy  \n",
            "  inflating: data/features/P10_cam01_P10_sandwich.npy  \n",
            "  inflating: data/features/P10_webcam01_P10_cereals.npy  \n",
            "  inflating: data/features/P10_webcam01_P10_coffee.npy  \n",
            "  inflating: data/features/P10_webcam01_P10_pancake.npy  \n",
            "  inflating: data/features/P10_webcam01_P10_tea.npy  \n",
            "  inflating: data/features/P11_cam01_P11_cereals.npy  \n",
            "  inflating: data/features/P11_cam01_P11_coffee.npy  \n",
            "  inflating: data/features/P11_cam01_P11_pancake.npy  \n",
            "  inflating: data/features/P11_cam01_P11_sandwich.npy  \n",
            "  inflating: data/features/P11_cam01_P11_tea.npy  \n",
            "  inflating: data/features/P11_webcam01_P11_cereals.npy  \n",
            "  inflating: data/features/P11_webcam01_P11_coffee.npy  \n",
            "  inflating: data/features/P11_webcam01_P11_pancake.npy  \n",
            "  inflating: data/features/P11_webcam01_P11_sandwich.npy  \n",
            "  inflating: data/features/P11_webcam01_P11_tea.npy  \n",
            "  inflating: data/features/P12_cam01_P12_cereals.npy  \n",
            "  inflating: data/features/P12_cam01_P12_coffee.npy  \n",
            "  inflating: data/features/P12_cam01_P12_pancake.npy  \n",
            "  inflating: data/features/P12_cam01_P12_sandwich.npy  \n",
            "  inflating: data/features/P12_cam01_P12_tea.npy  \n",
            "  inflating: data/features/P12_webcam01_P12_cereals.npy  \n",
            "  inflating: data/features/P12_webcam01_P12_coffee.npy  \n",
            "  inflating: data/features/P12_webcam01_P12_pancake.npy  \n",
            "  inflating: data/features/P12_webcam01_P12_sandwich.npy  \n",
            "  inflating: data/features/P12_webcam01_P12_tea.npy  \n",
            "  inflating: data/features/P13_cam01_P13_cereals.npy  \n",
            "  inflating: data/features/P13_cam01_P13_coffee.npy  \n",
            "  inflating: data/features/P13_cam01_P13_pancake.npy  \n",
            "  inflating: data/features/P13_cam01_P13_sandwich.npy  \n",
            "  inflating: data/features/P13_cam01_P13_tea.npy  \n",
            "  inflating: data/features/P13_stereo01_P13_cereals.npy  \n",
            "  inflating: data/features/P13_stereo01_P13_pancake.npy  \n",
            "  inflating: data/features/P13_stereo01_P13_tea.npy  \n",
            "  inflating: data/features/P13_webcam01_P13_cereals.npy  \n",
            "  inflating: data/features/P13_webcam01_P13_coffee.npy  \n",
            "  inflating: data/features/P13_webcam01_P13_pancake.npy  \n",
            "  inflating: data/features/P13_webcam01_P13_sandwich.npy  \n",
            "  inflating: data/features/P13_webcam01_P13_tea.npy  \n",
            "  inflating: data/features/P14_cam01_P14_cereals.npy  \n",
            "  inflating: data/features/P14_cam01_P14_coffee.npy  \n",
            "  inflating: data/features/P14_cam01_P14_pancake.npy  \n",
            "  inflating: data/features/P14_cam01_P14_sandwich.npy  \n",
            "  inflating: data/features/P14_cam01_P14_tea.npy  \n",
            "  inflating: data/features/P14_stereo01_P14_cereals.npy  \n",
            "  inflating: data/features/P14_stereo01_P14_coffee.npy  \n",
            "  inflating: data/features/P14_stereo01_P14_sandwich.npy  \n",
            "  inflating: data/features/P14_stereo01_P14_tea.npy  \n",
            "  inflating: data/features/P14_webcam01_P14_cereals.npy  \n",
            "  inflating: data/features/P14_webcam01_P14_coffee.npy  \n",
            "  inflating: data/features/P14_webcam01_P14_pancake.npy  \n",
            "  inflating: data/features/P14_webcam01_P14_sandwich.npy  \n",
            "  inflating: data/features/P14_webcam01_P14_tea.npy  \n",
            "  inflating: data/features/P15_cam01_P15_cereals.npy  \n",
            "  inflating: data/features/P15_cam01_P15_coffee.npy  \n",
            "  inflating: data/features/P15_cam01_P15_pancake.npy  \n",
            "  inflating: data/features/P15_cam01_P15_sandwich.npy  \n",
            "  inflating: data/features/P15_cam01_P15_tea.npy  \n",
            "  inflating: data/features/P15_stereo01_P15_cereals.npy  \n",
            "  inflating: data/features/P15_stereo01_P15_coffee.npy  \n",
            "  inflating: data/features/P15_stereo01_P15_pancake.npy  \n",
            "  inflating: data/features/P15_stereo01_P15_sandwich.npy  \n",
            "  inflating: data/features/P15_stereo01_P15_tea.npy  \n",
            "  inflating: data/features/P15_webcam01_P15_cereals.npy  \n",
            "  inflating: data/features/P15_webcam01_P15_coffee.npy  \n",
            "  inflating: data/features/P15_webcam01_P15_pancake.npy  \n",
            "  inflating: data/features/P15_webcam01_P15_sandwich.npy  \n",
            "  inflating: data/features/P15_webcam01_P15_tea.npy  \n",
            "  inflating: data/features/P16_cam01_P16_cereals.npy  \n",
            "  inflating: data/features/P16_cam01_P16_pancake.npy  \n",
            "  inflating: data/features/P16_cam01_P16_sandwich.npy  \n",
            "  inflating: data/features/P16_cam01_P16_tea.npy  \n",
            "  inflating: data/features/P16_stereo01_P16_cereals.npy  \n",
            "  inflating: data/features/P16_stereo01_P16_coffee.npy  \n",
            "  inflating: data/features/P16_stereo01_P16_pancake.npy  \n",
            "  inflating: data/features/P16_stereo01_P16_sandwich.npy  \n",
            "  inflating: data/features/P16_stereo01_P16_tea.npy  \n",
            "  inflating: data/features/P16_webcam01_P16_cereals.npy  \n",
            "  inflating: data/features/P16_webcam01_P16_pancake.npy  \n",
            "  inflating: data/features/P16_webcam01_P16_sandwich.npy  \n",
            "  inflating: data/features/P16_webcam01_P16_tea.npy  \n",
            "  inflating: data/features/P16_webcam02_P16_cereals.npy  \n",
            "  inflating: data/features/P16_webcam02_P16_coffee.npy  \n",
            "  inflating: data/features/P16_webcam02_P16_pancake.npy  \n",
            "  inflating: data/features/P16_webcam02_P16_sandwich.npy  \n",
            "  inflating: data/features/P16_webcam02_P16_tea.npy  \n",
            "  inflating: data/features/P17_cam01_P17_cereals.npy  \n",
            "  inflating: data/features/P17_cam01_P17_coffee.npy  \n",
            "  inflating: data/features/P17_cam01_P17_pancake.npy  \n",
            "  inflating: data/features/P17_cam01_P17_sandwich.npy  \n",
            "  inflating: data/features/P17_cam01_P17_tea.npy  \n",
            "  inflating: data/features/P17_stereo01_P17_cereals.npy  \n",
            "  inflating: data/features/P17_stereo01_P17_coffee.npy  \n",
            "  inflating: data/features/P17_stereo01_P17_pancake.npy  \n",
            "  inflating: data/features/P17_stereo01_P17_tea.npy  \n",
            "  inflating: data/features/P17_webcam01_P17_cereals.npy  \n",
            "  inflating: data/features/P17_webcam01_P17_coffee.npy  \n",
            "  inflating: data/features/P17_webcam01_P17_tea.npy  \n",
            "  inflating: data/features/P17_webcam02_P17_cereals.npy  \n",
            "  inflating: data/features/P17_webcam02_P17_coffee.npy  \n",
            "  inflating: data/features/P17_webcam02_P17_pancake.npy  \n",
            "  inflating: data/features/P17_webcam02_P17_tea.npy  \n",
            "  inflating: data/features/P18_cam01_P18_cereals.npy  \n",
            "  inflating: data/features/P18_cam01_P18_coffee.npy  \n",
            "  inflating: data/features/P18_cam01_P18_pancake.npy  \n",
            "  inflating: data/features/P18_cam01_P18_sandwich.npy  \n",
            "  inflating: data/features/P18_cam01_P18_tea.npy  \n",
            "  inflating: data/features/P18_stereo01_P18_cereals.npy  \n",
            "  inflating: data/features/P18_stereo01_P18_coffee.npy  \n",
            "  inflating: data/features/P18_stereo01_P18_tea.npy  \n",
            "  inflating: data/features/P18_webcam01_P18_cereals.npy  \n",
            "  inflating: data/features/P18_webcam01_P18_coffee.npy  \n",
            "  inflating: data/features/P18_webcam01_P18_pancake.npy  \n",
            "  inflating: data/features/P18_webcam01_P18_sandwich.npy  \n",
            "  inflating: data/features/P18_webcam01_P18_tea.npy  \n",
            "  inflating: data/features/P18_webcam02_P18_cereals.npy  \n",
            "  inflating: data/features/P18_webcam02_P18_coffee.npy  \n",
            "  inflating: data/features/P18_webcam02_P18_pancake.npy  \n",
            "  inflating: data/features/P18_webcam02_P18_sandwich.npy  \n",
            "  inflating: data/features/P18_webcam02_P18_tea.npy  \n",
            "  inflating: data/features/P19_cam01_P19_cereals.npy  \n",
            "  inflating: data/features/P19_cam01_P19_coffee.npy  \n",
            "  inflating: data/features/P19_cam01_P19_pancake.npy  \n",
            "  inflating: data/features/P19_cam01_P19_sandwich.npy  \n",
            "  inflating: data/features/P19_cam01_P19_tea.npy  \n",
            "  inflating: data/features/P19_stereo01_P19_cereals.npy  \n",
            "  inflating: data/features/P19_stereo01_P19_sandwich.npy  \n",
            "  inflating: data/features/P19_stereo01_P19_tea.npy  \n",
            "  inflating: data/features/P19_webcam01_P19_cereals.npy  \n",
            "  inflating: data/features/P19_webcam01_P19_coffee.npy  \n",
            "  inflating: data/features/P19_webcam01_P19_pancake.npy  \n",
            "  inflating: data/features/P19_webcam01_P19_sandwich.npy  \n",
            "  inflating: data/features/P19_webcam01_P19_tea.npy  \n",
            "  inflating: data/features/P19_webcam02_P19_cereals.npy  \n",
            "  inflating: data/features/P19_webcam02_P19_pancake.npy  \n",
            "  inflating: data/features/P19_webcam02_P19_sandwich.npy  \n",
            "  inflating: data/features/P19_webcam02_P19_tea.npy  \n",
            "  inflating: data/features/P20_cam01_P20_cereals.npy  \n",
            "  inflating: data/features/P20_cam01_P20_coffee.npy  \n",
            "  inflating: data/features/P20_cam01_P20_sandwich.npy  \n",
            "  inflating: data/features/P20_cam01_P20_tea.npy  \n",
            "  inflating: data/features/P20_cam02_P20_cereals.npy  \n",
            "  inflating: data/features/P20_cam02_P20_coffee.npy  \n",
            "  inflating: data/features/P20_cam02_P20_tea.npy  \n",
            "  inflating: data/features/P20_stereo01_P20_cereals.npy  \n",
            "  inflating: data/features/P20_stereo01_P20_coffee.npy  \n",
            "  inflating: data/features/P20_stereo01_P20_pancake.npy  \n",
            "  inflating: data/features/P20_stereo01_P20_tea.npy  \n",
            "  inflating: data/features/P20_webcam01_P20_cereals.npy  \n",
            "  inflating: data/features/P20_webcam01_P20_coffee.npy  \n",
            "  inflating: data/features/P20_webcam01_P20_pancake.npy  \n",
            "  inflating: data/features/P20_webcam01_P20_sandwich.npy  \n",
            "  inflating: data/features/P20_webcam01_P20_tea.npy  \n",
            "  inflating: data/features/P20_webcam02_P20_coffee.npy  \n",
            "  inflating: data/features/P20_webcam02_P20_pancake.npy  \n",
            "  inflating: data/features/P20_webcam02_P20_sandwich.npy  \n",
            "  inflating: data/features/P20_webcam02_P20_tea.npy  \n",
            "  inflating: data/features/P21_cam01_P21_cereals.npy  \n",
            "  inflating: data/features/P21_cam01_P21_coffee.npy  \n",
            "  inflating: data/features/P21_cam01_P21_pancake.npy  \n",
            "  inflating: data/features/P21_cam01_P21_sandwich.npy  \n",
            "  inflating: data/features/P21_cam01_P21_tea.npy  \n",
            "  inflating: data/features/P21_cam02_P21_cereals.npy  \n",
            "  inflating: data/features/P21_cam02_P21_coffee.npy  \n",
            "  inflating: data/features/P21_cam02_P21_tea.npy  \n",
            "  inflating: data/features/P21_stereo01_P21_coffee.npy  \n",
            "  inflating: data/features/P21_stereo01_P21_sandwich.npy  \n",
            "  inflating: data/features/P21_stereo01_P21_tea.npy  \n",
            "  inflating: data/features/P21_webcam01_P21_cereals.npy  \n",
            "  inflating: data/features/P21_webcam01_P21_coffee.npy  \n",
            "  inflating: data/features/P21_webcam01_P21_pancake.npy  \n",
            "  inflating: data/features/P21_webcam01_P21_sandwich.npy  \n",
            "  inflating: data/features/P21_webcam01_P21_tea.npy  \n",
            "  inflating: data/features/P21_webcam02_P21_cereals.npy  \n",
            "  inflating: data/features/P21_webcam02_P21_coffee.npy  \n",
            "  inflating: data/features/P21_webcam02_P21_pancake.npy  \n",
            "  inflating: data/features/P21_webcam02_P21_sandwich.npy  \n",
            "  inflating: data/features/P21_webcam02_P21_tea.npy  \n",
            "  inflating: data/features/P22_cam01_P22_cereals.npy  \n",
            "  inflating: data/features/P22_cam01_P22_coffee.npy  \n",
            "  inflating: data/features/P22_cam01_P22_pancake.npy  \n",
            "  inflating: data/features/P22_cam01_P22_sandwich.npy  \n",
            "  inflating: data/features/P22_cam01_P22_tea.npy  \n",
            "  inflating: data/features/P22_cam02_P22_cereals.npy  \n",
            "  inflating: data/features/P22_cam02_P22_coffee.npy  \n",
            "  inflating: data/features/P22_cam02_P22_tea.npy  \n",
            "  inflating: data/features/P22_stereo01_P22_cereals.npy  \n",
            "  inflating: data/features/P22_stereo01_P22_coffee.npy  \n",
            "  inflating: data/features/P22_stereo01_P22_tea.npy  \n",
            "  inflating: data/features/P22_webcam01_P22_cereals.npy  \n",
            "  inflating: data/features/P22_webcam01_P22_coffee.npy  \n",
            "  inflating: data/features/P22_webcam01_P22_pancake.npy  \n",
            "  inflating: data/features/P22_webcam01_P22_sandwich.npy  \n",
            "  inflating: data/features/P22_webcam01_P22_tea.npy  \n",
            "  inflating: data/features/P22_webcam02_P22_cereals.npy  \n",
            "  inflating: data/features/P22_webcam02_P22_coffee.npy  \n",
            "  inflating: data/features/P22_webcam02_P22_pancake.npy  \n",
            "  inflating: data/features/P22_webcam02_P22_sandwich.npy  \n",
            "  inflating: data/features/P22_webcam02_P22_tea.npy  \n",
            "  inflating: data/features/P23_cam01_P23_cereals.npy  \n",
            "  inflating: data/features/P23_cam01_P23_coffee.npy  \n",
            "  inflating: data/features/P23_cam01_P23_pancake.npy  \n",
            "  inflating: data/features/P23_cam01_P23_sandwich.npy  \n",
            "  inflating: data/features/P23_cam01_P23_tea.npy  \n",
            "  inflating: data/features/P23_cam02_P23_cereals.npy  \n",
            "  inflating: data/features/P23_cam02_P23_coffee.npy  \n",
            "  inflating: data/features/P23_cam02_P23_pancake.npy  \n",
            "  inflating: data/features/P23_cam02_P23_sandwich.npy  \n",
            "  inflating: data/features/P23_cam02_P23_tea.npy  \n",
            "  inflating: data/features/P23_stereo01_P23_cereals.npy  \n",
            "  inflating: data/features/P23_stereo01_P23_coffee.npy  \n",
            "  inflating: data/features/P23_stereo01_P23_sandwich.npy  \n",
            "  inflating: data/features/P23_stereo01_P23_tea.npy  \n",
            "  inflating: data/features/P23_webcam01_P23_cereals.npy  \n",
            "  inflating: data/features/P23_webcam01_P23_coffee.npy  \n",
            "  inflating: data/features/P23_webcam01_P23_pancake.npy  \n",
            "  inflating: data/features/P23_webcam01_P23_sandwich.npy  \n",
            "  inflating: data/features/P23_webcam01_P23_tea.npy  \n",
            "  inflating: data/features/P23_webcam02_P23_cereals.npy  \n",
            "  inflating: data/features/P23_webcam02_P23_coffee.npy  \n",
            "  inflating: data/features/P23_webcam02_P23_pancake.npy  \n",
            "  inflating: data/features/P23_webcam02_P23_sandwich.npy  \n",
            "  inflating: data/features/P23_webcam02_P23_tea.npy  \n",
            "  inflating: data/features/P24_cam01_P24_cereals.npy  \n",
            "  inflating: data/features/P24_cam01_P24_coffee.npy  \n",
            "  inflating: data/features/P24_cam01_P24_pancake.npy  \n",
            "  inflating: data/features/P24_cam01_P24_sandwich.npy  \n",
            "  inflating: data/features/P24_cam01_P24_tea.npy  \n",
            "  inflating: data/features/P24_cam02_P24_cereals.npy  \n",
            "  inflating: data/features/P24_cam02_P24_coffee.npy  \n",
            "  inflating: data/features/P24_cam02_P24_pancake.npy  \n",
            "  inflating: data/features/P24_cam02_P24_sandwich.npy  \n",
            "  inflating: data/features/P24_stereo01_P24_coffee.npy  \n",
            "  inflating: data/features/P24_stereo01_P24_sandwich.npy  \n",
            "  inflating: data/features/P24_webcam01_P24_cereals.npy  \n",
            "  inflating: data/features/P24_webcam01_P24_coffee.npy  \n",
            "  inflating: data/features/P24_webcam01_P24_pancake.npy  \n",
            "  inflating: data/features/P24_webcam01_P24_sandwich.npy  \n",
            "  inflating: data/features/P24_webcam01_P24_tea.npy  \n",
            "  inflating: data/features/P24_webcam02_P24_cereals.npy  \n",
            "  inflating: data/features/P24_webcam02_P24_coffee.npy  \n",
            "  inflating: data/features/P24_webcam02_P24_pancake.npy  \n",
            "  inflating: data/features/P24_webcam02_P24_sandwich.npy  \n",
            "  inflating: data/features/P24_webcam02_P24_tea.npy  \n",
            "  inflating: data/features/P25_cam01_P25_cereals.npy  \n",
            "  inflating: data/features/P25_cam01_P25_coffee.npy  \n",
            "  inflating: data/features/P25_cam01_P25_sandwich.npy  \n",
            "  inflating: data/features/P25_cam01_P25_tea.npy  \n",
            "  inflating: data/features/P25_cam02_P25_cereals.npy  \n",
            "  inflating: data/features/P25_cam02_P25_coffee.npy  \n",
            "  inflating: data/features/P25_cam02_P25_pancake.npy  \n",
            "  inflating: data/features/P25_cam02_P25_sandwich.npy  \n",
            "  inflating: data/features/P25_cam02_P25_tea.npy  \n",
            "  inflating: data/features/P25_stereo01_P25_sandwich.npy  \n",
            "  inflating: data/features/P25_stereo01_P25_tea.npy  \n",
            "  inflating: data/features/P25_webcam02_P25_cereals.npy  \n",
            "  inflating: data/features/P25_webcam02_P25_coffee.npy  \n",
            "  inflating: data/features/P25_webcam02_P25_pancake.npy  \n",
            "  inflating: data/features/P25_webcam02_P25_sandwich.npy  \n",
            "  inflating: data/features/P25_webcam02_P25_tea.npy  \n",
            "  inflating: data/features/P26_cam01_P26_cereals.npy  \n",
            "  inflating: data/features/P26_cam01_P26_coffee.npy  \n",
            "  inflating: data/features/P26_cam01_P26_pancake.npy  \n",
            "  inflating: data/features/P26_cam01_P26_sandwich.npy  \n",
            "  inflating: data/features/P26_cam02_P26_cereals.npy  \n",
            "  inflating: data/features/P26_cam02_P26_coffee.npy  \n",
            "  inflating: data/features/P26_cam02_P26_pancake.npy  \n",
            "  inflating: data/features/P26_cam02_P26_sandwich.npy  \n",
            "  inflating: data/features/P26_stereo01_P26_cereals.npy  \n",
            "  inflating: data/features/P26_stereo01_P26_coffee.npy  \n",
            "  inflating: data/features/P26_stereo01_P26_pancake.npy  \n",
            "  inflating: data/features/P26_webcam02_P26_cereals.npy  \n",
            "  inflating: data/features/P26_webcam02_P26_coffee.npy  \n",
            "  inflating: data/features/P26_webcam02_P26_pancake.npy  \n",
            "  inflating: data/features/P26_webcam02_P26_sandwich.npy  \n",
            "  inflating: data/features/P26_webcam02_P26_tea.npy  \n",
            "  inflating: data/features/P27_cam01_P27_cereals.npy  \n",
            "  inflating: data/features/P27_cam01_P27_coffee.npy  \n",
            "  inflating: data/features/P27_cam01_P27_pancake.npy  \n",
            "  inflating: data/features/P27_cam01_P27_sandwich.npy  \n",
            "  inflating: data/features/P27_cam01_P27_tea.npy  \n",
            "  inflating: data/features/P27_cam02_P27_cereals.npy  \n",
            "  inflating: data/features/P27_cam02_P27_coffee.npy  \n",
            "  inflating: data/features/P27_cam02_P27_pancake.npy  \n",
            "  inflating: data/features/P27_cam02_P27_sandwich.npy  \n",
            "  inflating: data/features/P27_cam02_P27_tea.npy  \n",
            "  inflating: data/features/P27_stereo01_P27_coffee.npy  \n",
            "  inflating: data/features/P27_stereo01_P27_pancake.npy  \n",
            "  inflating: data/features/P27_webcam02_P27_cereals.npy  \n",
            "  inflating: data/features/P27_webcam02_P27_coffee.npy  \n",
            "  inflating: data/features/P27_webcam02_P27_pancake.npy  \n",
            "  inflating: data/features/P27_webcam02_P27_sandwich.npy  \n",
            "  inflating: data/features/P27_webcam02_P27_tea.npy  \n",
            "  inflating: data/features/P28_cam01_P28_cereals.npy  \n",
            "  inflating: data/features/P28_cam01_P28_sandwich.npy  \n",
            "  inflating: data/features/P28_cam02_P28_cereals.npy  \n",
            "  inflating: data/features/P28_cam02_P28_sandwich.npy  \n",
            "  inflating: data/features/P28_stereo01_P28_cereals.npy  \n",
            "  inflating: data/features/P29_cam01_P29_cereals.npy  \n",
            "  inflating: data/features/P29_cam01_P29_coffee.npy  \n",
            "  inflating: data/features/P29_cam01_P29_pancake.npy  \n",
            "  inflating: data/features/P29_cam01_P29_sandwich.npy  \n",
            "  inflating: data/features/P29_cam01_P29_tea.npy  \n",
            "  inflating: data/features/P29_cam02_P29_cereals.npy  \n",
            "  inflating: data/features/P29_cam02_P29_coffee.npy  \n",
            "  inflating: data/features/P29_cam02_P29_pancake.npy  \n",
            "  inflating: data/features/P29_cam02_P29_sandwich.npy  \n",
            "  inflating: data/features/P29_cam02_P29_tea.npy  \n",
            "  inflating: data/features/P29_stereo01_P29_coffee.npy  \n",
            "  inflating: data/features/P29_stereo01_P29_pancake.npy  \n",
            "  inflating: data/features/P29_stereo01_P29_sandwich.npy  \n",
            "  inflating: data/features/P29_stereo01_P29_tea.npy  \n",
            "  inflating: data/features/P30_cam01_P30_coffee.npy  \n",
            "  inflating: data/features/P30_cam01_P30_pancake.npy  \n",
            "  inflating: data/features/P30_cam01_P30_tea.npy  \n",
            "  inflating: data/features/P30_cam02_P30_cereals.npy  \n",
            "  inflating: data/features/P30_cam02_P30_coffee.npy  \n",
            "  inflating: data/features/P30_cam02_P30_pancake.npy  \n",
            "  inflating: data/features/P30_cam02_P30_sandwich.npy  \n",
            "  inflating: data/features/P30_cam02_P30_tea.npy  \n",
            "  inflating: data/features/P30_stereo01_P30_coffee.npy  \n",
            "  inflating: data/features/P30_stereo01_P30_sandwich.npy  \n",
            "  inflating: data/features/P30_stereo01_P30_tea.npy  \n",
            "  inflating: data/features/P31_cam01_P31_cereals.npy  \n",
            "  inflating: data/features/P31_cam01_P31_coffee.npy  \n",
            "  inflating: data/features/P31_cam01_P31_pancake.npy  \n",
            "  inflating: data/features/P31_cam01_P31_sandwich.npy  \n",
            "  inflating: data/features/P31_cam01_P31_tea.npy  \n",
            "  inflating: data/features/P31_cam02_P31_cereals.npy  \n",
            "  inflating: data/features/P31_cam02_P31_coffee.npy  \n",
            "  inflating: data/features/P31_cam02_P31_pancake.npy  \n",
            "  inflating: data/features/P31_cam02_P31_sandwich.npy  \n",
            "  inflating: data/features/P31_cam02_P31_tea.npy  \n",
            "  inflating: data/features/P31_stereo01_P31_coffee.npy  \n",
            "  inflating: data/features/P31_stereo01_P31_tea.npy  \n",
            "  inflating: data/features/P32_cam01_P32_cereals.npy  \n",
            "  inflating: data/features/P32_cam01_P32_coffee.npy  \n",
            "  inflating: data/features/P32_cam01_P32_pancake.npy  \n",
            "  inflating: data/features/P32_cam01_P32_sandwich.npy  \n",
            "  inflating: data/features/P32_cam01_P32_tea.npy  \n",
            "  inflating: data/features/P32_cam02_P32_cereals.npy  \n",
            "  inflating: data/features/P32_cam02_P32_coffee.npy  \n",
            "  inflating: data/features/P32_cam02_P32_pancake.npy  \n",
            "  inflating: data/features/P32_cam02_P32_sandwich.npy  \n",
            "  inflating: data/features/P32_cam02_P32_tea.npy  \n",
            "  inflating: data/features/P32_stereo01_P32_cereals.npy  \n",
            "  inflating: data/features/P32_stereo01_P32_coffee.npy  \n",
            "  inflating: data/features/P32_stereo01_P32_sandwich.npy  \n",
            "  inflating: data/features/P32_stereo01_P32_tea.npy  \n",
            "  inflating: data/features/P33_cam01_P33_cereals.npy  \n",
            "  inflating: data/features/P33_cam01_P33_coffee.npy  \n",
            "  inflating: data/features/P33_cam01_P33_pancake.npy  \n",
            "  inflating: data/features/P33_cam01_P33_sandwich.npy  \n",
            "  inflating: data/features/P33_cam01_P33_tea.npy  \n",
            "  inflating: data/features/P33_cam02_P33_cereals.npy  \n",
            "  inflating: data/features/P33_cam02_P33_coffee.npy  \n",
            "  inflating: data/features/P33_cam02_P33_pancake.npy  \n",
            "  inflating: data/features/P33_cam02_P33_sandwich.npy  \n",
            "  inflating: data/features/P33_cam02_P33_tea.npy  \n",
            "  inflating: data/features/P33_stereo01_P33_cereals.npy  \n",
            "  inflating: data/features/P33_stereo01_P33_sandwich.npy  \n",
            "  inflating: data/features/P33_stereo01_P33_tea.npy  \n",
            "  inflating: data/features/P34_cam01_P34_cereals.npy  \n",
            "  inflating: data/features/P34_cam01_P34_coffee.npy  \n",
            "  inflating: data/features/P34_cam01_P34_sandwich.npy  \n",
            "  inflating: data/features/P34_cam01_P34_tea.npy  \n",
            "  inflating: data/features/P34_stereo01_P34_cereals.npy  \n",
            "  inflating: data/features/P34_stereo01_P34_sandwich.npy  \n",
            "  inflating: data/features/P34_stereo01_P34_tea.npy  \n",
            "  inflating: data/features/P34_webcam02_P34_cereals.npy  \n",
            "  inflating: data/features/P34_webcam02_P34_coffee.npy  \n",
            "  inflating: data/features/P34_webcam02_P34_sandwich.npy  \n",
            "  inflating: data/features/P34_webcam02_P34_tea.npy  \n",
            "  inflating: data/features/P35_cam01_P35_cereals.npy  \n",
            "  inflating: data/features/P35_cam01_P35_coffee.npy  \n",
            "  inflating: data/features/P35_cam01_P35_pancake.npy  \n",
            "  inflating: data/features/P35_cam01_P35_sandwich.npy  \n",
            "  inflating: data/features/P35_cam01_P35_tea.npy  \n",
            "  inflating: data/features/P35_cam02_P35_cereals.npy  \n",
            "  inflating: data/features/P35_cam02_P35_coffee.npy  \n",
            "  inflating: data/features/P35_cam02_P35_tea.npy  \n",
            "  inflating: data/features/P35_stereo01_P35_cereals.npy  \n",
            "  inflating: data/features/P35_stereo01_P35_coffee.npy  \n",
            "  inflating: data/features/P35_stereo01_P35_sandwich.npy  \n",
            "  inflating: data/features/P35_stereo01_P35_tea.npy  \n",
            "  inflating: data/features/P35_webcam02_P35_cereals.npy  \n",
            "  inflating: data/features/P35_webcam02_P35_coffee.npy  \n",
            "  inflating: data/features/P35_webcam02_P35_pancake.npy  \n",
            "  inflating: data/features/P35_webcam02_P35_sandwich.npy  \n",
            "  inflating: data/features/P35_webcam02_P35_tea.npy  \n",
            "  inflating: data/features/P36_cam01_P36_cereals.npy  \n",
            "  inflating: data/features/P36_cam01_P36_pancake.npy  \n",
            "  inflating: data/features/P36_cam01_P36_sandwich.npy  \n",
            "  inflating: data/features/P36_cam01_P36_tea.npy  \n",
            "  inflating: data/features/P36_stereo01_P36_cereals.npy  \n",
            "  inflating: data/features/P36_stereo01_P36_coffee.npy  \n",
            "  inflating: data/features/P36_stereo01_P36_pancake.npy  \n",
            "  inflating: data/features/P36_stereo01_P36_sandwich.npy  \n",
            "  inflating: data/features/P36_stereo01_P36_tea.npy  \n",
            "  inflating: data/features/P36_webcam01_P36_cereals.npy  \n",
            "  inflating: data/features/P36_webcam01_P36_pancake.npy  \n",
            "  inflating: data/features/P36_webcam01_P36_sandwich.npy  \n",
            "  inflating: data/features/P36_webcam01_P36_tea.npy  \n",
            "  inflating: data/features/P36_webcam02_P36_cereals.npy  \n",
            "  inflating: data/features/P36_webcam02_P36_pancake.npy  \n",
            "  inflating: data/features/P36_webcam02_P36_sandwich.npy  \n",
            "  inflating: data/features/P36_webcam02_P36_tea.npy  \n",
            "  inflating: data/features/P37_cam01_P37_cereals.npy  \n",
            "  inflating: data/features/P37_cam01_P37_coffee.npy  \n",
            "  inflating: data/features/P37_cam01_P37_pancake.npy  \n",
            "  inflating: data/features/P37_cam01_P37_sandwich.npy  \n",
            "  inflating: data/features/P37_cam01_P37_tea.npy  \n",
            "  inflating: data/features/P37_stereo01_P37_cereals.npy  \n",
            "  inflating: data/features/P37_stereo01_P37_coffee.npy  \n",
            "  inflating: data/features/P37_stereo01_P37_pancake.npy  \n",
            "  inflating: data/features/P37_stereo01_P37_sandwich.npy  \n",
            "  inflating: data/features/P37_stereo01_P37_tea.npy  \n",
            "  inflating: data/features/P37_webcam01_P37_cereals.npy  \n",
            "  inflating: data/features/P37_webcam01_P37_coffee.npy  \n",
            "  inflating: data/features/P37_webcam01_P37_pancake.npy  \n",
            "  inflating: data/features/P37_webcam01_P37_sandwich.npy  \n",
            "  inflating: data/features/P37_webcam01_P37_tea.npy  \n",
            "  inflating: data/features/P37_webcam02_P37_cereals.npy  \n",
            "  inflating: data/features/P37_webcam02_P37_coffee.npy  \n",
            "  inflating: data/features/P37_webcam02_P37_pancake.npy  \n",
            "  inflating: data/features/P37_webcam02_P37_sandwich.npy  \n",
            "  inflating: data/features/P37_webcam02_P37_tea.npy  \n",
            "  inflating: data/features/P38_cam01_P38_cereals.npy  \n",
            "  inflating: data/features/P38_cam01_P38_coffee.npy  \n",
            "  inflating: data/features/P38_cam01_P38_pancake.npy  \n",
            "  inflating: data/features/P38_cam01_P38_sandwich.npy  \n",
            "  inflating: data/features/P38_cam01_P38_tea.npy  \n",
            "  inflating: data/features/P38_stereo01_P38_cereals.npy  \n",
            "  inflating: data/features/P38_stereo01_P38_coffee.npy  \n",
            "  inflating: data/features/P38_stereo01_P38_pancake.npy  \n",
            "  inflating: data/features/P38_stereo01_P38_sandwich.npy  \n",
            "  inflating: data/features/P38_stereo01_P38_tea.npy  \n",
            "  inflating: data/features/P38_webcam01_P38_cereals.npy  \n",
            "  inflating: data/features/P38_webcam01_P38_coffee.npy  \n",
            "  inflating: data/features/P38_webcam01_P38_pancake.npy  \n",
            "  inflating: data/features/P38_webcam01_P38_sandwich.npy  \n",
            "  inflating: data/features/P38_webcam01_P38_tea.npy  \n",
            "  inflating: data/features/P38_webcam02_P38_cereals.npy  \n",
            "  inflating: data/features/P38_webcam02_P38_coffee.npy  \n",
            "  inflating: data/features/P38_webcam02_P38_pancake.npy  \n",
            "  inflating: data/features/P38_webcam02_P38_sandwich.npy  \n",
            "  inflating: data/features/P38_webcam02_P38_tea.npy  \n",
            "  inflating: data/features/P39_cam01_P39_cereals.npy  \n",
            "  inflating: data/features/P39_cam01_P39_pancake.npy  \n",
            "  inflating: data/features/P39_cam01_P39_sandwich.npy  \n",
            "  inflating: data/features/P39_cam01_P39_tea.npy  \n",
            "  inflating: data/features/P39_cam02_P39_cereals.npy  \n",
            "  inflating: data/features/P39_cam02_P39_pancake.npy  \n",
            "  inflating: data/features/P39_cam02_P39_sandwich.npy  \n",
            "  inflating: data/features/P39_cam02_P39_tea.npy  \n",
            "  inflating: data/features/P39_stereo01_P39_cereals.npy  \n",
            "  inflating: data/features/P39_stereo01_P39_coffee.npy  \n",
            "  inflating: data/features/P39_stereo01_P39_pancake.npy  \n",
            "  inflating: data/features/P39_stereo01_P39_sandwich.npy  \n",
            "  inflating: data/features/P39_stereo01_P39_tea.npy  \n",
            "  inflating: data/features/P39_webcam01_P39_cereals.npy  \n",
            "  inflating: data/features/P39_webcam01_P39_pancake.npy  \n",
            "  inflating: data/features/P39_webcam01_P39_sandwich.npy  \n",
            "  inflating: data/features/P39_webcam02_P39_cereals.npy  \n",
            "  inflating: data/features/P39_webcam02_P39_coffee.npy  \n",
            "  inflating: data/features/P39_webcam02_P39_pancake.npy  \n",
            "  inflating: data/features/P39_webcam02_P39_sandwich.npy  \n",
            "  inflating: data/features/P39_webcam02_P39_tea.npy  \n",
            "  inflating: data/features/P40_cam01_P40_cereals.npy  \n",
            "  inflating: data/features/P40_cam01_P40_pancake.npy  \n",
            "  inflating: data/features/P40_cam01_P40_sandwich.npy  \n",
            "  inflating: data/features/P40_cam02_P40_cereals.npy  \n",
            "  inflating: data/features/P40_cam02_P40_coffee.npy  \n",
            "  inflating: data/features/P40_cam02_P40_pancake.npy  \n",
            "  inflating: data/features/P40_cam02_P40_sandwich.npy  \n",
            "  inflating: data/features/P40_cam02_P40_tea.npy  \n",
            "  inflating: data/features/P40_stereo01_P40_cereals.npy  \n",
            "  inflating: data/features/P40_stereo01_P40_coffee.npy  \n",
            "  inflating: data/features/P40_stereo01_P40_sandwich.npy  \n",
            "  inflating: data/features/P40_stereo01_P40_tea.npy  \n",
            "  inflating: data/features/P40_webcam01_P40_cereals.npy  \n",
            "  inflating: data/features/P40_webcam01_P40_coffee.npy  \n",
            "  inflating: data/features/P40_webcam01_P40_pancake.npy  \n",
            "  inflating: data/features/P40_webcam01_P40_sandwich.npy  \n",
            "  inflating: data/features/P40_webcam01_P40_tea.npy  \n",
            "  inflating: data/features/P40_webcam02_P40_cereals.npy  \n",
            "  inflating: data/features/P40_webcam02_P40_coffee.npy  \n",
            "  inflating: data/features/P40_webcam02_P40_pancake.npy  \n",
            "  inflating: data/features/P40_webcam02_P40_sandwich.npy  \n",
            "  inflating: data/features/P40_webcam02_P40_tea.npy  \n",
            "  inflating: data/features/P41_cam01_P41_cereals.npy  \n",
            "  inflating: data/features/P41_cam01_P41_coffee.npy  \n",
            "  inflating: data/features/P41_cam01_P41_pancake.npy  \n",
            "  inflating: data/features/P41_cam01_P41_sandwich.npy  \n",
            "  inflating: data/features/P41_cam01_P41_tea.npy  \n",
            "  inflating: data/features/P41_cam02_P41_cereals.npy  \n",
            "  inflating: data/features/P41_cam02_P41_coffee.npy  \n",
            "  inflating: data/features/P41_cam02_P41_pancake.npy  \n",
            "  inflating: data/features/P41_cam02_P41_sandwich.npy  \n",
            "  inflating: data/features/P41_cam02_P41_tea.npy  \n",
            "  inflating: data/features/P41_stereo01_P41_cereals.npy  \n",
            "  inflating: data/features/P41_stereo01_P41_coffee.npy  \n",
            "  inflating: data/features/P41_stereo01_P41_pancake.npy  \n",
            "  inflating: data/features/P41_stereo01_P41_sandwich.npy  \n",
            "  inflating: data/features/P41_stereo01_P41_tea.npy  \n",
            "  inflating: data/features/P41_webcam01_P41_cereals.npy  \n",
            "  inflating: data/features/P41_webcam01_P41_coffee.npy  \n",
            "  inflating: data/features/P41_webcam01_P41_pancake.npy  \n",
            "  inflating: data/features/P41_webcam01_P41_sandwich.npy  \n",
            "  inflating: data/features/P41_webcam01_P41_tea.npy  \n",
            "  inflating: data/features/P41_webcam02_P41_cereals.npy  \n",
            "  inflating: data/features/P41_webcam02_P41_coffee.npy  \n",
            "  inflating: data/features/P41_webcam02_P41_pancake.npy  \n",
            "  inflating: data/features/P41_webcam02_P41_sandwich.npy  \n",
            "  inflating: data/features/P41_webcam02_P41_tea.npy  \n",
            "  inflating: data/features/P42_cam01_P42_cereals.npy  \n",
            "  inflating: data/features/P42_cam01_P42_coffee.npy  \n",
            "  inflating: data/features/P42_cam01_P42_pancake.npy  \n",
            "  inflating: data/features/P42_cam01_P42_sandwich.npy  \n",
            "  inflating: data/features/P42_cam01_P42_tea.npy  \n",
            "  inflating: data/features/P42_cam02_P42_cereals.npy  \n",
            "  inflating: data/features/P42_cam02_P42_coffee.npy  \n",
            "  inflating: data/features/P42_cam02_P42_pancake.npy  \n",
            "  inflating: data/features/P42_cam02_P42_sandwich.npy  \n",
            "  inflating: data/features/P42_cam02_P42_tea.npy  \n",
            "  inflating: data/features/P42_stereo01_P42_cereals.npy  \n",
            "  inflating: data/features/P42_stereo01_P42_coffee.npy  \n",
            "  inflating: data/features/P42_stereo01_P42_pancake.npy  \n",
            "  inflating: data/features/P42_stereo01_P42_sandwich.npy  \n",
            "  inflating: data/features/P42_stereo01_P42_tea.npy  \n",
            "  inflating: data/features/P42_webcam01_P42_cereals.npy  \n",
            "  inflating: data/features/P42_webcam01_P42_coffee.npy  \n",
            "  inflating: data/features/P42_webcam01_P42_pancake.npy  \n",
            "  inflating: data/features/P42_webcam01_P42_sandwich.npy  \n",
            "  inflating: data/features/P42_webcam01_P42_tea.npy  \n",
            "  inflating: data/features/P42_webcam02_P42_cereals.npy  \n",
            "  inflating: data/features/P42_webcam02_P42_coffee.npy  \n",
            "  inflating: data/features/P42_webcam02_P42_pancake.npy  \n",
            "  inflating: data/features/P42_webcam02_P42_sandwich.npy  \n",
            "  inflating: data/features/P42_webcam02_P42_tea.npy  \n",
            "  inflating: data/features/P43_cam02_P43_cereals.npy  \n",
            "  inflating: data/features/P43_cam02_P43_coffee.npy  \n",
            "  inflating: data/features/P43_cam02_P43_pancake.npy  \n",
            "  inflating: data/features/P43_cam02_P43_tea.npy  \n",
            "  inflating: data/features/P43_stereo01_P43_cereals.npy  \n",
            "  inflating: data/features/P43_stereo01_P43_pancake.npy  \n",
            "  inflating: data/features/P43_stereo01_P43_tea.npy  \n",
            "  inflating: data/features/P43_webcam01_P43_cereals.npy  \n",
            "  inflating: data/features/P43_webcam01_P43_coffee.npy  \n",
            "  inflating: data/features/P43_webcam01_P43_pancake.npy  \n",
            "  inflating: data/features/P43_webcam01_P43_sandwich.npy  \n",
            "  inflating: data/features/P43_webcam01_P43_tea.npy  \n",
            "  inflating: data/features/P43_webcam02_P43_cereals.npy  \n",
            "  inflating: data/features/P43_webcam02_P43_coffee.npy  \n",
            "  inflating: data/features/P43_webcam02_P43_pancake.npy  \n",
            "  inflating: data/features/P43_webcam02_P43_sandwich.npy  \n",
            "  inflating: data/features/P43_webcam02_P43_tea.npy  \n",
            "  inflating: data/features/P44_cam01_P44_cereals.npy  \n",
            "  inflating: data/features/P44_cam01_P44_coffee.npy  \n",
            "  inflating: data/features/P44_cam01_P44_pancake.npy  \n",
            "  inflating: data/features/P44_cam01_P44_sandwich.npy  \n",
            "  inflating: data/features/P44_cam01_P44_tea.npy  \n",
            "  inflating: data/features/P44_cam02_P44_cereals.npy  \n",
            "  inflating: data/features/P44_cam02_P44_coffee.npy  \n",
            "  inflating: data/features/P44_cam02_P44_pancake.npy  \n",
            "  inflating: data/features/P44_cam02_P44_sandwich.npy  \n",
            "  inflating: data/features/P44_cam02_P44_tea.npy  \n",
            "  inflating: data/features/P44_stereo01_P44_cereals.npy  \n",
            "  inflating: data/features/P44_stereo01_P44_coffee.npy  \n",
            "  inflating: data/features/P44_stereo01_P44_sandwich.npy  \n",
            "  inflating: data/features/P44_stereo01_P44_tea.npy  \n",
            "  inflating: data/features/P44_webcam01_P44_cereals.npy  \n",
            "  inflating: data/features/P44_webcam01_P44_coffee.npy  \n",
            "  inflating: data/features/P44_webcam01_P44_pancake.npy  \n",
            "  inflating: data/features/P44_webcam01_P44_sandwich.npy  \n",
            "  inflating: data/features/P44_webcam01_P44_tea.npy  \n",
            "  inflating: data/features/P44_webcam02_P44_cereals.npy  \n",
            "  inflating: data/features/P44_webcam02_P44_coffee.npy  \n",
            "  inflating: data/features/P44_webcam02_P44_pancake.npy  \n",
            "  inflating: data/features/P44_webcam02_P44_sandwich.npy  \n",
            "  inflating: data/features/P44_webcam02_P44_tea.npy  \n",
            "  inflating: data/features/P45_cam01_P45_cereals.npy  \n",
            "  inflating: data/features/P45_cam01_P45_coffee.npy  \n",
            "  inflating: data/features/P45_cam01_P45_pancake.npy  \n",
            "  inflating: data/features/P45_cam01_P45_sandwich.npy  \n",
            "  inflating: data/features/P45_cam01_P45_tea.npy  \n",
            "  inflating: data/features/P45_cam02_P45_cereals.npy  \n",
            "  inflating: data/features/P45_cam02_P45_coffee.npy  \n",
            "  inflating: data/features/P45_cam02_P45_pancake.npy  \n",
            "  inflating: data/features/P45_cam02_P45_tea.npy  \n",
            "  inflating: data/features/P45_stereo01_P45_cereals.npy  \n",
            "  inflating: data/features/P45_stereo01_P45_coffee.npy  \n",
            "  inflating: data/features/P45_webcam01_P45_cereals.npy  \n",
            "  inflating: data/features/P45_webcam01_P45_coffee.npy  \n",
            "  inflating: data/features/P45_webcam01_P45_pancake.npy  \n",
            "  inflating: data/features/P45_webcam01_P45_sandwich.npy  \n",
            "  inflating: data/features/P45_webcam01_P45_tea.npy  \n",
            "  inflating: data/features/P45_webcam02_P45_cereals.npy  \n",
            "  inflating: data/features/P45_webcam02_P45_coffee.npy  \n",
            "  inflating: data/features/P45_webcam02_P45_pancake.npy  \n",
            "  inflating: data/features/P45_webcam02_P45_sandwich.npy  \n",
            "  inflating: data/features/P45_webcam02_P45_tea.npy  \n",
            "  inflating: data/features/P46_cam01_P46_cereals.npy  \n",
            "  inflating: data/features/P46_cam01_P46_coffee.npy  \n",
            "  inflating: data/features/P46_cam01_P46_pancake.npy  \n",
            "  inflating: data/features/P46_cam01_P46_sandwich.npy  \n",
            "  inflating: data/features/P46_cam01_P46_tea.npy  \n",
            "  inflating: data/features/P46_cam02_P46_cereals.npy  \n",
            "  inflating: data/features/P46_cam02_P46_coffee.npy  \n",
            "  inflating: data/features/P46_cam02_P46_pancake.npy  \n",
            "  inflating: data/features/P46_cam02_P46_sandwich.npy  \n",
            "  inflating: data/features/P46_cam02_P46_tea.npy  \n",
            "  inflating: data/features/P46_stereo01_P46_coffee.npy  \n",
            "  inflating: data/features/P46_stereo01_P46_tea.npy  \n",
            "  inflating: data/features/P46_webcam01_P46_cereals.npy  \n",
            "  inflating: data/features/P46_webcam01_P46_coffee.npy  \n",
            "  inflating: data/features/P46_webcam01_P46_pancake.npy  \n",
            "  inflating: data/features/P46_webcam01_P46_sandwich.npy  \n",
            "  inflating: data/features/P46_webcam01_P46_tea.npy  \n",
            "  inflating: data/features/P46_webcam02_P46_cereals.npy  \n",
            "  inflating: data/features/P46_webcam02_P46_coffee.npy  \n",
            "  inflating: data/features/P46_webcam02_P46_pancake.npy  \n",
            "  inflating: data/features/P46_webcam02_P46_sandwich.npy  \n",
            "  inflating: data/features/P46_webcam02_P46_tea.npy  \n",
            "  inflating: data/features/P47_cam01_P47_cereals.npy  \n",
            "  inflating: data/features/P47_cam01_P47_coffee.npy  \n",
            "  inflating: data/features/P47_cam01_P47_pancake.npy  \n",
            "  inflating: data/features/P47_cam01_P47_sandwich.npy  \n",
            "  inflating: data/features/P47_cam01_P47_tea.npy  \n",
            "  inflating: data/features/P47_cam02_P47_cereals.npy  \n",
            "  inflating: data/features/P47_cam02_P47_coffee.npy  \n",
            "  inflating: data/features/P47_cam02_P47_pancake.npy  \n",
            "  inflating: data/features/P47_cam02_P47_sandwich.npy  \n",
            "  inflating: data/features/P47_cam02_P47_tea.npy  \n",
            "  inflating: data/features/P47_stereo01_P47_cereals.npy  \n",
            "  inflating: data/features/P47_stereo01_P47_tea.npy  \n",
            "  inflating: data/features/P47_webcam01_P47_cereals.npy  \n",
            "  inflating: data/features/P47_webcam01_P47_coffee.npy  \n",
            "  inflating: data/features/P47_webcam01_P47_pancake.npy  \n",
            "  inflating: data/features/P47_webcam01_P47_sandwich.npy  \n",
            "  inflating: data/features/P47_webcam01_P47_tea.npy  \n",
            "  inflating: data/features/P47_webcam02_P47_cereals.npy  \n",
            "  inflating: data/features/P47_webcam02_P47_coffee.npy  \n",
            "  inflating: data/features/P47_webcam02_P47_pancake.npy  \n",
            "  inflating: data/features/P47_webcam02_P47_sandwich.npy  \n",
            "  inflating: data/features/P47_webcam02_P47_tea.npy  \n",
            "  inflating: data/features/P48_cam01_P48_cereals.npy  \n",
            "  inflating: data/features/P48_cam01_P48_pancake.npy  \n",
            "  inflating: data/features/P48_cam01_P48_sandwich.npy  \n",
            "  inflating: data/features/P48_cam01_P48_tea.npy  \n",
            "  inflating: data/features/P48_cam02_P48_cereals.npy  \n",
            "  inflating: data/features/P48_cam02_P48_coffee.npy  \n",
            "  inflating: data/features/P48_cam02_P48_pancake.npy  \n",
            "  inflating: data/features/P48_cam02_P48_sandwich.npy  \n",
            "  inflating: data/features/P48_cam02_P48_tea.npy  \n",
            "  inflating: data/features/P48_stereo01_P48_cereals.npy  \n",
            "  inflating: data/features/P48_stereo01_P48_coffee.npy  \n",
            "  inflating: data/features/P48_webcam01_P48_cereals.npy  \n",
            "  inflating: data/features/P48_webcam01_P48_coffee.npy  \n",
            "  inflating: data/features/P48_webcam01_P48_pancake.npy  \n",
            "  inflating: data/features/P48_webcam01_P48_sandwich.npy  \n",
            "  inflating: data/features/P48_webcam01_P48_tea.npy  \n",
            "  inflating: data/features/P48_webcam02_P48_cereals.npy  \n",
            "  inflating: data/features/P48_webcam02_P48_coffee.npy  \n",
            "  inflating: data/features/P48_webcam02_P48_pancake.npy  \n",
            "  inflating: data/features/P48_webcam02_P48_sandwich.npy  \n",
            "  inflating: data/features/P48_webcam02_P48_tea.npy  \n",
            "  inflating: data/features/P49_cam01_P49_cereals.npy  \n",
            "  inflating: data/features/P49_cam01_P49_coffee.npy  \n",
            "  inflating: data/features/P49_cam01_P49_pancake.npy  \n",
            "  inflating: data/features/P49_cam01_P49_sandwich.npy  \n",
            "  inflating: data/features/P49_cam01_P49_tea.npy  \n",
            "  inflating: data/features/P49_cam02_P49_cereals.npy  \n",
            "  inflating: data/features/P49_cam02_P49_coffee.npy  \n",
            "  inflating: data/features/P49_cam02_P49_pancake.npy  \n",
            "  inflating: data/features/P49_cam02_P49_sandwich.npy  \n",
            "  inflating: data/features/P49_cam02_P49_tea.npy  \n",
            "  inflating: data/features/P49_stereo01_P49_cereals.npy  \n",
            "  inflating: data/features/P49_stereo01_P49_coffee.npy  \n",
            "  inflating: data/features/P49_stereo01_P49_sandwich.npy  \n",
            "  inflating: data/features/P49_stereo01_P49_tea.npy  \n",
            "  inflating: data/features/P49_webcam01_P49_cereals.npy  \n",
            "  inflating: data/features/P49_webcam01_P49_coffee.npy  \n",
            "  inflating: data/features/P49_webcam01_P49_pancake.npy  \n",
            "  inflating: data/features/P49_webcam01_P49_sandwich.npy  \n",
            "  inflating: data/features/P49_webcam01_P49_tea.npy  \n",
            "  inflating: data/features/P49_webcam02_P49_coffee.npy  \n",
            "  inflating: data/features/P49_webcam02_P49_pancake.npy  \n",
            "  inflating: data/features/P49_webcam02_P49_sandwich.npy  \n",
            "  inflating: data/features/P49_webcam02_P49_tea.npy  \n",
            "  inflating: data/features/P50_cam01_P50_cereals.npy  \n",
            "  inflating: data/features/P50_cam01_P50_coffee.npy  \n",
            "  inflating: data/features/P50_cam01_P50_pancake.npy  \n",
            "  inflating: data/features/P50_cam01_P50_sandwich.npy  \n",
            "  inflating: data/features/P50_cam01_P50_tea.npy  \n",
            "  inflating: data/features/P50_cam02_P50_cereals.npy  \n",
            "  inflating: data/features/P50_cam02_P50_coffee.npy  \n",
            "  inflating: data/features/P50_cam02_P50_pancake.npy  \n",
            "  inflating: data/features/P50_cam02_P50_sandwich.npy  \n",
            "  inflating: data/features/P50_cam02_P50_tea.npy  \n",
            "  inflating: data/features/P50_stereo01_P50_cereals.npy  \n",
            "  inflating: data/features/P50_stereo01_P50_coffee.npy  \n",
            "  inflating: data/features/P50_stereo01_P50_pancake.npy  \n",
            "  inflating: data/features/P50_stereo01_P50_sandwich.npy  \n",
            "  inflating: data/features/P50_stereo01_P50_tea.npy  \n",
            "  inflating: data/features/P50_webcam01_P50_cereals.npy  \n",
            "  inflating: data/features/P50_webcam01_P50_coffee.npy  \n",
            "  inflating: data/features/P50_webcam01_P50_pancake.npy  \n",
            "  inflating: data/features/P50_webcam01_P50_sandwich.npy  \n",
            "  inflating: data/features/P50_webcam01_P50_tea.npy  \n",
            "  inflating: data/features/P50_webcam02_P50_cereals.npy  \n",
            "  inflating: data/features/P50_webcam02_P50_coffee.npy  \n",
            "  inflating: data/features/P50_webcam02_P50_pancake.npy  \n",
            "  inflating: data/features/P50_webcam02_P50_sandwich.npy  \n",
            "  inflating: data/features/P50_webcam02_P50_tea.npy  \n",
            "  inflating: data/features/P51_cam01_P51_cereals.npy  \n",
            "  inflating: data/features/P51_cam01_P51_pancake.npy  \n",
            "  inflating: data/features/P51_cam01_P51_sandwich.npy  \n",
            "  inflating: data/features/P51_cam01_P51_tea.npy  \n",
            "  inflating: data/features/P51_cam02_P51_cereals.npy  \n",
            "  inflating: data/features/P51_cam02_P51_coffee.npy  \n",
            "  inflating: data/features/P51_cam02_P51_pancake.npy  \n",
            "  inflating: data/features/P51_cam02_P51_sandwich.npy  \n",
            "  inflating: data/features/P51_cam02_P51_tea.npy  \n",
            "  inflating: data/features/P51_stereo01_P51_cereals.npy  \n",
            "  inflating: data/features/P51_stereo01_P51_coffee.npy  \n",
            "  inflating: data/features/P51_stereo01_P51_sandwich.npy  \n",
            "  inflating: data/features/P51_stereo01_P51_tea.npy  \n",
            "  inflating: data/features/P51_webcam01_P51_cereals.npy  \n",
            "  inflating: data/features/P51_webcam01_P51_coffee.npy  \n",
            "  inflating: data/features/P51_webcam01_P51_pancake.npy  \n",
            "  inflating: data/features/P51_webcam01_P51_sandwich.npy  \n",
            "  inflating: data/features/P51_webcam01_P51_tea.npy  \n",
            "  inflating: data/features/P51_webcam02_P51_cereals.npy  \n",
            "  inflating: data/features/P51_webcam02_P51_coffee.npy  \n",
            "  inflating: data/features/P51_webcam02_P51_pancake.npy  \n",
            "  inflating: data/features/P51_webcam02_P51_sandwich.npy  \n",
            "  inflating: data/features/P51_webcam02_P51_tea.npy  \n",
            "  inflating: data/features/P52_cam01_P52_pancake.npy  \n",
            "  inflating: data/features/P52_cam01_P52_tea.npy  \n",
            "  inflating: data/features/P52_cam02_P52_cereals.npy  \n",
            "  inflating: data/features/P52_cam02_P52_coffee.npy  \n",
            "  inflating: data/features/P52_cam02_P52_pancake.npy  \n",
            "  inflating: data/features/P52_cam02_P52_tea.npy  \n",
            "  inflating: data/features/P52_stereo01_P52_cereals.npy  \n",
            "  inflating: data/features/P52_stereo01_P52_coffee.npy  \n",
            "  inflating: data/features/P52_stereo01_P52_pancake.npy  \n",
            "  inflating: data/features/P52_stereo01_P52_sandwich.npy  \n",
            "  inflating: data/features/P52_stereo01_P52_tea.npy  \n",
            "  inflating: data/features/P52_webcam01_P52_cereals.npy  \n",
            "  inflating: data/features/P52_webcam01_P52_coffee.npy  \n",
            "  inflating: data/features/P52_webcam01_P52_pancake.npy  \n",
            "  inflating: data/features/P52_webcam01_P52_sandwich.npy  \n",
            "  inflating: data/features/P52_webcam01_P52_tea.npy  \n",
            "  inflating: data/features/P52_webcam02_P52_cereals.npy  \n",
            "  inflating: data/features/P52_webcam02_P52_coffee.npy  \n",
            "  inflating: data/features/P52_webcam02_P52_pancake.npy  \n",
            "  inflating: data/features/P52_webcam02_P52_sandwich.npy  \n",
            "  inflating: data/features/P52_webcam02_P52_tea.npy  \n",
            "  inflating: data/features/P53_cam01_P53_cereals.npy  \n",
            "  inflating: data/features/P53_cam01_P53_pancake.npy  \n",
            "  inflating: data/features/P53_cam02_P53_cereals.npy  \n",
            "  inflating: data/features/P53_cam02_P53_coffee.npy  \n",
            "  inflating: data/features/P53_cam02_P53_pancake.npy  \n",
            "  inflating: data/features/P53_cam02_P53_sandwich.npy  \n",
            "  inflating: data/features/P53_cam02_P53_tea.npy  \n",
            "  inflating: data/features/P53_stereo01_P53_cereals.npy  \n",
            "  inflating: data/features/P53_stereo01_P53_coffee.npy  \n",
            "  inflating: data/features/P53_stereo01_P53_sandwich.npy  \n",
            "  inflating: data/features/P53_stereo01_P53_tea.npy  \n",
            "  inflating: data/features/P53_webcam01_P53_cereals.npy  \n",
            "  inflating: data/features/P53_webcam01_P53_coffee.npy  \n",
            "  inflating: data/features/P53_webcam01_P53_pancake.npy  \n",
            "  inflating: data/features/P53_webcam01_P53_sandwich.npy  \n",
            "  inflating: data/features/P53_webcam01_P53_tea.npy  \n",
            "  inflating: data/features/P53_webcam02_P53_cereals.npy  \n",
            "  inflating: data/features/P53_webcam02_P53_coffee.npy  \n",
            "  inflating: data/features/P53_webcam02_P53_pancake.npy  \n",
            "  inflating: data/features/P53_webcam02_P53_sandwich.npy  \n",
            "  inflating: data/features/P53_webcam02_P53_tea.npy  \n",
            "  inflating: data/features/P54_cam01_P54_cereals.npy  \n",
            "  inflating: data/features/P54_cam01_P54_pancake.npy  \n",
            "  inflating: data/features/P54_cam01_P54_sandwich.npy  \n",
            "  inflating: data/features/P54_cam02_P54_cereals.npy  \n",
            "  inflating: data/features/P54_cam02_P54_coffee.npy  \n",
            "  inflating: data/features/P54_cam02_P54_pancake.npy  \n",
            "  inflating: data/features/P54_cam02_P54_tea.npy  \n",
            "  inflating: data/features/P54_stereo01_P54_cereals.npy  \n",
            "  inflating: data/features/P54_stereo01_P54_coffee.npy  \n",
            "  inflating: data/features/P54_stereo01_P54_pancake.npy  \n",
            "  inflating: data/features/P54_stereo01_P54_sandwich.npy  \n",
            "  inflating: data/features/P54_stereo01_P54_tea.npy  \n",
            "  inflating: data/features/P54_webcam01_P54_cereals.npy  \n",
            "  inflating: data/features/P54_webcam01_P54_coffee.npy  \n",
            "  inflating: data/features/P54_webcam01_P54_pancake.npy  \n",
            "  inflating: data/features/P54_webcam01_P54_tea.npy  \n",
            "  inflating: data/features/P54_webcam02_P54_cereals.npy  \n",
            "  inflating: data/features/P54_webcam02_P54_coffee.npy  \n",
            "  inflating: data/features/P54_webcam02_P54_pancake.npy  \n",
            "  inflating: data/features/P54_webcam02_P54_sandwich.npy  \n",
            "  inflating: data/features/P54_webcam02_P54_tea.npy  \n",
            "   creating: data/groundTruth/\n",
            "  inflating: data/groundTruth/P03_cam01_P03_cereals.txt  \n",
            "  inflating: data/groundTruth/P03_cam01_P03_coffee.txt  \n",
            "  inflating: data/groundTruth/P03_cam01_P03_sandwich.txt  \n",
            "  inflating: data/groundTruth/P03_cam01_P03_tea.txt  \n",
            "  inflating: data/groundTruth/P03_stereo01_P03_cereals.txt  \n",
            "  inflating: data/groundTruth/P03_stereo01_P03_coffee.txt  \n",
            "  inflating: data/groundTruth/P03_stereo01_P03_sandwich.txt  \n",
            "  inflating: data/groundTruth/P03_stereo01_P03_tea.txt  \n",
            "  inflating: data/groundTruth/P03_webcam01_P03_cereals.txt  \n",
            "  inflating: data/groundTruth/P03_webcam01_P03_coffee.txt  \n",
            "  inflating: data/groundTruth/P03_webcam01_P03_sandwich.txt  \n",
            "  inflating: data/groundTruth/P03_webcam01_P03_tea.txt  \n",
            "  inflating: data/groundTruth/P03_webcam02_P03_cereals.txt  \n",
            "  inflating: data/groundTruth/P03_webcam02_P03_coffee.txt  \n",
            "  inflating: data/groundTruth/P03_webcam02_P03_sandwich.txt  \n",
            "  inflating: data/groundTruth/P03_webcam02_P03_tea.txt  \n",
            "  inflating: data/groundTruth/P04_cam01_P04_cereals.txt  \n",
            "  inflating: data/groundTruth/P04_cam01_P04_pancake.txt  \n",
            "  inflating: data/groundTruth/P04_cam01_P04_sandwich.txt  \n",
            "  inflating: data/groundTruth/P04_cam01_P04_tea.txt  \n",
            "  inflating: data/groundTruth/P04_stereo01_P04_cereals.txt  \n",
            "  inflating: data/groundTruth/P04_stereo01_P04_pancake.txt  \n",
            "  inflating: data/groundTruth/P04_stereo01_P04_sandwich.txt  \n",
            "  inflating: data/groundTruth/P04_stereo01_P04_tea.txt  \n",
            "  inflating: data/groundTruth/P04_webcam01_P04_cereals.txt  \n",
            "  inflating: data/groundTruth/P04_webcam01_P04_pancake.txt  \n",
            "  inflating: data/groundTruth/P04_webcam01_P04_sandwich.txt  \n",
            "  inflating: data/groundTruth/P04_webcam01_P04_tea.txt  \n",
            "  inflating: data/groundTruth/P04_webcam02_P04_cereals.txt  \n",
            "  inflating: data/groundTruth/P04_webcam02_P04_pancake.txt  \n",
            "  inflating: data/groundTruth/P04_webcam02_P04_sandwich.txt  \n",
            "  inflating: data/groundTruth/P04_webcam02_P04_tea.txt  \n",
            "  inflating: data/groundTruth/P05_cam01_P05_cereals.txt  \n",
            "  inflating: data/groundTruth/P05_cam01_P05_coffee.txt  \n",
            "  inflating: data/groundTruth/P05_cam01_P05_pancake.txt  \n",
            "  inflating: data/groundTruth/P05_cam01_P05_sandwich.txt  \n",
            "  inflating: data/groundTruth/P05_cam01_P05_tea.txt  \n",
            "  inflating: data/groundTruth/P06_cam01_P06_cereals.txt  \n",
            "  inflating: data/groundTruth/P06_cam01_P06_coffee.txt  \n",
            "  inflating: data/groundTruth/P06_cam01_P06_pancake.txt  \n",
            "  inflating: data/groundTruth/P06_cam01_P06_sandwich.txt  \n",
            "  inflating: data/groundTruth/P06_cam01_P06_tea.txt  \n",
            "  inflating: data/groundTruth/P07_stereo01_P07_sandwich.txt  \n",
            "  inflating: data/groundTruth/P07_stereo01_P07_tea.txt  \n",
            "  inflating: data/groundTruth/P07_webcam01_P07_cereals.txt  \n",
            "  inflating: data/groundTruth/P07_webcam01_P07_pancake.txt  \n",
            "  inflating: data/groundTruth/P07_webcam01_P07_sandwich.txt  \n",
            "  inflating: data/groundTruth/P07_webcam01_P07_tea.txt  \n",
            "  inflating: data/groundTruth/P08_cam01_P08_tea.txt  \n",
            "  inflating: data/groundTruth/P08_webcam01_P08_cereals.txt  \n",
            "  inflating: data/groundTruth/P08_webcam01_P08_coffee.txt  \n",
            "  inflating: data/groundTruth/P08_webcam01_P08_pancake.txt  \n",
            "  inflating: data/groundTruth/P08_webcam01_P08_sandwich.txt  \n",
            "  inflating: data/groundTruth/P08_webcam01_P08_tea.txt  \n",
            "  inflating: data/groundTruth/P09_cam01_P09_coffee.txt  \n",
            "  inflating: data/groundTruth/P09_cam01_P09_tea.txt  \n",
            "  inflating: data/groundTruth/P09_webcam01_P09_cereals.txt  \n",
            "  inflating: data/groundTruth/P09_webcam01_P09_coffee.txt  \n",
            "  inflating: data/groundTruth/P09_webcam01_P09_pancake.txt  \n",
            "  inflating: data/groundTruth/P09_webcam01_P09_sandwich.txt  \n",
            "  inflating: data/groundTruth/P09_webcam01_P09_tea.txt  \n",
            "  inflating: data/groundTruth/P10_cam01_P10_sandwich.txt  \n",
            "  inflating: data/groundTruth/P10_webcam01_P10_cereals.txt  \n",
            "  inflating: data/groundTruth/P10_webcam01_P10_coffee.txt  \n",
            "  inflating: data/groundTruth/P10_webcam01_P10_pancake.txt  \n",
            "  inflating: data/groundTruth/P10_webcam01_P10_tea.txt  \n",
            "  inflating: data/groundTruth/P11_cam01_P11_cereals.txt  \n",
            "  inflating: data/groundTruth/P11_cam01_P11_coffee.txt  \n",
            "  inflating: data/groundTruth/P11_cam01_P11_pancake.txt  \n",
            "  inflating: data/groundTruth/P11_cam01_P11_sandwich.txt  \n",
            "  inflating: data/groundTruth/P11_cam01_P11_tea.txt  \n",
            "  inflating: data/groundTruth/P11_webcam01_P11_cereals.txt  \n",
            "  inflating: data/groundTruth/P11_webcam01_P11_coffee.txt  \n",
            "  inflating: data/groundTruth/P11_webcam01_P11_pancake.txt  \n",
            "  inflating: data/groundTruth/P11_webcam01_P11_sandwich.txt  \n",
            "  inflating: data/groundTruth/P11_webcam01_P11_tea.txt  \n",
            "  inflating: data/groundTruth/P12_cam01_P12_cereals.txt  \n",
            "  inflating: data/groundTruth/P12_cam01_P12_coffee.txt  \n",
            "  inflating: data/groundTruth/P12_cam01_P12_pancake.txt  \n",
            "  inflating: data/groundTruth/P12_cam01_P12_sandwich.txt  \n",
            "  inflating: data/groundTruth/P12_cam01_P12_tea.txt  \n",
            "  inflating: data/groundTruth/P12_webcam01_P12_cereals.txt  \n",
            "  inflating: data/groundTruth/P12_webcam01_P12_coffee.txt  \n",
            "  inflating: data/groundTruth/P12_webcam01_P12_pancake.txt  \n",
            "  inflating: data/groundTruth/P12_webcam01_P12_sandwich.txt  \n",
            "  inflating: data/groundTruth/P12_webcam01_P12_tea.txt  \n",
            "  inflating: data/groundTruth/P13_cam01_P13_cereals.txt  \n",
            "  inflating: data/groundTruth/P13_cam01_P13_coffee.txt  \n",
            "  inflating: data/groundTruth/P13_cam01_P13_pancake.txt  \n",
            "  inflating: data/groundTruth/P13_cam01_P13_sandwich.txt  \n",
            "  inflating: data/groundTruth/P13_cam01_P13_tea.txt  \n",
            "  inflating: data/groundTruth/P13_stereo01_P13_cereals.txt  \n",
            "  inflating: data/groundTruth/P13_stereo01_P13_pancake.txt  \n",
            "  inflating: data/groundTruth/P13_stereo01_P13_tea.txt  \n",
            "  inflating: data/groundTruth/P13_webcam01_P13_cereals.txt  \n",
            "  inflating: data/groundTruth/P13_webcam01_P13_coffee.txt  \n",
            "  inflating: data/groundTruth/P13_webcam01_P13_pancake.txt  \n",
            "  inflating: data/groundTruth/P13_webcam01_P13_sandwich.txt  \n",
            "  inflating: data/groundTruth/P13_webcam01_P13_tea.txt  \n",
            "  inflating: data/groundTruth/P14_cam01_P14_cereals.txt  \n",
            "  inflating: data/groundTruth/P14_cam01_P14_coffee.txt  \n",
            "  inflating: data/groundTruth/P14_cam01_P14_pancake.txt  \n",
            "  inflating: data/groundTruth/P14_cam01_P14_sandwich.txt  \n",
            "  inflating: data/groundTruth/P14_cam01_P14_tea.txt  \n",
            "  inflating: data/groundTruth/P14_stereo01_P14_cereals.txt  \n",
            "  inflating: data/groundTruth/P14_stereo01_P14_coffee.txt  \n",
            "  inflating: data/groundTruth/P14_stereo01_P14_sandwich.txt  \n",
            "  inflating: data/groundTruth/P14_stereo01_P14_tea.txt  \n",
            "  inflating: data/groundTruth/P14_webcam01_P14_cereals.txt  \n",
            "  inflating: data/groundTruth/P14_webcam01_P14_coffee.txt  \n",
            "  inflating: data/groundTruth/P14_webcam01_P14_pancake.txt  \n",
            "  inflating: data/groundTruth/P14_webcam01_P14_sandwich.txt  \n",
            "  inflating: data/groundTruth/P14_webcam01_P14_tea.txt  \n",
            "  inflating: data/groundTruth/P15_cam01_P15_cereals.txt  \n",
            "  inflating: data/groundTruth/P15_cam01_P15_coffee.txt  \n",
            "  inflating: data/groundTruth/P15_cam01_P15_pancake.txt  \n",
            "  inflating: data/groundTruth/P15_cam01_P15_sandwich.txt  \n",
            "  inflating: data/groundTruth/P15_cam01_P15_tea.txt  \n",
            "  inflating: data/groundTruth/P15_stereo01_P15_cereals.txt  \n",
            "  inflating: data/groundTruth/P15_stereo01_P15_coffee.txt  \n",
            "  inflating: data/groundTruth/P15_stereo01_P15_pancake.txt  \n",
            "  inflating: data/groundTruth/P15_stereo01_P15_sandwich.txt  \n",
            "  inflating: data/groundTruth/P15_stereo01_P15_tea.txt  \n",
            "  inflating: data/groundTruth/P15_webcam01_P15_cereals.txt  \n",
            "  inflating: data/groundTruth/P15_webcam01_P15_coffee.txt  \n",
            "  inflating: data/groundTruth/P15_webcam01_P15_pancake.txt  \n",
            "  inflating: data/groundTruth/P15_webcam01_P15_sandwich.txt  \n",
            "  inflating: data/groundTruth/P15_webcam01_P15_tea.txt  \n",
            "  inflating: data/groundTruth/P16_cam01_P16_cereals.txt  \n",
            "  inflating: data/groundTruth/P16_cam01_P16_pancake.txt  \n",
            "  inflating: data/groundTruth/P16_cam01_P16_sandwich.txt  \n",
            "  inflating: data/groundTruth/P16_cam01_P16_tea.txt  \n",
            "  inflating: data/groundTruth/P16_stereo01_P16_cereals.txt  \n",
            "  inflating: data/groundTruth/P16_stereo01_P16_coffee.txt  \n",
            "  inflating: data/groundTruth/P16_stereo01_P16_pancake.txt  \n",
            "  inflating: data/groundTruth/P16_stereo01_P16_sandwich.txt  \n",
            "  inflating: data/groundTruth/P16_stereo01_P16_tea.txt  \n",
            "  inflating: data/groundTruth/P16_webcam01_P16_cereals.txt  \n",
            "  inflating: data/groundTruth/P16_webcam01_P16_pancake.txt  \n",
            "  inflating: data/groundTruth/P16_webcam01_P16_sandwich.txt  \n",
            "  inflating: data/groundTruth/P16_webcam01_P16_tea.txt  \n",
            "  inflating: data/groundTruth/P16_webcam02_P16_cereals.txt  \n",
            "  inflating: data/groundTruth/P16_webcam02_P16_coffee.txt  \n",
            "  inflating: data/groundTruth/P16_webcam02_P16_pancake.txt  \n",
            "  inflating: data/groundTruth/P16_webcam02_P16_sandwich.txt  \n",
            "  inflating: data/groundTruth/P16_webcam02_P16_tea.txt  \n",
            "  inflating: data/groundTruth/P17_cam01_P17_cereals.txt  \n",
            "  inflating: data/groundTruth/P17_cam01_P17_coffee.txt  \n",
            "  inflating: data/groundTruth/P17_cam01_P17_pancake.txt  \n",
            "  inflating: data/groundTruth/P17_cam01_P17_sandwich.txt  \n",
            "  inflating: data/groundTruth/P17_cam01_P17_tea.txt  \n",
            "  inflating: data/groundTruth/P17_stereo01_P17_cereals.txt  \n",
            "  inflating: data/groundTruth/P17_stereo01_P17_coffee.txt  \n",
            "  inflating: data/groundTruth/P17_stereo01_P17_pancake.txt  \n",
            "  inflating: data/groundTruth/P17_stereo01_P17_tea.txt  \n",
            "  inflating: data/groundTruth/P17_webcam01_P17_cereals.txt  \n",
            "  inflating: data/groundTruth/P17_webcam01_P17_coffee.txt  \n",
            "  inflating: data/groundTruth/P17_webcam01_P17_tea.txt  \n",
            "  inflating: data/groundTruth/P17_webcam02_P17_cereals.txt  \n",
            "  inflating: data/groundTruth/P17_webcam02_P17_coffee.txt  \n",
            "  inflating: data/groundTruth/P17_webcam02_P17_pancake.txt  \n",
            "  inflating: data/groundTruth/P17_webcam02_P17_tea.txt  \n",
            "  inflating: data/groundTruth/P18_cam01_P18_cereals.txt  \n",
            "  inflating: data/groundTruth/P18_cam01_P18_coffee.txt  \n",
            "  inflating: data/groundTruth/P18_cam01_P18_pancake.txt  \n",
            "  inflating: data/groundTruth/P18_cam01_P18_sandwich.txt  \n",
            "  inflating: data/groundTruth/P18_cam01_P18_tea.txt  \n",
            "  inflating: data/groundTruth/P18_stereo01_P18_cereals.txt  \n",
            "  inflating: data/groundTruth/P18_stereo01_P18_coffee.txt  \n",
            "  inflating: data/groundTruth/P18_stereo01_P18_tea.txt  \n",
            "  inflating: data/groundTruth/P18_webcam01_P18_cereals.txt  \n",
            "  inflating: data/groundTruth/P18_webcam01_P18_coffee.txt  \n",
            "  inflating: data/groundTruth/P18_webcam01_P18_pancake.txt  \n",
            "  inflating: data/groundTruth/P18_webcam01_P18_sandwich.txt  \n",
            "  inflating: data/groundTruth/P18_webcam01_P18_tea.txt  \n",
            "  inflating: data/groundTruth/P18_webcam02_P18_cereals.txt  \n",
            "  inflating: data/groundTruth/P18_webcam02_P18_coffee.txt  \n",
            "  inflating: data/groundTruth/P18_webcam02_P18_pancake.txt  \n",
            "  inflating: data/groundTruth/P18_webcam02_P18_sandwich.txt  \n",
            "  inflating: data/groundTruth/P18_webcam02_P18_tea.txt  \n",
            "  inflating: data/groundTruth/P19_cam01_P19_cereals.txt  \n",
            "  inflating: data/groundTruth/P19_cam01_P19_coffee.txt  \n",
            "  inflating: data/groundTruth/P19_cam01_P19_pancake.txt  \n",
            "  inflating: data/groundTruth/P19_cam01_P19_sandwich.txt  \n",
            "  inflating: data/groundTruth/P19_cam01_P19_tea.txt  \n",
            "  inflating: data/groundTruth/P19_stereo01_P19_cereals.txt  \n",
            "  inflating: data/groundTruth/P19_stereo01_P19_sandwich.txt  \n",
            "  inflating: data/groundTruth/P19_stereo01_P19_tea.txt  \n",
            "  inflating: data/groundTruth/P19_webcam01_P19_cereals.txt  \n",
            "  inflating: data/groundTruth/P19_webcam01_P19_coffee.txt  \n",
            "  inflating: data/groundTruth/P19_webcam01_P19_pancake.txt  \n",
            "  inflating: data/groundTruth/P19_webcam01_P19_sandwich.txt  \n",
            "  inflating: data/groundTruth/P19_webcam01_P19_tea.txt  \n",
            "  inflating: data/groundTruth/P19_webcam02_P19_cereals.txt  \n",
            "  inflating: data/groundTruth/P19_webcam02_P19_pancake.txt  \n",
            "  inflating: data/groundTruth/P19_webcam02_P19_sandwich.txt  \n",
            "  inflating: data/groundTruth/P19_webcam02_P19_tea.txt  \n",
            "  inflating: data/groundTruth/P20_cam01_P20_cereals.txt  \n",
            "  inflating: data/groundTruth/P20_cam01_P20_coffee.txt  \n",
            "  inflating: data/groundTruth/P20_cam01_P20_sandwich.txt  \n",
            "  inflating: data/groundTruth/P20_cam01_P20_tea.txt  \n",
            "  inflating: data/groundTruth/P20_cam02_P20_cereals.txt  \n",
            "  inflating: data/groundTruth/P20_cam02_P20_coffee.txt  \n",
            "  inflating: data/groundTruth/P20_cam02_P20_tea.txt  \n",
            "  inflating: data/groundTruth/P20_stereo01_P20_cereals.txt  \n",
            "  inflating: data/groundTruth/P20_stereo01_P20_coffee.txt  \n",
            "  inflating: data/groundTruth/P20_stereo01_P20_pancake.txt  \n",
            "  inflating: data/groundTruth/P20_stereo01_P20_tea.txt  \n",
            "  inflating: data/groundTruth/P20_webcam01_P20_cereals.txt  \n",
            "  inflating: data/groundTruth/P20_webcam01_P20_coffee.txt  \n",
            "  inflating: data/groundTruth/P20_webcam01_P20_pancake.txt  \n",
            "  inflating: data/groundTruth/P20_webcam01_P20_sandwich.txt  \n",
            "  inflating: data/groundTruth/P20_webcam01_P20_tea.txt  \n",
            "  inflating: data/groundTruth/P20_webcam02_P20_coffee.txt  \n",
            "  inflating: data/groundTruth/P20_webcam02_P20_pancake.txt  \n",
            "  inflating: data/groundTruth/P20_webcam02_P20_sandwich.txt  \n",
            "  inflating: data/groundTruth/P20_webcam02_P20_tea.txt  \n",
            "  inflating: data/groundTruth/P21_cam01_P21_cereals.txt  \n",
            "  inflating: data/groundTruth/P21_cam01_P21_coffee.txt  \n",
            "  inflating: data/groundTruth/P21_cam01_P21_pancake.txt  \n",
            "  inflating: data/groundTruth/P21_cam01_P21_sandwich.txt  \n",
            "  inflating: data/groundTruth/P21_cam01_P21_tea.txt  \n",
            "  inflating: data/groundTruth/P21_cam02_P21_cereals.txt  \n",
            "  inflating: data/groundTruth/P21_cam02_P21_coffee.txt  \n",
            "  inflating: data/groundTruth/P21_cam02_P21_tea.txt  \n",
            "  inflating: data/groundTruth/P21_stereo01_P21_coffee.txt  \n",
            "  inflating: data/groundTruth/P21_stereo01_P21_sandwich.txt  \n",
            "  inflating: data/groundTruth/P21_stereo01_P21_tea.txt  \n",
            "  inflating: data/groundTruth/P21_webcam01_P21_cereals.txt  \n",
            "  inflating: data/groundTruth/P21_webcam01_P21_coffee.txt  \n",
            "  inflating: data/groundTruth/P21_webcam01_P21_pancake.txt  \n",
            "  inflating: data/groundTruth/P21_webcam01_P21_sandwich.txt  \n",
            "  inflating: data/groundTruth/P21_webcam01_P21_tea.txt  \n",
            "  inflating: data/groundTruth/P21_webcam02_P21_cereals.txt  \n",
            "  inflating: data/groundTruth/P21_webcam02_P21_coffee.txt  \n",
            "  inflating: data/groundTruth/P21_webcam02_P21_pancake.txt  \n",
            "  inflating: data/groundTruth/P21_webcam02_P21_sandwich.txt  \n",
            "  inflating: data/groundTruth/P21_webcam02_P21_tea.txt  \n",
            "  inflating: data/groundTruth/P22_cam01_P22_cereals.txt  \n",
            "  inflating: data/groundTruth/P22_cam01_P22_coffee.txt  \n",
            "  inflating: data/groundTruth/P22_cam01_P22_pancake.txt  \n",
            "  inflating: data/groundTruth/P22_cam01_P22_sandwich.txt  \n",
            "  inflating: data/groundTruth/P22_cam01_P22_tea.txt  \n",
            "  inflating: data/groundTruth/P22_cam02_P22_cereals.txt  \n",
            "  inflating: data/groundTruth/P22_cam02_P22_coffee.txt  \n",
            "  inflating: data/groundTruth/P22_cam02_P22_tea.txt  \n",
            "  inflating: data/groundTruth/P22_stereo01_P22_cereals.txt  \n",
            "  inflating: data/groundTruth/P22_stereo01_P22_coffee.txt  \n",
            "  inflating: data/groundTruth/P22_stereo01_P22_tea.txt  \n",
            "  inflating: data/groundTruth/P22_webcam01_P22_cereals.txt  \n",
            "  inflating: data/groundTruth/P22_webcam01_P22_coffee.txt  \n",
            "  inflating: data/groundTruth/P22_webcam01_P22_pancake.txt  \n",
            "  inflating: data/groundTruth/P22_webcam01_P22_sandwich.txt  \n",
            "  inflating: data/groundTruth/P22_webcam01_P22_tea.txt  \n",
            "  inflating: data/groundTruth/P22_webcam02_P22_cereals.txt  \n",
            "  inflating: data/groundTruth/P22_webcam02_P22_coffee.txt  \n",
            "  inflating: data/groundTruth/P22_webcam02_P22_pancake.txt  \n",
            "  inflating: data/groundTruth/P22_webcam02_P22_sandwich.txt  \n",
            "  inflating: data/groundTruth/P22_webcam02_P22_tea.txt  \n",
            "  inflating: data/groundTruth/P23_cam01_P23_cereals.txt  \n",
            "  inflating: data/groundTruth/P23_cam01_P23_coffee.txt  \n",
            "  inflating: data/groundTruth/P23_cam01_P23_pancake.txt  \n",
            "  inflating: data/groundTruth/P23_cam01_P23_sandwich.txt  \n",
            "  inflating: data/groundTruth/P23_cam01_P23_tea.txt  \n",
            "  inflating: data/groundTruth/P23_cam02_P23_cereals.txt  \n",
            "  inflating: data/groundTruth/P23_cam02_P23_coffee.txt  \n",
            "  inflating: data/groundTruth/P23_cam02_P23_pancake.txt  \n",
            "  inflating: data/groundTruth/P23_cam02_P23_sandwich.txt  \n",
            "  inflating: data/groundTruth/P23_cam02_P23_tea.txt  \n",
            "  inflating: data/groundTruth/P23_stereo01_P23_cereals.txt  \n",
            "  inflating: data/groundTruth/P23_stereo01_P23_coffee.txt  \n",
            "  inflating: data/groundTruth/P23_stereo01_P23_sandwich.txt  \n",
            "  inflating: data/groundTruth/P23_stereo01_P23_tea.txt  \n",
            "  inflating: data/groundTruth/P23_webcam01_P23_cereals.txt  \n",
            "  inflating: data/groundTruth/P23_webcam01_P23_coffee.txt  \n",
            "  inflating: data/groundTruth/P23_webcam01_P23_pancake.txt  \n",
            "  inflating: data/groundTruth/P23_webcam01_P23_sandwich.txt  \n",
            "  inflating: data/groundTruth/P23_webcam01_P23_tea.txt  \n",
            "  inflating: data/groundTruth/P23_webcam02_P23_cereals.txt  \n",
            "  inflating: data/groundTruth/P23_webcam02_P23_coffee.txt  \n",
            "  inflating: data/groundTruth/P23_webcam02_P23_pancake.txt  \n",
            "  inflating: data/groundTruth/P23_webcam02_P23_sandwich.txt  \n",
            "  inflating: data/groundTruth/P23_webcam02_P23_tea.txt  \n",
            "  inflating: data/groundTruth/P24_cam01_P24_cereals.txt  \n",
            "  inflating: data/groundTruth/P24_cam01_P24_coffee.txt  \n",
            "  inflating: data/groundTruth/P24_cam01_P24_pancake.txt  \n",
            "  inflating: data/groundTruth/P24_cam01_P24_sandwich.txt  \n",
            "  inflating: data/groundTruth/P24_cam01_P24_tea.txt  \n",
            "  inflating: data/groundTruth/P24_cam02_P24_cereals.txt  \n",
            "  inflating: data/groundTruth/P24_cam02_P24_coffee.txt  \n",
            "  inflating: data/groundTruth/P24_cam02_P24_pancake.txt  \n",
            "  inflating: data/groundTruth/P24_cam02_P24_sandwich.txt  \n",
            "  inflating: data/groundTruth/P24_stereo01_P24_coffee.txt  \n",
            "  inflating: data/groundTruth/P24_stereo01_P24_sandwich.txt  \n",
            "  inflating: data/groundTruth/P24_webcam01_P24_cereals.txt  \n",
            "  inflating: data/groundTruth/P24_webcam01_P24_coffee.txt  \n",
            "  inflating: data/groundTruth/P24_webcam01_P24_pancake.txt  \n",
            "  inflating: data/groundTruth/P24_webcam01_P24_sandwich.txt  \n",
            "  inflating: data/groundTruth/P24_webcam01_P24_tea.txt  \n",
            "  inflating: data/groundTruth/P24_webcam02_P24_cereals.txt  \n",
            "  inflating: data/groundTruth/P24_webcam02_P24_coffee.txt  \n",
            "  inflating: data/groundTruth/P24_webcam02_P24_pancake.txt  \n",
            "  inflating: data/groundTruth/P24_webcam02_P24_sandwich.txt  \n",
            "  inflating: data/groundTruth/P24_webcam02_P24_tea.txt  \n",
            "  inflating: data/groundTruth/P25_cam01_P25_cereals.txt  \n",
            "  inflating: data/groundTruth/P25_cam01_P25_coffee.txt  \n",
            "  inflating: data/groundTruth/P25_cam01_P25_sandwich.txt  \n",
            "  inflating: data/groundTruth/P25_cam01_P25_tea.txt  \n",
            "  inflating: data/groundTruth/P25_cam02_P25_cereals.txt  \n",
            "  inflating: data/groundTruth/P25_cam02_P25_coffee.txt  \n",
            "  inflating: data/groundTruth/P25_cam02_P25_pancake.txt  \n",
            "  inflating: data/groundTruth/P25_cam02_P25_sandwich.txt  \n",
            "  inflating: data/groundTruth/P25_cam02_P25_tea.txt  \n",
            "  inflating: data/groundTruth/P25_stereo01_P25_sandwich.txt  \n",
            "  inflating: data/groundTruth/P25_stereo01_P25_tea.txt  \n",
            "  inflating: data/groundTruth/P25_webcam02_P25_cereals.txt  \n",
            "  inflating: data/groundTruth/P25_webcam02_P25_coffee.txt  \n",
            "  inflating: data/groundTruth/P25_webcam02_P25_pancake.txt  \n",
            "  inflating: data/groundTruth/P25_webcam02_P25_sandwich.txt  \n",
            "  inflating: data/groundTruth/P25_webcam02_P25_tea.txt  \n",
            "  inflating: data/groundTruth/P26_cam01_P26_cereals.txt  \n",
            "  inflating: data/groundTruth/P26_cam01_P26_coffee.txt  \n",
            "  inflating: data/groundTruth/P26_cam01_P26_pancake.txt  \n",
            "  inflating: data/groundTruth/P26_cam01_P26_sandwich.txt  \n",
            "  inflating: data/groundTruth/P26_cam02_P26_cereals.txt  \n",
            "  inflating: data/groundTruth/P26_cam02_P26_coffee.txt  \n",
            "  inflating: data/groundTruth/P26_cam02_P26_pancake.txt  \n",
            "  inflating: data/groundTruth/P26_cam02_P26_sandwich.txt  \n",
            "  inflating: data/groundTruth/P26_stereo01_P26_cereals.txt  \n",
            "  inflating: data/groundTruth/P26_stereo01_P26_coffee.txt  \n",
            "  inflating: data/groundTruth/P26_stereo01_P26_pancake.txt  \n",
            "  inflating: data/groundTruth/P26_webcam02_P26_cereals.txt  \n",
            "  inflating: data/groundTruth/P26_webcam02_P26_coffee.txt  \n",
            "  inflating: data/groundTruth/P26_webcam02_P26_pancake.txt  \n",
            "  inflating: data/groundTruth/P26_webcam02_P26_sandwich.txt  \n",
            "  inflating: data/groundTruth/P26_webcam02_P26_tea.txt  \n",
            "  inflating: data/groundTruth/P27_cam01_P27_cereals.txt  \n",
            "  inflating: data/groundTruth/P27_cam01_P27_coffee.txt  \n",
            "  inflating: data/groundTruth/P27_cam01_P27_pancake.txt  \n",
            "  inflating: data/groundTruth/P27_cam01_P27_sandwich.txt  \n",
            "  inflating: data/groundTruth/P27_cam01_P27_tea.txt  \n",
            "  inflating: data/groundTruth/P27_cam02_P27_cereals.txt  \n",
            "  inflating: data/groundTruth/P27_cam02_P27_coffee.txt  \n",
            "  inflating: data/groundTruth/P27_cam02_P27_pancake.txt  \n",
            "  inflating: data/groundTruth/P27_cam02_P27_sandwich.txt  \n",
            "  inflating: data/groundTruth/P27_cam02_P27_tea.txt  \n",
            "  inflating: data/groundTruth/P27_stereo01_P27_coffee.txt  \n",
            "  inflating: data/groundTruth/P27_stereo01_P27_pancake.txt  \n",
            "  inflating: data/groundTruth/P27_webcam02_P27_cereals.txt  \n",
            "  inflating: data/groundTruth/P27_webcam02_P27_coffee.txt  \n",
            "  inflating: data/groundTruth/P27_webcam02_P27_pancake.txt  \n",
            "  inflating: data/groundTruth/P27_webcam02_P27_sandwich.txt  \n",
            "  inflating: data/groundTruth/P27_webcam02_P27_tea.txt  \n",
            "  inflating: data/groundTruth/P28_cam01_P28_cereals.txt  \n",
            "  inflating: data/groundTruth/P28_cam01_P28_sandwich.txt  \n",
            "  inflating: data/groundTruth/P28_cam02_P28_cereals.txt  \n",
            "  inflating: data/groundTruth/P28_cam02_P28_sandwich.txt  \n",
            "  inflating: data/groundTruth/P28_stereo01_P28_cereals.txt  \n",
            "  inflating: data/groundTruth/P29_cam01_P29_cereals.txt  \n",
            "  inflating: data/groundTruth/P29_cam01_P29_coffee.txt  \n",
            "  inflating: data/groundTruth/P29_cam01_P29_pancake.txt  \n",
            "  inflating: data/groundTruth/P29_cam01_P29_sandwich.txt  \n",
            "  inflating: data/groundTruth/P29_cam01_P29_tea.txt  \n",
            "  inflating: data/groundTruth/P29_cam02_P29_cereals.txt  \n",
            "  inflating: data/groundTruth/P29_cam02_P29_coffee.txt  \n",
            "  inflating: data/groundTruth/P29_cam02_P29_pancake.txt  \n",
            "  inflating: data/groundTruth/P29_cam02_P29_sandwich.txt  \n",
            "  inflating: data/groundTruth/P29_cam02_P29_tea.txt  \n",
            "  inflating: data/groundTruth/P29_stereo01_P29_coffee.txt  \n",
            "  inflating: data/groundTruth/P29_stereo01_P29_pancake.txt  \n",
            "  inflating: data/groundTruth/P29_stereo01_P29_sandwich.txt  \n",
            "  inflating: data/groundTruth/P29_stereo01_P29_tea.txt  \n",
            "  inflating: data/groundTruth/P30_cam01_P30_coffee.txt  \n",
            "  inflating: data/groundTruth/P30_cam01_P30_pancake.txt  \n",
            "  inflating: data/groundTruth/P30_cam01_P30_tea.txt  \n",
            "  inflating: data/groundTruth/P30_cam02_P30_cereals.txt  \n",
            "  inflating: data/groundTruth/P30_cam02_P30_coffee.txt  \n",
            "  inflating: data/groundTruth/P30_cam02_P30_pancake.txt  \n",
            "  inflating: data/groundTruth/P30_cam02_P30_sandwich.txt  \n",
            "  inflating: data/groundTruth/P30_cam02_P30_tea.txt  \n",
            "  inflating: data/groundTruth/P30_stereo01_P30_coffee.txt  \n",
            "  inflating: data/groundTruth/P30_stereo01_P30_sandwich.txt  \n",
            "  inflating: data/groundTruth/P30_stereo01_P30_tea.txt  \n",
            "  inflating: data/groundTruth/P31_cam01_P31_cereals.txt  \n",
            "  inflating: data/groundTruth/P31_cam01_P31_coffee.txt  \n",
            "  inflating: data/groundTruth/P31_cam01_P31_pancake.txt  \n",
            "  inflating: data/groundTruth/P31_cam01_P31_sandwich.txt  \n",
            "  inflating: data/groundTruth/P31_cam01_P31_tea.txt  \n",
            "  inflating: data/groundTruth/P31_cam02_P31_cereals.txt  \n",
            "  inflating: data/groundTruth/P31_cam02_P31_coffee.txt  \n",
            "  inflating: data/groundTruth/P31_cam02_P31_pancake.txt  \n",
            "  inflating: data/groundTruth/P31_cam02_P31_sandwich.txt  \n",
            "  inflating: data/groundTruth/P31_cam02_P31_tea.txt  \n",
            "  inflating: data/groundTruth/P31_stereo01_P31_coffee.txt  \n",
            "  inflating: data/groundTruth/P31_stereo01_P31_tea.txt  \n",
            "  inflating: data/groundTruth/P32_cam01_P32_cereals.txt  \n",
            "  inflating: data/groundTruth/P32_cam01_P32_coffee.txt  \n",
            "  inflating: data/groundTruth/P32_cam01_P32_pancake.txt  \n",
            "  inflating: data/groundTruth/P32_cam01_P32_sandwich.txt  \n",
            "  inflating: data/groundTruth/P32_cam01_P32_tea.txt  \n",
            "  inflating: data/groundTruth/P32_cam02_P32_cereals.txt  \n",
            "  inflating: data/groundTruth/P32_cam02_P32_coffee.txt  \n",
            "  inflating: data/groundTruth/P32_cam02_P32_pancake.txt  \n",
            "  inflating: data/groundTruth/P32_cam02_P32_sandwich.txt  \n",
            "  inflating: data/groundTruth/P32_cam02_P32_tea.txt  \n",
            "  inflating: data/groundTruth/P32_stereo01_P32_cereals.txt  \n",
            "  inflating: data/groundTruth/P32_stereo01_P32_coffee.txt  \n",
            "  inflating: data/groundTruth/P32_stereo01_P32_sandwich.txt  \n",
            "  inflating: data/groundTruth/P32_stereo01_P32_tea.txt  \n",
            "  inflating: data/groundTruth/P33_cam01_P33_cereals.txt  \n",
            "  inflating: data/groundTruth/P33_cam01_P33_coffee.txt  \n",
            "  inflating: data/groundTruth/P33_cam01_P33_pancake.txt  \n",
            "  inflating: data/groundTruth/P33_cam01_P33_sandwich.txt  \n",
            "  inflating: data/groundTruth/P33_cam01_P33_tea.txt  \n",
            "  inflating: data/groundTruth/P33_cam02_P33_cereals.txt  \n",
            "  inflating: data/groundTruth/P33_cam02_P33_coffee.txt  \n",
            "  inflating: data/groundTruth/P33_cam02_P33_pancake.txt  \n",
            "  inflating: data/groundTruth/P33_cam02_P33_sandwich.txt  \n",
            "  inflating: data/groundTruth/P33_cam02_P33_tea.txt  \n",
            "  inflating: data/groundTruth/P33_stereo01_P33_cereals.txt  \n",
            "  inflating: data/groundTruth/P33_stereo01_P33_sandwich.txt  \n",
            "  inflating: data/groundTruth/P33_stereo01_P33_tea.txt  \n",
            "  inflating: data/groundTruth/P34_cam01_P34_cereals.txt  \n",
            "  inflating: data/groundTruth/P34_cam01_P34_coffee.txt  \n",
            "  inflating: data/groundTruth/P34_cam01_P34_sandwich.txt  \n",
            "  inflating: data/groundTruth/P34_cam01_P34_tea.txt  \n",
            "  inflating: data/groundTruth/P34_stereo01_P34_cereals.txt  \n",
            "  inflating: data/groundTruth/P34_stereo01_P34_sandwich.txt  \n",
            "  inflating: data/groundTruth/P34_stereo01_P34_tea.txt  \n",
            "  inflating: data/groundTruth/P34_webcam02_P34_cereals.txt  \n",
            "  inflating: data/groundTruth/P34_webcam02_P34_coffee.txt  \n",
            "  inflating: data/groundTruth/P34_webcam02_P34_sandwich.txt  \n",
            "  inflating: data/groundTruth/P34_webcam02_P34_tea.txt  \n",
            "  inflating: data/groundTruth/P35_cam01_P35_cereals.txt  \n",
            "  inflating: data/groundTruth/P35_cam01_P35_coffee.txt  \n",
            "  inflating: data/groundTruth/P35_cam01_P35_pancake.txt  \n",
            "  inflating: data/groundTruth/P35_cam01_P35_sandwich.txt  \n",
            "  inflating: data/groundTruth/P35_cam01_P35_tea.txt  \n",
            "  inflating: data/groundTruth/P35_cam02_P35_cereals.txt  \n",
            "  inflating: data/groundTruth/P35_cam02_P35_coffee.txt  \n",
            "  inflating: data/groundTruth/P35_cam02_P35_tea.txt  \n",
            "  inflating: data/groundTruth/P35_stereo01_P35_cereals.txt  \n",
            "  inflating: data/groundTruth/P35_stereo01_P35_coffee.txt  \n",
            "  inflating: data/groundTruth/P35_stereo01_P35_sandwich.txt  \n",
            "  inflating: data/groundTruth/P35_stereo01_P35_tea.txt  \n",
            "  inflating: data/groundTruth/P35_webcam02_P35_cereals.txt  \n",
            "  inflating: data/groundTruth/P35_webcam02_P35_coffee.txt  \n",
            "  inflating: data/groundTruth/P35_webcam02_P35_pancake.txt  \n",
            "  inflating: data/groundTruth/P35_webcam02_P35_sandwich.txt  \n",
            "  inflating: data/groundTruth/P35_webcam02_P35_tea.txt  \n",
            "  inflating: data/groundTruth/P36_cam01_P36_cereals.txt  \n",
            "  inflating: data/groundTruth/P36_cam01_P36_pancake.txt  \n",
            "  inflating: data/groundTruth/P36_cam01_P36_sandwich.txt  \n",
            "  inflating: data/groundTruth/P36_cam01_P36_tea.txt  \n",
            "  inflating: data/groundTruth/P36_stereo01_P36_cereals.txt  \n",
            "  inflating: data/groundTruth/P36_stereo01_P36_coffee.txt  \n",
            "  inflating: data/groundTruth/P36_stereo01_P36_pancake.txt  \n",
            "  inflating: data/groundTruth/P36_stereo01_P36_sandwich.txt  \n",
            "  inflating: data/groundTruth/P36_stereo01_P36_tea.txt  \n",
            "  inflating: data/groundTruth/P36_webcam01_P36_cereals.txt  \n",
            "  inflating: data/groundTruth/P36_webcam01_P36_pancake.txt  \n",
            "  inflating: data/groundTruth/P36_webcam01_P36_sandwich.txt  \n",
            "  inflating: data/groundTruth/P36_webcam01_P36_tea.txt  \n",
            "  inflating: data/groundTruth/P36_webcam02_P36_cereals.txt  \n",
            "  inflating: data/groundTruth/P36_webcam02_P36_pancake.txt  \n",
            "  inflating: data/groundTruth/P36_webcam02_P36_sandwich.txt  \n",
            "  inflating: data/groundTruth/P36_webcam02_P36_tea.txt  \n",
            "  inflating: data/groundTruth/P37_cam01_P37_cereals.txt  \n",
            "  inflating: data/groundTruth/P37_cam01_P37_coffee.txt  \n",
            "  inflating: data/groundTruth/P37_cam01_P37_pancake.txt  \n",
            "  inflating: data/groundTruth/P37_cam01_P37_sandwich.txt  \n",
            "  inflating: data/groundTruth/P37_cam01_P37_tea.txt  \n",
            "  inflating: data/groundTruth/P37_stereo01_P37_cereals.txt  \n",
            "  inflating: data/groundTruth/P37_stereo01_P37_coffee.txt  \n",
            "  inflating: data/groundTruth/P37_stereo01_P37_pancake.txt  \n",
            "  inflating: data/groundTruth/P37_stereo01_P37_sandwich.txt  \n",
            "  inflating: data/groundTruth/P37_stereo01_P37_tea.txt  \n",
            "  inflating: data/groundTruth/P37_webcam01_P37_cereals.txt  \n",
            "  inflating: data/groundTruth/P37_webcam01_P37_coffee.txt  \n",
            "  inflating: data/groundTruth/P37_webcam01_P37_pancake.txt  \n",
            "  inflating: data/groundTruth/P37_webcam01_P37_sandwich.txt  \n",
            "  inflating: data/groundTruth/P37_webcam01_P37_tea.txt  \n",
            "  inflating: data/groundTruth/P37_webcam02_P37_cereals.txt  \n",
            "  inflating: data/groundTruth/P37_webcam02_P37_coffee.txt  \n",
            "  inflating: data/groundTruth/P37_webcam02_P37_pancake.txt  \n",
            "  inflating: data/groundTruth/P37_webcam02_P37_sandwich.txt  \n",
            "  inflating: data/groundTruth/P37_webcam02_P37_tea.txt  \n",
            "  inflating: data/groundTruth/P38_cam01_P38_cereals.txt  \n",
            "  inflating: data/groundTruth/P38_cam01_P38_coffee.txt  \n",
            "  inflating: data/groundTruth/P38_cam01_P38_pancake.txt  \n",
            "  inflating: data/groundTruth/P38_cam01_P38_sandwich.txt  \n",
            "  inflating: data/groundTruth/P38_cam01_P38_tea.txt  \n",
            "  inflating: data/groundTruth/P38_stereo01_P38_cereals.txt  \n",
            "  inflating: data/groundTruth/P38_stereo01_P38_coffee.txt  \n",
            "  inflating: data/groundTruth/P38_stereo01_P38_pancake.txt  \n",
            "  inflating: data/groundTruth/P38_stereo01_P38_sandwich.txt  \n",
            "  inflating: data/groundTruth/P38_stereo01_P38_tea.txt  \n",
            "  inflating: data/groundTruth/P38_webcam01_P38_cereals.txt  \n",
            "  inflating: data/groundTruth/P38_webcam01_P38_coffee.txt  \n",
            "  inflating: data/groundTruth/P38_webcam01_P38_pancake.txt  \n",
            "  inflating: data/groundTruth/P38_webcam01_P38_sandwich.txt  \n",
            "  inflating: data/groundTruth/P38_webcam01_P38_tea.txt  \n",
            "  inflating: data/groundTruth/P38_webcam02_P38_cereals.txt  \n",
            "  inflating: data/groundTruth/P38_webcam02_P38_coffee.txt  \n",
            "  inflating: data/groundTruth/P38_webcam02_P38_pancake.txt  \n",
            "  inflating: data/groundTruth/P38_webcam02_P38_sandwich.txt  \n",
            "  inflating: data/groundTruth/P38_webcam02_P38_tea.txt  \n",
            "  inflating: data/groundTruth/P39_cam01_P39_cereals.txt  \n",
            "  inflating: data/groundTruth/P39_cam01_P39_pancake.txt  \n",
            "  inflating: data/groundTruth/P39_cam01_P39_sandwich.txt  \n",
            "  inflating: data/groundTruth/P39_cam01_P39_tea.txt  \n",
            "  inflating: data/groundTruth/P39_cam02_P39_cereals.txt  \n",
            "  inflating: data/groundTruth/P39_cam02_P39_pancake.txt  \n",
            "  inflating: data/groundTruth/P39_cam02_P39_sandwich.txt  \n",
            "  inflating: data/groundTruth/P39_cam02_P39_tea.txt  \n",
            "  inflating: data/groundTruth/P39_stereo01_P39_cereals.txt  \n",
            "  inflating: data/groundTruth/P39_stereo01_P39_coffee.txt  \n",
            "  inflating: data/groundTruth/P39_stereo01_P39_pancake.txt  \n",
            "  inflating: data/groundTruth/P39_stereo01_P39_sandwich.txt  \n",
            "  inflating: data/groundTruth/P39_stereo01_P39_tea.txt  \n",
            "  inflating: data/groundTruth/P39_webcam01_P39_cereals.txt  \n",
            "  inflating: data/groundTruth/P39_webcam01_P39_pancake.txt  \n",
            "  inflating: data/groundTruth/P39_webcam01_P39_sandwich.txt  \n",
            "  inflating: data/groundTruth/P39_webcam02_P39_cereals.txt  \n",
            "  inflating: data/groundTruth/P39_webcam02_P39_coffee.txt  \n",
            "  inflating: data/groundTruth/P39_webcam02_P39_pancake.txt  \n",
            "  inflating: data/groundTruth/P39_webcam02_P39_sandwich.txt  \n",
            "  inflating: data/groundTruth/P39_webcam02_P39_tea.txt  \n",
            "  inflating: data/groundTruth/P40_cam01_P40_cereals.txt  \n",
            "  inflating: data/groundTruth/P40_cam01_P40_pancake.txt  \n",
            "  inflating: data/groundTruth/P40_cam01_P40_sandwich.txt  \n",
            "  inflating: data/groundTruth/P40_cam02_P40_cereals.txt  \n",
            "  inflating: data/groundTruth/P40_cam02_P40_coffee.txt  \n",
            "  inflating: data/groundTruth/P40_cam02_P40_pancake.txt  \n",
            "  inflating: data/groundTruth/P40_cam02_P40_sandwich.txt  \n",
            "  inflating: data/groundTruth/P40_cam02_P40_tea.txt  \n",
            "  inflating: data/groundTruth/P40_stereo01_P40_cereals.txt  \n",
            "  inflating: data/groundTruth/P40_stereo01_P40_coffee.txt  \n",
            "  inflating: data/groundTruth/P40_stereo01_P40_sandwich.txt  \n",
            "  inflating: data/groundTruth/P40_stereo01_P40_tea.txt  \n",
            "  inflating: data/groundTruth/P40_webcam01_P40_cereals.txt  \n",
            "  inflating: data/groundTruth/P40_webcam01_P40_coffee.txt  \n",
            "  inflating: data/groundTruth/P40_webcam01_P40_pancake.txt  \n",
            "  inflating: data/groundTruth/P40_webcam01_P40_sandwich.txt  \n",
            "  inflating: data/groundTruth/P40_webcam01_P40_tea.txt  \n",
            "  inflating: data/groundTruth/P40_webcam02_P40_cereals.txt  \n",
            "  inflating: data/groundTruth/P40_webcam02_P40_coffee.txt  \n",
            "  inflating: data/groundTruth/P40_webcam02_P40_pancake.txt  \n",
            "  inflating: data/groundTruth/P40_webcam02_P40_sandwich.txt  \n",
            "  inflating: data/groundTruth/P40_webcam02_P40_tea.txt  \n",
            "  inflating: data/groundTruth/P41_cam01_P41_cereals.txt  \n",
            "  inflating: data/groundTruth/P41_cam01_P41_coffee.txt  \n",
            "  inflating: data/groundTruth/P41_cam01_P41_pancake.txt  \n",
            "  inflating: data/groundTruth/P41_cam01_P41_sandwich.txt  \n",
            "  inflating: data/groundTruth/P41_cam01_P41_tea.txt  \n",
            "  inflating: data/groundTruth/P41_cam02_P41_cereals.txt  \n",
            "  inflating: data/groundTruth/P41_cam02_P41_coffee.txt  \n",
            "  inflating: data/groundTruth/P41_cam02_P41_pancake.txt  \n",
            "  inflating: data/groundTruth/P41_cam02_P41_sandwich.txt  \n",
            "  inflating: data/groundTruth/P41_cam02_P41_tea.txt  \n",
            "  inflating: data/groundTruth/P41_stereo01_P41_cereals.txt  \n",
            "  inflating: data/groundTruth/P41_stereo01_P41_coffee.txt  \n",
            "  inflating: data/groundTruth/P41_stereo01_P41_pancake.txt  \n",
            "  inflating: data/groundTruth/P41_stereo01_P41_sandwich.txt  \n",
            "  inflating: data/groundTruth/P41_stereo01_P41_tea.txt  \n",
            "  inflating: data/groundTruth/P41_webcam01_P41_cereals.txt  \n",
            "  inflating: data/groundTruth/P41_webcam01_P41_coffee.txt  \n",
            "  inflating: data/groundTruth/P41_webcam01_P41_pancake.txt  \n",
            "  inflating: data/groundTruth/P41_webcam01_P41_sandwich.txt  \n",
            "  inflating: data/groundTruth/P41_webcam01_P41_tea.txt  \n",
            "  inflating: data/groundTruth/P41_webcam02_P41_cereals.txt  \n",
            "  inflating: data/groundTruth/P41_webcam02_P41_coffee.txt  \n",
            "  inflating: data/groundTruth/P41_webcam02_P41_pancake.txt  \n",
            "  inflating: data/groundTruth/P41_webcam02_P41_sandwich.txt  \n",
            "  inflating: data/groundTruth/P41_webcam02_P41_tea.txt  \n",
            "  inflating: data/groundTruth/P42_cam01_P42_cereals.txt  \n",
            "  inflating: data/groundTruth/P42_cam01_P42_coffee.txt  \n",
            "  inflating: data/groundTruth/P42_cam01_P42_pancake.txt  \n",
            "  inflating: data/groundTruth/P42_cam01_P42_sandwich.txt  \n",
            "  inflating: data/groundTruth/P42_cam01_P42_tea.txt  \n",
            "  inflating: data/groundTruth/P42_cam02_P42_cereals.txt  \n",
            "  inflating: data/groundTruth/P42_cam02_P42_coffee.txt  \n",
            "  inflating: data/groundTruth/P42_cam02_P42_pancake.txt  \n",
            "  inflating: data/groundTruth/P42_cam02_P42_sandwich.txt  \n",
            "  inflating: data/groundTruth/P42_cam02_P42_tea.txt  \n",
            "  inflating: data/groundTruth/P42_stereo01_P42_cereals.txt  \n",
            "  inflating: data/groundTruth/P42_stereo01_P42_coffee.txt  \n",
            "  inflating: data/groundTruth/P42_stereo01_P42_pancake.txt  \n",
            "  inflating: data/groundTruth/P42_stereo01_P42_sandwich.txt  \n",
            "  inflating: data/groundTruth/P42_stereo01_P42_tea.txt  \n",
            "  inflating: data/groundTruth/P42_webcam01_P42_cereals.txt  \n",
            "  inflating: data/groundTruth/P42_webcam01_P42_coffee.txt  \n",
            "  inflating: data/groundTruth/P42_webcam01_P42_pancake.txt  \n",
            "  inflating: data/groundTruth/P42_webcam01_P42_sandwich.txt  \n",
            "  inflating: data/groundTruth/P42_webcam01_P42_tea.txt  \n",
            "  inflating: data/groundTruth/P42_webcam02_P42_cereals.txt  \n",
            "  inflating: data/groundTruth/P42_webcam02_P42_coffee.txt  \n",
            "  inflating: data/groundTruth/P42_webcam02_P42_pancake.txt  \n",
            "  inflating: data/groundTruth/P42_webcam02_P42_sandwich.txt  \n",
            "  inflating: data/groundTruth/P42_webcam02_P42_tea.txt  \n",
            "  inflating: data/groundTruth/P43_cam02_P43_cereals.txt  \n",
            "  inflating: data/groundTruth/P43_cam02_P43_coffee.txt  \n",
            "  inflating: data/groundTruth/P43_cam02_P43_pancake.txt  \n",
            "  inflating: data/groundTruth/P43_cam02_P43_tea.txt  \n",
            "  inflating: data/groundTruth/P43_stereo01_P43_cereals.txt  \n",
            "  inflating: data/groundTruth/P43_stereo01_P43_pancake.txt  \n",
            "  inflating: data/groundTruth/P43_stereo01_P43_tea.txt  \n",
            "  inflating: data/groundTruth/P43_webcam01_P43_cereals.txt  \n",
            "  inflating: data/groundTruth/P43_webcam01_P43_coffee.txt  \n",
            "  inflating: data/groundTruth/P43_webcam01_P43_pancake.txt  \n",
            "  inflating: data/groundTruth/P43_webcam01_P43_sandwich.txt  \n",
            "  inflating: data/groundTruth/P43_webcam01_P43_tea.txt  \n",
            "  inflating: data/groundTruth/P43_webcam02_P43_cereals.txt  \n",
            "  inflating: data/groundTruth/P43_webcam02_P43_coffee.txt  \n",
            "  inflating: data/groundTruth/P43_webcam02_P43_pancake.txt  \n",
            "  inflating: data/groundTruth/P43_webcam02_P43_sandwich.txt  \n",
            "  inflating: data/groundTruth/P43_webcam02_P43_tea.txt  \n",
            "  inflating: data/groundTruth/P44_cam01_P44_cereals.txt  \n",
            "  inflating: data/groundTruth/P44_cam01_P44_coffee.txt  \n",
            "  inflating: data/groundTruth/P44_cam01_P44_pancake.txt  \n",
            "  inflating: data/groundTruth/P44_cam01_P44_sandwich.txt  \n",
            "  inflating: data/groundTruth/P44_cam01_P44_tea.txt  \n",
            "  inflating: data/groundTruth/P44_cam02_P44_cereals.txt  \n",
            "  inflating: data/groundTruth/P44_cam02_P44_coffee.txt  \n",
            "  inflating: data/groundTruth/P44_cam02_P44_pancake.txt  \n",
            "  inflating: data/groundTruth/P44_cam02_P44_sandwich.txt  \n",
            "  inflating: data/groundTruth/P44_cam02_P44_tea.txt  \n",
            "  inflating: data/groundTruth/P44_stereo01_P44_cereals.txt  \n",
            "  inflating: data/groundTruth/P44_stereo01_P44_coffee.txt  \n",
            "  inflating: data/groundTruth/P44_stereo01_P44_sandwich.txt  \n",
            "  inflating: data/groundTruth/P44_stereo01_P44_tea.txt  \n",
            "  inflating: data/groundTruth/P44_webcam01_P44_cereals.txt  \n",
            "  inflating: data/groundTruth/P44_webcam01_P44_coffee.txt  \n",
            "  inflating: data/groundTruth/P44_webcam01_P44_pancake.txt  \n",
            "  inflating: data/groundTruth/P44_webcam01_P44_sandwich.txt  \n",
            "  inflating: data/groundTruth/P44_webcam01_P44_tea.txt  \n",
            "  inflating: data/groundTruth/P44_webcam02_P44_cereals.txt  \n",
            "  inflating: data/groundTruth/P44_webcam02_P44_coffee.txt  \n",
            "  inflating: data/groundTruth/P44_webcam02_P44_pancake.txt  \n",
            "  inflating: data/groundTruth/P44_webcam02_P44_sandwich.txt  \n",
            "  inflating: data/groundTruth/P44_webcam02_P44_tea.txt  \n",
            "  inflating: data/groundTruth/P45_cam01_P45_cereals.txt  \n",
            "  inflating: data/groundTruth/P45_cam01_P45_coffee.txt  \n",
            "  inflating: data/groundTruth/P45_cam01_P45_pancake.txt  \n",
            "  inflating: data/groundTruth/P45_cam01_P45_sandwich.txt  \n",
            "  inflating: data/groundTruth/P45_cam01_P45_tea.txt  \n",
            "  inflating: data/groundTruth/P45_cam02_P45_cereals.txt  \n",
            "  inflating: data/groundTruth/P45_cam02_P45_coffee.txt  \n",
            "  inflating: data/groundTruth/P45_cam02_P45_pancake.txt  \n",
            "  inflating: data/groundTruth/P45_cam02_P45_tea.txt  \n",
            "  inflating: data/groundTruth/P45_stereo01_P45_cereals.txt  \n",
            "  inflating: data/groundTruth/P45_stereo01_P45_coffee.txt  \n",
            "  inflating: data/groundTruth/P45_webcam01_P45_cereals.txt  \n",
            "  inflating: data/groundTruth/P45_webcam01_P45_coffee.txt  \n",
            "  inflating: data/groundTruth/P45_webcam01_P45_pancake.txt  \n",
            "  inflating: data/groundTruth/P45_webcam01_P45_sandwich.txt  \n",
            "  inflating: data/groundTruth/P45_webcam01_P45_tea.txt  \n",
            "  inflating: data/groundTruth/P45_webcam02_P45_cereals.txt  \n",
            "  inflating: data/groundTruth/P45_webcam02_P45_coffee.txt  \n",
            "  inflating: data/groundTruth/P45_webcam02_P45_pancake.txt  \n",
            "  inflating: data/groundTruth/P45_webcam02_P45_sandwich.txt  \n",
            "  inflating: data/groundTruth/P45_webcam02_P45_tea.txt  \n",
            "  inflating: data/groundTruth/P46_cam01_P46_cereals.txt  \n",
            "  inflating: data/groundTruth/P46_cam01_P46_coffee.txt  \n",
            "  inflating: data/groundTruth/P46_cam01_P46_pancake.txt  \n",
            "  inflating: data/groundTruth/P46_cam01_P46_sandwich.txt  \n",
            "  inflating: data/groundTruth/P46_cam01_P46_tea.txt  \n",
            "  inflating: data/groundTruth/P46_cam02_P46_cereals.txt  \n",
            "  inflating: data/groundTruth/P46_cam02_P46_coffee.txt  \n",
            "  inflating: data/groundTruth/P46_cam02_P46_pancake.txt  \n",
            "  inflating: data/groundTruth/P46_cam02_P46_sandwich.txt  \n",
            "  inflating: data/groundTruth/P46_cam02_P46_tea.txt  \n",
            "  inflating: data/groundTruth/P46_stereo01_P46_coffee.txt  \n",
            "  inflating: data/groundTruth/P46_stereo01_P46_tea.txt  \n",
            "  inflating: data/groundTruth/P46_webcam01_P46_cereals.txt  \n",
            "  inflating: data/groundTruth/P46_webcam01_P46_coffee.txt  \n",
            "  inflating: data/groundTruth/P46_webcam01_P46_pancake.txt  \n",
            "  inflating: data/groundTruth/P46_webcam01_P46_sandwich.txt  \n",
            "  inflating: data/groundTruth/P46_webcam01_P46_tea.txt  \n",
            "  inflating: data/groundTruth/P46_webcam02_P46_cereals.txt  \n",
            "  inflating: data/groundTruth/P46_webcam02_P46_coffee.txt  \n",
            "  inflating: data/groundTruth/P46_webcam02_P46_pancake.txt  \n",
            "  inflating: data/groundTruth/P46_webcam02_P46_sandwich.txt  \n",
            "  inflating: data/groundTruth/P46_webcam02_P46_tea.txt  \n",
            "  inflating: data/groundTruth/P47_cam01_P47_cereals.txt  \n",
            "  inflating: data/groundTruth/P47_cam01_P47_coffee.txt  \n",
            "  inflating: data/groundTruth/P47_cam01_P47_pancake.txt  \n",
            "  inflating: data/groundTruth/P47_cam01_P47_sandwich.txt  \n",
            "  inflating: data/groundTruth/P47_cam01_P47_tea.txt  \n",
            "  inflating: data/groundTruth/P47_cam02_P47_cereals.txt  \n",
            "  inflating: data/groundTruth/P47_cam02_P47_coffee.txt  \n",
            "  inflating: data/groundTruth/P47_cam02_P47_pancake.txt  \n",
            "  inflating: data/groundTruth/P47_cam02_P47_sandwich.txt  \n",
            "  inflating: data/groundTruth/P47_cam02_P47_tea.txt  \n",
            "  inflating: data/groundTruth/P47_stereo01_P47_cereals.txt  \n",
            "  inflating: data/groundTruth/P47_stereo01_P47_tea.txt  \n",
            "  inflating: data/groundTruth/P47_webcam01_P47_cereals.txt  \n",
            "  inflating: data/groundTruth/P47_webcam01_P47_coffee.txt  \n",
            "  inflating: data/groundTruth/P47_webcam01_P47_pancake.txt  \n",
            "  inflating: data/groundTruth/P47_webcam01_P47_sandwich.txt  \n",
            "  inflating: data/groundTruth/P47_webcam01_P47_tea.txt  \n",
            "  inflating: data/groundTruth/P47_webcam02_P47_cereals.txt  \n",
            "  inflating: data/groundTruth/P47_webcam02_P47_coffee.txt  \n",
            "  inflating: data/groundTruth/P47_webcam02_P47_pancake.txt  \n",
            "  inflating: data/groundTruth/P47_webcam02_P47_sandwich.txt  \n",
            "  inflating: data/groundTruth/P47_webcam02_P47_tea.txt  \n",
            "  inflating: data/groundTruth/P48_cam01_P48_cereals.txt  \n",
            "  inflating: data/groundTruth/P48_cam01_P48_pancake.txt  \n",
            "  inflating: data/groundTruth/P48_cam01_P48_sandwich.txt  \n",
            "  inflating: data/groundTruth/P48_cam01_P48_tea.txt  \n",
            "  inflating: data/groundTruth/P48_cam02_P48_cereals.txt  \n",
            "  inflating: data/groundTruth/P48_cam02_P48_coffee.txt  \n",
            "  inflating: data/groundTruth/P48_cam02_P48_pancake.txt  \n",
            "  inflating: data/groundTruth/P48_cam02_P48_sandwich.txt  \n",
            "  inflating: data/groundTruth/P48_cam02_P48_tea.txt  \n",
            "  inflating: data/groundTruth/P48_stereo01_P48_cereals.txt  \n",
            "  inflating: data/groundTruth/P48_stereo01_P48_coffee.txt  \n",
            "  inflating: data/groundTruth/P48_webcam01_P48_cereals.txt  \n",
            "  inflating: data/groundTruth/P48_webcam01_P48_coffee.txt  \n",
            "  inflating: data/groundTruth/P48_webcam01_P48_pancake.txt  \n",
            "  inflating: data/groundTruth/P48_webcam01_P48_sandwich.txt  \n",
            "  inflating: data/groundTruth/P48_webcam01_P48_tea.txt  \n",
            "  inflating: data/groundTruth/P48_webcam02_P48_cereals.txt  \n",
            "  inflating: data/groundTruth/P48_webcam02_P48_coffee.txt  \n",
            "  inflating: data/groundTruth/P48_webcam02_P48_pancake.txt  \n",
            "  inflating: data/groundTruth/P48_webcam02_P48_sandwich.txt  \n",
            "  inflating: data/groundTruth/P48_webcam02_P48_tea.txt  \n",
            "  inflating: data/groundTruth/P49_cam01_P49_cereals.txt  \n",
            "  inflating: data/groundTruth/P49_cam01_P49_coffee.txt  \n",
            "  inflating: data/groundTruth/P49_cam01_P49_pancake.txt  \n",
            "  inflating: data/groundTruth/P49_cam01_P49_sandwich.txt  \n",
            "  inflating: data/groundTruth/P49_cam01_P49_tea.txt  \n",
            "  inflating: data/groundTruth/P49_cam02_P49_cereals.txt  \n",
            "  inflating: data/groundTruth/P49_cam02_P49_coffee.txt  \n",
            "  inflating: data/groundTruth/P49_cam02_P49_pancake.txt  \n",
            "  inflating: data/groundTruth/P49_cam02_P49_sandwich.txt  \n",
            "  inflating: data/groundTruth/P49_cam02_P49_tea.txt  \n",
            "  inflating: data/groundTruth/P49_stereo01_P49_cereals.txt  \n",
            "  inflating: data/groundTruth/P49_stereo01_P49_coffee.txt  \n",
            "  inflating: data/groundTruth/P49_stereo01_P49_sandwich.txt  \n",
            "  inflating: data/groundTruth/P49_stereo01_P49_tea.txt  \n",
            "  inflating: data/groundTruth/P49_webcam01_P49_cereals.txt  \n",
            "  inflating: data/groundTruth/P49_webcam01_P49_coffee.txt  \n",
            "  inflating: data/groundTruth/P49_webcam01_P49_pancake.txt  \n",
            "  inflating: data/groundTruth/P49_webcam01_P49_sandwich.txt  \n",
            "  inflating: data/groundTruth/P49_webcam01_P49_tea.txt  \n",
            "  inflating: data/groundTruth/P49_webcam02_P49_coffee.txt  \n",
            "  inflating: data/groundTruth/P49_webcam02_P49_pancake.txt  \n",
            "  inflating: data/groundTruth/P49_webcam02_P49_sandwich.txt  \n",
            "  inflating: data/groundTruth/P49_webcam02_P49_tea.txt  \n",
            "  inflating: data/groundTruth/P50_cam01_P50_cereals.txt  \n",
            "  inflating: data/groundTruth/P50_cam01_P50_coffee.txt  \n",
            "  inflating: data/groundTruth/P50_cam01_P50_pancake.txt  \n",
            "  inflating: data/groundTruth/P50_cam01_P50_sandwich.txt  \n",
            "  inflating: data/groundTruth/P50_cam01_P50_tea.txt  \n",
            "  inflating: data/groundTruth/P50_cam02_P50_cereals.txt  \n",
            "  inflating: data/groundTruth/P50_cam02_P50_coffee.txt  \n",
            "  inflating: data/groundTruth/P50_cam02_P50_pancake.txt  \n",
            "  inflating: data/groundTruth/P50_cam02_P50_sandwich.txt  \n",
            "  inflating: data/groundTruth/P50_cam02_P50_tea.txt  \n",
            "  inflating: data/groundTruth/P50_stereo01_P50_cereals.txt  \n",
            "  inflating: data/groundTruth/P50_stereo01_P50_coffee.txt  \n",
            "  inflating: data/groundTruth/P50_stereo01_P50_pancake.txt  \n",
            "  inflating: data/groundTruth/P50_stereo01_P50_sandwich.txt  \n",
            "  inflating: data/groundTruth/P50_stereo01_P50_tea.txt  \n",
            "  inflating: data/groundTruth/P50_webcam01_P50_cereals.txt  \n",
            "  inflating: data/groundTruth/P50_webcam01_P50_coffee.txt  \n",
            "  inflating: data/groundTruth/P50_webcam01_P50_pancake.txt  \n",
            "  inflating: data/groundTruth/P50_webcam01_P50_sandwich.txt  \n",
            "  inflating: data/groundTruth/P50_webcam01_P50_tea.txt  \n",
            "  inflating: data/groundTruth/P50_webcam02_P50_cereals.txt  \n",
            "  inflating: data/groundTruth/P50_webcam02_P50_coffee.txt  \n",
            "  inflating: data/groundTruth/P50_webcam02_P50_pancake.txt  \n",
            "  inflating: data/groundTruth/P50_webcam02_P50_sandwich.txt  \n",
            "  inflating: data/groundTruth/P50_webcam02_P50_tea.txt  \n",
            "  inflating: data/groundTruth/P51_cam01_P51_cereals.txt  \n",
            "  inflating: data/groundTruth/P51_cam01_P51_pancake.txt  \n",
            "  inflating: data/groundTruth/P51_cam01_P51_sandwich.txt  \n",
            "  inflating: data/groundTruth/P51_cam01_P51_tea.txt  \n",
            "  inflating: data/groundTruth/P51_cam02_P51_cereals.txt  \n",
            "  inflating: data/groundTruth/P51_cam02_P51_coffee.txt  \n",
            "  inflating: data/groundTruth/P51_cam02_P51_pancake.txt  \n",
            "  inflating: data/groundTruth/P51_cam02_P51_sandwich.txt  \n",
            "  inflating: data/groundTruth/P51_cam02_P51_tea.txt  \n",
            "  inflating: data/groundTruth/P51_stereo01_P51_cereals.txt  \n",
            "  inflating: data/groundTruth/P51_stereo01_P51_coffee.txt  \n",
            "  inflating: data/groundTruth/P51_stereo01_P51_sandwich.txt  \n",
            "  inflating: data/groundTruth/P51_stereo01_P51_tea.txt  \n",
            "  inflating: data/groundTruth/P51_webcam01_P51_cereals.txt  \n",
            "  inflating: data/groundTruth/P51_webcam01_P51_coffee.txt  \n",
            "  inflating: data/groundTruth/P51_webcam01_P51_pancake.txt  \n",
            "  inflating: data/groundTruth/P51_webcam01_P51_sandwich.txt  \n",
            "  inflating: data/groundTruth/P51_webcam01_P51_tea.txt  \n",
            "  inflating: data/groundTruth/P51_webcam02_P51_cereals.txt  \n",
            "  inflating: data/groundTruth/P51_webcam02_P51_coffee.txt  \n",
            "  inflating: data/groundTruth/P51_webcam02_P51_pancake.txt  \n",
            "  inflating: data/groundTruth/P51_webcam02_P51_sandwich.txt  \n",
            "  inflating: data/groundTruth/P51_webcam02_P51_tea.txt  \n",
            "  inflating: data/groundTruth/P52_cam01_P52_pancake.txt  \n",
            "  inflating: data/groundTruth/P52_cam01_P52_tea.txt  \n",
            "  inflating: data/groundTruth/P52_cam02_P52_cereals.txt  \n",
            "  inflating: data/groundTruth/P52_cam02_P52_coffee.txt  \n",
            "  inflating: data/groundTruth/P52_cam02_P52_pancake.txt  \n",
            "  inflating: data/groundTruth/P52_cam02_P52_tea.txt  \n",
            "  inflating: data/groundTruth/P52_stereo01_P52_cereals.txt  \n",
            "  inflating: data/groundTruth/P52_stereo01_P52_coffee.txt  \n",
            "  inflating: data/groundTruth/P52_stereo01_P52_pancake.txt  \n",
            "  inflating: data/groundTruth/P52_stereo01_P52_sandwich.txt  \n",
            "  inflating: data/groundTruth/P52_stereo01_P52_tea.txt  \n",
            "  inflating: data/groundTruth/P52_webcam01_P52_cereals.txt  \n",
            "  inflating: data/groundTruth/P52_webcam01_P52_coffee.txt  \n",
            "  inflating: data/groundTruth/P52_webcam01_P52_pancake.txt  \n",
            "  inflating: data/groundTruth/P52_webcam01_P52_sandwich.txt  \n",
            "  inflating: data/groundTruth/P52_webcam01_P52_tea.txt  \n",
            "  inflating: data/groundTruth/P52_webcam02_P52_cereals.txt  \n",
            "  inflating: data/groundTruth/P52_webcam02_P52_coffee.txt  \n",
            "  inflating: data/groundTruth/P52_webcam02_P52_pancake.txt  \n",
            "  inflating: data/groundTruth/P52_webcam02_P52_sandwich.txt  \n",
            "  inflating: data/groundTruth/P52_webcam02_P52_tea.txt  \n",
            "  inflating: data/groundTruth/P53_cam01_P53_cereals.txt  \n",
            "  inflating: data/groundTruth/P53_cam01_P53_pancake.txt  \n",
            "  inflating: data/groundTruth/P53_cam02_P53_cereals.txt  \n",
            "  inflating: data/groundTruth/P53_cam02_P53_coffee.txt  \n",
            "  inflating: data/groundTruth/P53_cam02_P53_pancake.txt  \n",
            "  inflating: data/groundTruth/P53_cam02_P53_sandwich.txt  \n",
            "  inflating: data/groundTruth/P53_cam02_P53_tea.txt  \n",
            "  inflating: data/groundTruth/P53_stereo01_P53_cereals.txt  \n",
            "  inflating: data/groundTruth/P53_stereo01_P53_coffee.txt  \n",
            "  inflating: data/groundTruth/P53_stereo01_P53_sandwich.txt  \n",
            "  inflating: data/groundTruth/P53_stereo01_P53_tea.txt  \n",
            "  inflating: data/groundTruth/P53_webcam01_P53_cereals.txt  \n",
            "  inflating: data/groundTruth/P53_webcam01_P53_coffee.txt  \n",
            "  inflating: data/groundTruth/P53_webcam01_P53_pancake.txt  \n",
            "  inflating: data/groundTruth/P53_webcam01_P53_sandwich.txt  \n",
            "  inflating: data/groundTruth/P53_webcam01_P53_tea.txt  \n",
            "  inflating: data/groundTruth/P53_webcam02_P53_cereals.txt  \n",
            "  inflating: data/groundTruth/P53_webcam02_P53_coffee.txt  \n",
            "  inflating: data/groundTruth/P53_webcam02_P53_pancake.txt  \n",
            "  inflating: data/groundTruth/P53_webcam02_P53_sandwich.txt  \n",
            "  inflating: data/groundTruth/P53_webcam02_P53_tea.txt  \n",
            "  inflating: data/groundTruth/P54_cam01_P54_cereals.txt  \n",
            "  inflating: data/groundTruth/P54_cam01_P54_pancake.txt  \n",
            "  inflating: data/groundTruth/P54_cam01_P54_sandwich.txt  \n",
            "  inflating: data/groundTruth/P54_cam02_P54_cereals.txt  \n",
            "  inflating: data/groundTruth/P54_cam02_P54_coffee.txt  \n",
            "  inflating: data/groundTruth/P54_cam02_P54_pancake.txt  \n",
            "  inflating: data/groundTruth/P54_cam02_P54_tea.txt  \n",
            "  inflating: data/groundTruth/P54_stereo01_P54_cereals.txt  \n",
            "  inflating: data/groundTruth/P54_stereo01_P54_coffee.txt  \n",
            "  inflating: data/groundTruth/P54_stereo01_P54_pancake.txt  \n",
            "  inflating: data/groundTruth/P54_stereo01_P54_sandwich.txt  \n",
            "  inflating: data/groundTruth/P54_stereo01_P54_tea.txt  \n",
            "  inflating: data/groundTruth/P54_webcam01_P54_cereals.txt  \n",
            "  inflating: data/groundTruth/P54_webcam01_P54_coffee.txt  \n",
            "  inflating: data/groundTruth/P54_webcam01_P54_pancake.txt  \n",
            "  inflating: data/groundTruth/P54_webcam01_P54_tea.txt  \n",
            "  inflating: data/groundTruth/P54_webcam02_P54_cereals.txt  \n",
            "  inflating: data/groundTruth/P54_webcam02_P54_coffee.txt  \n",
            "  inflating: data/groundTruth/P54_webcam02_P54_pancake.txt  \n",
            "  inflating: data/groundTruth/P54_webcam02_P54_sandwich.txt  \n",
            "  inflating: data/groundTruth/P54_webcam02_P54_tea.txt  \n",
            "  inflating: data/mapping.txt        \n",
            "  inflating: data/test.bundle        \n",
            "  inflating: data/train.bundle       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrRWr4dp0Ilf"
      },
      "source": [
        "import torch\n",
        "from torchvision.io.video import read_video\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import torchvision.transforms.functional as tf\n",
        "\n",
        "\n",
        "\n",
        "class TCNDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,path='/content/data' , training = True):\n",
        "        \n",
        "        self.path = path\n",
        "        # load classes mapping\n",
        "        self.class2index = {} \n",
        "        self.index2class = {}\n",
        "        classes_file = open(path+'/mapping.txt','r')\n",
        "        for line in classes_file:\n",
        "            line = line.rstrip('\\n') \n",
        "            splitted = line.split(' ')\n",
        "            self.class2index[splitted[1]] = splitted[0]\n",
        "            self.index2class[splitted[0]] = splitted[1]\n",
        "        classes_file.close()\n",
        "        \n",
        "        # load class names \n",
        "        video_list_location = '/train.bundle' if training else '/test.bundle'\n",
        "        video_list_file = open(path+video_list_location)\n",
        "        self.video_list = []\n",
        "        for line in video_list_file:\n",
        "            line = line.rstrip('\\n')\n",
        "            name = line.split('.txt')[0]\n",
        "            self.video_list.append(name)\n",
        "            \n",
        "        video_list_file.close()\n",
        "        \n",
        "        self.size = len(self.video_list)\n",
        "        self.training = training\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        video_name = self.video_list[index]\n",
        "        features = torch.from_numpy(np.load(self.path+'/features/'+video_name+'.npy'))\n",
        "        labels_file = open(self.path+'/groundTruth/'+video_name+'.txt')\n",
        "        labels = torch.zeros((features.shape[1],))\n",
        "        for idx, line in enumerate(labels_file):\n",
        "             line = line.rstrip('\\n')\n",
        "             label = self.class2index[line]\n",
        "             labels[idx] = int(label)\n",
        "        labels_file.close()\n",
        "        return features, labels\n",
        "\n",
        "                "
      ],
      "id": "OrRWr4dp0Ilf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptj-pSvC0SZM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# From figure 2 in paper\n",
        "class DilatedResidualLayer(torch.nn.Module):\n",
        "    def __init__(self, dilation_factor, in_channels, out_channels):\n",
        "        super(DilatedResidualLayer, self).__init__()\n",
        "        # padding = dilation_factor to keep size \n",
        "        self.block =  nn.Sequential(  nn.Conv1d(in_channels, out_channels, 3, padding=dilation_factor, dilation=dilation_factor),\n",
        "                                      nn.ReLU(inplace = True),\n",
        "                                      nn.Conv1d(out_channels, out_channels, 1)\n",
        "                                      )\n",
        "    def forward(self,x, mask):\n",
        "        return (self.block(x) + x )* mask[:, 0:1, :]\n",
        "\n",
        "    \n",
        "\n",
        "class TCN(torch.nn.Module):\n",
        "    def __init__(self, num_layers = 10, num_f_maps=64, dim = 2048, num_classes = 48):\n",
        "        super(TCN, self).__init__()\n",
        "        self.conv_1x1 = nn.Conv1d(dim, num_f_maps, 1)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            # linear increasing of number dilation using i+1\n",
        "            layer = DilatedResidualLayer(i+1, num_f_maps, num_f_maps)\n",
        "            self.layers.append(layer)\n",
        "        self.last_conv = nn.Conv1d(num_f_maps, num_classes, 1)\n",
        "\n",
        "    def forward(self, x , mask):\n",
        "        out = self.conv_1x1(x)\n",
        "        for layer in self.layers:\n",
        "            out = layer(out,mask)\n",
        "        out = self.last_conv(out)  * mask[:, 0:1, :]\n",
        "        return out\n",
        "    \n",
        "    \n",
        "class MultiStageTCN(torch.nn.Module):\n",
        "    def __init__(self, num_stages = 4, num_layers = 10, num_f_maps=64, dim = 2048, num_classes = 48):\n",
        "        super(MultiStageTCN, self).__init__()\n",
        "        self.first_TCN = TCN(num_layers, num_f_maps, dim, num_classes)\n",
        "        self.TCNs = nn.ModuleList()\n",
        "        for i in range(num_layers-1):\n",
        "            tcn =  TCN(num_layers, num_f_maps, num_classes + dim, num_classes)\n",
        "            self.TCNs.append(tcn)\n",
        "        self.last_TCN =  TCN(num_layers, num_f_maps, num_classes + dim, num_classes)\n",
        "\n",
        "    def forward(self, x , mask):\n",
        "        out = self.first_TCN(x,mask)   \n",
        "        out = torch.cat((x, out), dim=1)\n",
        "        #out_wrapped = out.unsqueeze(0)\n",
        "        for stage in self.TCNs:\n",
        "            out = stage(out,mask)\n",
        "            out = F.softmax(out, dim=1)   \n",
        "            out = torch.cat((x, out), dim=1)\n",
        "            out = stage( out* mask[:, 0:1, :], mask)\n",
        "            out = torch.cat((x, out), dim=1)\n",
        "            #out_wrapped = torch.cat((out_wrapped, out.unsqueeze(0)), dim=0)\n",
        "        out = self.last_TCN(out,mask)   \n",
        "        #out_wrapped = torch.cat((out_wrapped, out.unsqueeze(0)), dim=0)\n",
        "        return out\n",
        "    \n",
        "\n",
        "# For question 4, supporting down and upsampling  \n",
        "class SampledTCN(torch.nn.Module):\n",
        "    def __init__(self, sampling_factor, num_layers = 10, num_f_maps=64, dim = 2048, num_classes = 48 ):\n",
        "        super(SampledTCN, self).__init__()\n",
        "        # we downsamble using convolutions \n",
        "        self.downsamble_conv = nn.Conv1d(dim, dim//sampling_factor, 1)\n",
        "        self.conv_1x1 = nn.Conv1d(dim//sampling_factor, num_f_maps, 1)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            layer = DilatedResidualLayer(i+1, num_f_maps, num_f_maps)\n",
        "            self.layers.append(layer)\n",
        "        self.upsample_conv = nn.Conv1d(num_f_maps, dim, 1)\n",
        "\n",
        "    def forward(self, x , mask):\n",
        "        out = self.downsamble_conv(x)\n",
        "        out = self.conv_1x1(out)\n",
        "        for layer in self.layers:\n",
        "            out = layer(out,mask)\n",
        "        out = self.upsample_conv(out) * mask[:, 0:1, :]\n",
        "        return out\n",
        "    \n",
        "    \n",
        "    \n",
        "class ParallelTCNs(torch.nn.Module):\n",
        "        def __init__(self, num_layers = 10, num_f_maps=64, dim = 2048, num_classes = 48):\n",
        "            super(ParallelTCNs, self).__init__()\n",
        "            self.TCN1 = SampledTCN(1, num_layers, num_f_maps, dim, num_classes)\n",
        "            # scale reduced with factor 4 2048 -> 512\n",
        "            self.TCN2 = SampledTCN(4, num_layers, num_f_maps, dim, num_classes)\n",
        "             # scale reduced with factor 8 2048 -> 256\n",
        "            self.TCN3 = SampledTCN(8, num_layers, num_f_maps, dim, num_classes)\n",
        "            \n",
        "            self.prediction_conv1 = nn.Conv1d(dim, num_classes, 1)\n",
        "            self.prediction_conv2 = nn.Conv1d(dim, num_classes, 1)\n",
        "            self.prediction_conv3 = nn.Conv1d(dim, num_classes, 1)\n",
        "\n",
        "            self.prediction_conv_average = nn.Conv1d(dim, num_classes, 1)\n",
        "            \n",
        "            \n",
        "        def forward(self, x, mask):\n",
        "            out1 = self.TCN1(x,mask)\n",
        "            out2 = self.TCN2(x,mask)\n",
        "            out3 = self.TCN3(x,mask)\n",
        "            \n",
        "            average_out = torch.mean(torch.stack([out1,out2,out3]) , dim = 0)\n",
        "            out1 = self.prediction_conv1(out1) * mask[:, 0:1, :]\n",
        "            out2 = self.prediction_conv2(out2) * mask[:, 0:1, :]\n",
        "            out3 = self.prediction_conv3(out3) * mask[:, 0:1, :]\n",
        "            average_out = self.prediction_conv_average(average_out) * mask[:, 0:1, :]\n",
        "            return out1 , out2 , out3 , average_out\n",
        "            \n",
        "            \n",
        "\n"
      ],
      "id": "ptj-pSvC0SZM",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfezvc6K0Wmw"
      },
      "source": [
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "def get_labels_start_end_time(frame_wise_labels, bg_class=[\"SIL\"]):\n",
        "    labels = []\n",
        "    starts = []\n",
        "    ends = []\n",
        "    last_label = frame_wise_labels[0]\n",
        "    if frame_wise_labels[0] not in bg_class:\n",
        "        labels.append(frame_wise_labels[0])\n",
        "        starts.append(0)\n",
        "    for i in range(len(frame_wise_labels)):\n",
        "        if frame_wise_labels[i] != last_label:\n",
        "            if frame_wise_labels[i] not in bg_class:\n",
        "                labels.append(frame_wise_labels[i])\n",
        "                starts.append(i)\n",
        "            if last_label not in bg_class:\n",
        "                ends.append(i)\n",
        "            last_label = frame_wise_labels[i]\n",
        "    if last_label not in bg_class:\n",
        "        ends.append(i + 1)\n",
        "    return labels, starts, ends\n",
        "\n",
        "\n",
        "def levenstein(p, y, norm=False):\n",
        "    m_row = len(p)    \n",
        "    n_col = len(y)\n",
        "    D = np.zeros([m_row+1, n_col+1], np.float64)\n",
        "    for i in range(m_row+1):\n",
        "        D[i, 0] = i\n",
        "    for i in range(n_col+1):\n",
        "        D[0, i] = i\n",
        "\n",
        "    for j in range(1, n_col+1):\n",
        "        for i in range(1, m_row+1):\n",
        "            if y[j-1] == p[i-1]:\n",
        "                D[i, j] = D[i-1, j-1]\n",
        "            else:\n",
        "                D[i, j] = min(D[i-1, j] + 1,\n",
        "                              D[i, j-1] + 1,\n",
        "                              D[i-1, j-1] + 1)\n",
        "    \n",
        "    if norm:\n",
        "        score = (1 - D[-1, -1]/max(m_row, n_col)) * 100\n",
        "    else:\n",
        "        score = D[-1, -1]\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def edit_score(recognized, ground_truth, norm=True, bg_class=[\"SIL\"]):\n",
        "    P, _, _ = get_labels_start_end_time(recognized, bg_class)\n",
        "    Y, _, _ = get_labels_start_end_time(ground_truth, bg_class)\n",
        "    return levenstein(P, Y, norm)\n",
        "\n",
        "\n",
        "def f_score(recognized, ground_truth, overlap, bg_class=[\"SIL\"]):\n",
        "    p_label, p_start, p_end = get_labels_start_end_time(recognized, bg_class)\n",
        "    y_label, y_start, y_end = get_labels_start_end_time(ground_truth, bg_class)\n",
        "\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "\n",
        "    hits = np.zeros(len(y_label))\n",
        "\n",
        "    for j in range(len(p_label)):\n",
        "        intersection = np.minimum(p_end[j], y_end) - np.maximum(p_start[j], y_start)\n",
        "        union = np.maximum(p_end[j], y_end) - np.minimum(p_start[j], y_start)\n",
        "        IoU = (1.0*intersection / union)*([p_label[j] == y_label[x] for x in range(len(y_label))])\n",
        "        # Get the best scoring segment\n",
        "        idx = np.array(IoU).argmax()\n",
        "\n",
        "        if IoU[idx] >= overlap and not hits[idx]:\n",
        "            tp += 1\n",
        "            hits[idx] = 1\n",
        "        else:\n",
        "            fp += 1\n",
        "    fn = len(y_label) - sum(hits)\n",
        "    return float(tp), float(fp), float(fn)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def read_file(path):\n",
        "    with open(path, 'r') as f:\n",
        "        content = f.read()\n",
        "        f.close()\n",
        "    return content\n",
        "\n",
        "\n",
        "def get_results(model,features, labels, masks): # Input  = features, labels and masks for 1 image\n",
        "    _,_,_,out = model(features,masks)\n",
        "    out_hot = torch.max(out,1).indices #?? Should we apply softmax first?\n",
        "    recog_content = out_hot.cpu().numpy()\n",
        "    recog_content = recog_content.reshape(recog_content.shape[1])\n",
        "    gt_content = labels.cpu().numpy()\n",
        "    gt_content = gt_content.reshape(gt_content.shape[1])\n",
        "    return(gt_content,recog_content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def eval_(model, test_dataloader):# Batch size 1\n",
        "    model.eval()\n",
        "    recog_path = sys.argv[1] # pass the path of the directory that contains your predictions as a command line parameter\n",
        "    ground_truth_path = \"/content/data/groundTruth/\"\n",
        "    file_list = \"/content/data/test.bundle\"\n",
        "\n",
        "    list_of_videos = read_file(file_list).split('\\n')[:-1]\n",
        "    \n",
        "    overlap = [.1, .25, .5]\n",
        "    tp, fp, fn = np.zeros(3), np.zeros(3), np.zeros(3)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    edit = 0\n",
        "    \n",
        "    for features, labels, masks in test_dataloader:\n",
        "        features, labels, masks = features.cuda(), labels.cuda(), masks.cuda()\n",
        "        gt_content,recog_content = get_results(model,features, labels, masks)\n",
        "        \n",
        "        for i in range(len(gt_content)):\n",
        "            total += 1\n",
        "            if gt_content[i] == recog_content[i]:\n",
        "                correct += 1\n",
        "        \n",
        "        edit += edit_score(recog_content, gt_content)\n",
        "\n",
        "        for s in range(len(overlap)):\n",
        "            tp1, fp1, fn1 = f_score(recog_content, gt_content, overlap[s])\n",
        "            tp[s] += tp1\n",
        "            fp[s] += fp1\n",
        "            fn[s] += fn1\n",
        "\n",
        "    print (\"Acc: %.4f\" % (100*float(correct)/total))\n",
        "    print ('Edit: %.4f' % ((1.0*edit)/len(list_of_videos)))\n",
        "\n",
        "    for s in range(len(overlap)):\n",
        "        precision = tp[s] / float(tp[s]+fp[s])\n",
        "        recall = tp[s] / float(tp[s]+fn[s])\n",
        "\n",
        "        f1 = 2.0 * (precision*recall) / (precision+recall)\n",
        "\n",
        "        f1 = np.nan_to_num(f1)*100\n",
        "        print ('F1@%0.2f: %.4f' % (overlap[s], f1))\n",
        "\n"
      ],
      "id": "dfezvc6K0Wmw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "928d8edc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "    \n",
        "def train_parallel(model, dataloader,optimizer):\n",
        "    model.train()\n",
        "    i=0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    running_loss = 0 \n",
        "    for features, labels, masks in dataloader:\n",
        "        features , labels , masks = features.cuda() , labels.cuda() , masks.cuda()\n",
        "        out1, out2, out3 ,out_average = model(features,masks)\n",
        "        optimizer.zero_grad()\n",
        "        loss1 = criterion(out1, labels)\n",
        "        loss2 = criterion(out2, labels)\n",
        "        loss3 = criterion(out3, labels)\n",
        "        loss_average = criterion(out_average, labels)\n",
        "        loss = loss1 + loss2 + loss3 + loss_average\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 10 == 0:\n",
        "                print(\"    Batch {}: combined loss = {} , average loss: {}\".format(i ,loss.item(), loss.item()/4 ))\n",
        "        i += 1\n",
        "        running_loss = loss.item()\n",
        "    return running_loss / len(dataloader)\n",
        "\n",
        "\n",
        "\n",
        "# function for zero padding for dataloader because of variable video length\n",
        "# inspired by the code from the paper\n",
        "def collate_fn_padd(batch):\n",
        "        batch_input , batch_target = [list(t) for t in zip(*batch)] \n",
        "        length_of_sequences = list(map(len, batch_target))\n",
        "        batch_input_tensor = torch.zeros(len(batch_input), np.shape(batch_input[0])[0], max(length_of_sequences), dtype=torch.float)\n",
        "        \n",
        "        batch_target_tensor = torch.ones(len(batch_input), max(length_of_sequences), dtype=torch.long)*(-100)\n",
        "        \n",
        "        mask = torch.zeros(len(batch_input), num_classes, max(length_of_sequences), dtype=torch.float)\n",
        "        \n",
        "        for i in range(len(batch_input)):\n",
        "            batch_input_tensor[i, :, :np.shape(batch_input[i])[1]] = batch_input[i]\n",
        "            \n",
        "            batch_target_tensor[i, :np.shape(batch_target[i])[0]] = batch_target[i]\n",
        "            \n",
        "            mask[i, :, :np.shape(batch_target[i])[0]] = torch.ones(num_classes, batch_target[i].shape[0])\n",
        "            \n",
        "        return batch_input_tensor, batch_target_tensor, mask\n",
        "            \n",
        "            \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 4\n",
        "epochs = 50\n",
        "num_classes = 48\n",
        "\n",
        "\n",
        "# DATA LOADERS \n",
        "\n",
        "training_dataset = TCNDataset(training=True)\n",
        "training_dataloader = torch.utils.data.DataLoader(training_dataset,collate_fn=collate_fn_padd,  batch_size=batch_size, shuffle=True, drop_last=False)"
      ],
      "id": "928d8edc",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23389ea0"
      },
      "source": [
        "parallel_TCNs = ParallelTCNs().cuda()\n",
        "parallel_TCNs_optimizer = torch.optim.Adam(parallel_TCNs.parameters(),lr=0.001)"
      ],
      "id": "23389ea0",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5556da3a"
      },
      "source": [
        "training_accuracy_dataloader = torch.utils.data.DataLoader(training_dataset,collate_fn=collate_fn_padd,  batch_size=1, shuffle=False, drop_last=False)\n",
        "\n",
        "test_dataset = TCNDataset(training=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,collate_fn=collate_fn_padd,  batch_size=1, shuffle=False, drop_last=False)"
      ],
      "id": "5556da3a",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b12bbe4d",
        "outputId": "6071a4ae-4067-4020-d806-0eae7756a998"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    print(\"RUNNING EPOCH: {}\".format(epoch+1))\n",
        "    train_parallel(parallel_TCNs,training_dataloader , parallel_TCNs_optimizer )\n",
        "    print(\"ACCURACY ON TRAINING AFTER EPOCH: {}\".format(epoch+1))\n",
        "    eval_(parallel_TCNs,training_accuracy_dataloader)\n",
        "    print(\"EVALUATION AFTER EPOCH: {}\".format(epoch+1))\n",
        "    eval_(parallel_TCNs,test_dataloader)\n",
        "    torch.save(parallel_TCNs, \"./parallel_model_after_epoch_{}\".format(epoch))"
      ],
      "id": "b12bbe4d",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RUNNING EPOCH: 1\n",
            "    Batch 0: combined loss = 12.640819549560547 , average loss: 3.1602048873901367\n",
            "    Batch 10: combined loss = 8.527698516845703 , average loss: 2.131924629211426\n",
            "    Batch 20: combined loss = 12.125816345214844 , average loss: 3.031454086303711\n",
            "    Batch 30: combined loss = 9.351282119750977 , average loss: 2.337820529937744\n",
            "    Batch 40: combined loss = 7.981199264526367 , average loss: 1.9952998161315918\n",
            "    Batch 50: combined loss = 10.48235034942627 , average loss: 2.6205875873565674\n",
            "    Batch 60: combined loss = 11.183212280273438 , average loss: 2.7958030700683594\n",
            "    Batch 70: combined loss = 9.450632095336914 , average loss: 2.3626580238342285\n",
            "    Batch 80: combined loss = 15.732348442077637 , average loss: 3.933087110519409\n",
            "    Batch 90: combined loss = 9.579380989074707 , average loss: 2.3948452472686768\n",
            "    Batch 100: combined loss = 8.536373138427734 , average loss: 2.1340932846069336\n",
            "    Batch 110: combined loss = 8.846992492675781 , average loss: 2.2117481231689453\n",
            "    Batch 120: combined loss = 12.562055587768555 , average loss: 3.1405138969421387\n",
            "    Batch 130: combined loss = 8.76224136352539 , average loss: 2.1905603408813477\n",
            "    Batch 140: combined loss = 7.617288589477539 , average loss: 1.9043221473693848\n",
            "    Batch 150: combined loss = 10.864870071411133 , average loss: 2.716217517852783\n",
            "    Batch 160: combined loss = 8.301913261413574 , average loss: 2.0754783153533936\n",
            "    Batch 170: combined loss = 9.642281532287598 , average loss: 2.4105703830718994\n",
            "    Batch 180: combined loss = 8.461343765258789 , average loss: 2.1153359413146973\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 1\n",
            "Acc: 45.9733\n",
            "Edit: 29.6481\n",
            "F1@0.10: 3.4027\n",
            "F1@0.25: 2.1816\n",
            "F1@0.50: 0.9100\n",
            "EVALUATION AFTER EPOCH: 1\n",
            "Acc: 45.5635\n",
            "Edit: 5.3851\n",
            "F1@0.10: 3.5869\n",
            "F1@0.25: 2.3603\n",
            "F1@0.50: 1.2059\n",
            "RUNNING EPOCH: 2\n",
            "    Batch 0: combined loss = 6.215135097503662 , average loss: 1.5537837743759155\n",
            "    Batch 10: combined loss = 7.327828884124756 , average loss: 1.831957221031189\n",
            "    Batch 20: combined loss = 8.212760925292969 , average loss: 2.053190231323242\n",
            "    Batch 30: combined loss = 8.814546585083008 , average loss: 2.203636646270752\n",
            "    Batch 40: combined loss = 6.165671348571777 , average loss: 1.5414178371429443\n",
            "    Batch 50: combined loss = 6.8168721199035645 , average loss: 1.7042180299758911\n",
            "    Batch 60: combined loss = 7.534792900085449 , average loss: 1.8836982250213623\n",
            "    Batch 70: combined loss = 6.918954372406006 , average loss: 1.7297385931015015\n",
            "    Batch 80: combined loss = 7.676413536071777 , average loss: 1.9191033840179443\n",
            "    Batch 90: combined loss = 11.938098907470703 , average loss: 2.984524726867676\n",
            "    Batch 100: combined loss = 7.1512131690979 , average loss: 1.787803292274475\n",
            "    Batch 110: combined loss = 7.842906951904297 , average loss: 1.9607267379760742\n",
            "    Batch 120: combined loss = 9.42146110534668 , average loss: 2.35536527633667\n",
            "    Batch 130: combined loss = 7.517945766448975 , average loss: 1.8794864416122437\n",
            "    Batch 140: combined loss = 8.339917182922363 , average loss: 2.084979295730591\n",
            "    Batch 150: combined loss = 9.713254928588867 , average loss: 2.428313732147217\n",
            "    Batch 160: combined loss = 11.032430648803711 , average loss: 2.7581076622009277\n",
            "    Batch 170: combined loss = 9.482280731201172 , average loss: 2.370570182800293\n",
            "    Batch 180: combined loss = 6.927030563354492 , average loss: 1.731757640838623\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 2\n",
            "Acc: 50.7763\n",
            "Edit: 23.6038\n",
            "F1@0.10: 3.1639\n",
            "F1@0.25: 1.9964\n",
            "F1@0.50: 0.9378\n",
            "EVALUATION AFTER EPOCH: 2\n",
            "Acc: 47.2578\n",
            "Edit: 3.6263\n",
            "F1@0.10: 2.8417\n",
            "F1@0.25: 1.8212\n",
            "F1@0.50: 0.8242\n",
            "RUNNING EPOCH: 3\n",
            "    Batch 0: combined loss = 10.808008193969727 , average loss: 2.7020020484924316\n",
            "    Batch 10: combined loss = 5.600768089294434 , average loss: 1.4001920223236084\n",
            "    Batch 20: combined loss = 5.3074469566345215 , average loss: 1.3268617391586304\n",
            "    Batch 30: combined loss = 5.278392791748047 , average loss: 1.3195981979370117\n",
            "    Batch 40: combined loss = 8.191747665405273 , average loss: 2.0479369163513184\n",
            "    Batch 50: combined loss = 9.013659477233887 , average loss: 2.2534148693084717\n",
            "    Batch 60: combined loss = 8.921022415161133 , average loss: 2.230255603790283\n",
            "    Batch 70: combined loss = 7.510199069976807 , average loss: 1.8775497674942017\n",
            "    Batch 80: combined loss = 7.139060020446777 , average loss: 1.7847650051116943\n",
            "    Batch 90: combined loss = 10.25013256072998 , average loss: 2.562533140182495\n",
            "    Batch 100: combined loss = 6.761998653411865 , average loss: 1.6904996633529663\n",
            "    Batch 110: combined loss = 6.516659259796143 , average loss: 1.6291648149490356\n",
            "    Batch 120: combined loss = 6.744111061096191 , average loss: 1.6860277652740479\n",
            "    Batch 130: combined loss = 10.393119812011719 , average loss: 2.5982799530029297\n",
            "    Batch 140: combined loss = 7.966231346130371 , average loss: 1.9915578365325928\n",
            "    Batch 150: combined loss = 9.673074722290039 , average loss: 2.4182686805725098\n",
            "    Batch 160: combined loss = 8.794170379638672 , average loss: 2.198542594909668\n",
            "    Batch 170: combined loss = 8.250572204589844 , average loss: 2.062643051147461\n",
            "    Batch 180: combined loss = 7.519251823425293 , average loss: 1.8798129558563232\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 3\n",
            "Acc: 52.6721\n",
            "Edit: 23.6320\n",
            "F1@0.10: 3.2893\n",
            "F1@0.25: 2.0698\n",
            "F1@0.50: 0.9273\n",
            "EVALUATION AFTER EPOCH: 3\n",
            "Acc: 49.6077\n",
            "Edit: 3.7658\n",
            "F1@0.10: 2.9761\n",
            "F1@0.25: 1.7825\n",
            "F1@0.50: 0.8324\n",
            "RUNNING EPOCH: 4\n",
            "    Batch 0: combined loss = 7.349916934967041 , average loss: 1.8374792337417603\n",
            "    Batch 10: combined loss = 5.336334705352783 , average loss: 1.3340836763381958\n",
            "    Batch 20: combined loss = 6.52789831161499 , average loss: 1.6319745779037476\n",
            "    Batch 30: combined loss = 10.27772045135498 , average loss: 2.569430112838745\n",
            "    Batch 40: combined loss = 7.494787693023682 , average loss: 1.8736969232559204\n",
            "    Batch 50: combined loss = 8.058003425598145 , average loss: 2.014500856399536\n",
            "    Batch 60: combined loss = 5.697453498840332 , average loss: 1.424363374710083\n",
            "    Batch 70: combined loss = 7.896624565124512 , average loss: 1.974156141281128\n",
            "    Batch 80: combined loss = 7.3925089836120605 , average loss: 1.8481272459030151\n",
            "    Batch 90: combined loss = 7.055703639984131 , average loss: 1.7639259099960327\n",
            "    Batch 100: combined loss = 7.7091875076293945 , average loss: 1.9272968769073486\n",
            "    Batch 110: combined loss = 9.781414031982422 , average loss: 2.4453535079956055\n",
            "    Batch 120: combined loss = 6.314716815948486 , average loss: 1.5786792039871216\n",
            "    Batch 130: combined loss = 6.031869888305664 , average loss: 1.507967472076416\n",
            "    Batch 140: combined loss = 6.015581130981445 , average loss: 1.5038952827453613\n",
            "    Batch 150: combined loss = 6.2365570068359375 , average loss: 1.5591392517089844\n",
            "    Batch 160: combined loss = 9.876947402954102 , average loss: 2.4692368507385254\n",
            "    Batch 170: combined loss = 7.461761951446533 , average loss: 1.8654404878616333\n",
            "    Batch 180: combined loss = 3.961337089538574 , average loss: 0.9903342723846436\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 4\n",
            "Acc: 53.0250\n",
            "Edit: 29.8820\n",
            "F1@0.10: 3.8443\n",
            "F1@0.25: 2.7703\n",
            "F1@0.50: 1.4511\n",
            "EVALUATION AFTER EPOCH: 4\n",
            "Acc: 45.0634\n",
            "Edit: 3.9232\n",
            "F1@0.10: 3.3131\n",
            "F1@0.25: 2.2033\n",
            "F1@0.50: 1.0445\n",
            "RUNNING EPOCH: 5\n",
            "    Batch 0: combined loss = 7.587099075317383 , average loss: 1.8967747688293457\n",
            "    Batch 10: combined loss = 6.966657638549805 , average loss: 1.7416644096374512\n",
            "    Batch 20: combined loss = 7.605999946594238 , average loss: 1.9014999866485596\n",
            "    Batch 30: combined loss = 9.861001968383789 , average loss: 2.4652504920959473\n",
            "    Batch 40: combined loss = 9.040424346923828 , average loss: 2.260106086730957\n",
            "    Batch 50: combined loss = 8.673073768615723 , average loss: 2.1682684421539307\n",
            "    Batch 60: combined loss = 4.596794128417969 , average loss: 1.1491985321044922\n",
            "    Batch 70: combined loss = 9.36214828491211 , average loss: 2.3405370712280273\n",
            "    Batch 80: combined loss = 7.189180850982666 , average loss: 1.7972952127456665\n",
            "    Batch 90: combined loss = 9.17121696472168 , average loss: 2.29280424118042\n",
            "    Batch 100: combined loss = 7.761247634887695 , average loss: 1.9403119087219238\n",
            "    Batch 110: combined loss = 11.416085243225098 , average loss: 2.8540213108062744\n",
            "    Batch 120: combined loss = 8.415203094482422 , average loss: 2.1038007736206055\n",
            "    Batch 130: combined loss = 7.129913806915283 , average loss: 1.7824784517288208\n",
            "    Batch 140: combined loss = 8.900662422180176 , average loss: 2.225165605545044\n",
            "    Batch 150: combined loss = 6.625709533691406 , average loss: 1.6564273834228516\n",
            "    Batch 160: combined loss = 6.883736610412598 , average loss: 1.7209341526031494\n",
            "    Batch 170: combined loss = 9.959394454956055 , average loss: 2.4898486137390137\n",
            "    Batch 180: combined loss = 6.080554008483887 , average loss: 1.5201385021209717\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 5\n",
            "Acc: 52.6877\n",
            "Edit: 24.9637\n",
            "F1@0.10: 3.1886\n",
            "F1@0.25: 1.9297\n",
            "F1@0.50: 0.8774\n",
            "EVALUATION AFTER EPOCH: 5\n",
            "Acc: 50.0249\n",
            "Edit: 4.1730\n",
            "F1@0.10: 3.1658\n",
            "F1@0.25: 1.7176\n",
            "F1@0.50: 0.7325\n",
            "RUNNING EPOCH: 6\n",
            "    Batch 0: combined loss = 9.206803321838379 , average loss: 2.3017008304595947\n",
            "    Batch 10: combined loss = 6.112717151641846 , average loss: 1.5281792879104614\n",
            "    Batch 20: combined loss = 6.25261116027832 , average loss: 1.56315279006958\n",
            "    Batch 30: combined loss = 5.192996978759766 , average loss: 1.2982492446899414\n",
            "    Batch 40: combined loss = 9.038448333740234 , average loss: 2.2596120834350586\n",
            "    Batch 50: combined loss = 9.12356185913086 , average loss: 2.280890464782715\n",
            "    Batch 60: combined loss = 8.102371215820312 , average loss: 2.025592803955078\n",
            "    Batch 70: combined loss = 6.290492057800293 , average loss: 1.5726230144500732\n",
            "    Batch 80: combined loss = 7.541843414306641 , average loss: 1.8854608535766602\n",
            "    Batch 90: combined loss = 7.396442413330078 , average loss: 1.8491106033325195\n",
            "    Batch 100: combined loss = 6.862607002258301 , average loss: 1.7156517505645752\n",
            "    Batch 110: combined loss = 10.86913013458252 , average loss: 2.71728253364563\n",
            "    Batch 120: combined loss = 8.463976860046387 , average loss: 2.1159942150115967\n",
            "    Batch 130: combined loss = 8.307662010192871 , average loss: 2.0769155025482178\n",
            "    Batch 140: combined loss = 8.153671264648438 , average loss: 2.0384178161621094\n",
            "    Batch 150: combined loss = 8.065908432006836 , average loss: 2.016477108001709\n",
            "    Batch 160: combined loss = 7.248453617095947 , average loss: 1.8121134042739868\n",
            "    Batch 170: combined loss = 5.827815532684326 , average loss: 1.4569538831710815\n",
            "    Batch 180: combined loss = 8.437583923339844 , average loss: 2.109395980834961\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 6\n",
            "Acc: 45.8806\n",
            "Edit: 35.9985\n",
            "F1@0.10: 3.5269\n",
            "F1@0.25: 2.5561\n",
            "F1@0.50: 1.4439\n",
            "EVALUATION AFTER EPOCH: 6\n",
            "Acc: 38.1733\n",
            "Edit: 5.1079\n",
            "F1@0.10: 3.0768\n",
            "F1@0.25: 2.2527\n",
            "F1@0.50: 1.2980\n",
            "RUNNING EPOCH: 7\n",
            "    Batch 0: combined loss = 8.438836097717285 , average loss: 2.1097090244293213\n",
            "    Batch 10: combined loss = 6.129026889801025 , average loss: 1.5322567224502563\n",
            "    Batch 20: combined loss = 7.123421669006348 , average loss: 1.780855417251587\n",
            "    Batch 30: combined loss = 6.641981601715088 , average loss: 1.660495400428772\n",
            "    Batch 40: combined loss = 5.592966079711914 , average loss: 1.3982415199279785\n",
            "    Batch 50: combined loss = 4.85943078994751 , average loss: 1.2148576974868774\n",
            "    Batch 60: combined loss = 9.361420631408691 , average loss: 2.340355157852173\n",
            "    Batch 70: combined loss = 6.741348743438721 , average loss: 1.6853371858596802\n",
            "    Batch 80: combined loss = 5.13395881652832 , average loss: 1.28348970413208\n",
            "    Batch 90: combined loss = 4.653541564941406 , average loss: 1.1633853912353516\n",
            "    Batch 100: combined loss = 8.515264511108398 , average loss: 2.1288161277770996\n",
            "    Batch 110: combined loss = 9.01312255859375 , average loss: 2.2532806396484375\n",
            "    Batch 120: combined loss = 4.866585731506348 , average loss: 1.216646432876587\n",
            "    Batch 130: combined loss = 6.0772175788879395 , average loss: 1.5193043947219849\n",
            "    Batch 140: combined loss = 7.219024658203125 , average loss: 1.8047561645507812\n",
            "    Batch 150: combined loss = 5.866881370544434 , average loss: 1.4667203426361084\n",
            "    Batch 160: combined loss = 3.042529821395874 , average loss: 0.7606324553489685\n",
            "    Batch 170: combined loss = 5.936971664428711 , average loss: 1.4842429161071777\n",
            "    Batch 180: combined loss = 5.735392093658447 , average loss: 1.4338480234146118\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 7\n",
            "Acc: 55.8267\n",
            "Edit: 27.9632\n",
            "F1@0.10: 3.9279\n",
            "F1@0.25: 2.7440\n",
            "F1@0.50: 1.4560\n",
            "EVALUATION AFTER EPOCH: 7\n",
            "Acc: 43.4334\n",
            "Edit: 4.0882\n",
            "F1@0.10: 3.1728\n",
            "F1@0.25: 2.0668\n",
            "F1@0.50: 0.9125\n",
            "RUNNING EPOCH: 8\n",
            "    Batch 0: combined loss = 8.053922653198242 , average loss: 2.0134806632995605\n",
            "    Batch 10: combined loss = 5.352318286895752 , average loss: 1.338079571723938\n",
            "    Batch 20: combined loss = 6.165330410003662 , average loss: 1.5413326025009155\n",
            "    Batch 30: combined loss = 6.252237319946289 , average loss: 1.5630593299865723\n",
            "    Batch 40: combined loss = 4.805423259735107 , average loss: 1.2013558149337769\n",
            "    Batch 50: combined loss = 5.562991142272949 , average loss: 1.3907477855682373\n",
            "    Batch 60: combined loss = 7.529891014099121 , average loss: 1.8824727535247803\n",
            "    Batch 70: combined loss = 7.0692009925842285 , average loss: 1.7673002481460571\n",
            "    Batch 80: combined loss = 10.289721488952637 , average loss: 2.572430372238159\n",
            "    Batch 90: combined loss = 7.551708221435547 , average loss: 1.8879270553588867\n",
            "    Batch 100: combined loss = 6.181193828582764 , average loss: 1.545298457145691\n",
            "    Batch 110: combined loss = 7.2393293380737305 , average loss: 1.8098323345184326\n",
            "    Batch 120: combined loss = 5.3788981437683105 , average loss: 1.3447245359420776\n",
            "    Batch 130: combined loss = 6.080816268920898 , average loss: 1.5202040672302246\n",
            "    Batch 140: combined loss = 8.056608200073242 , average loss: 2.0141520500183105\n",
            "    Batch 150: combined loss = 7.429417610168457 , average loss: 1.8573544025421143\n",
            "    Batch 160: combined loss = 6.28826904296875 , average loss: 1.5720672607421875\n",
            "    Batch 170: combined loss = 7.385889530181885 , average loss: 1.8464723825454712\n",
            "    Batch 180: combined loss = 7.266819000244141 , average loss: 1.8167047500610352\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 8\n",
            "Acc: 54.5933\n",
            "Edit: 32.7220\n",
            "F1@0.10: 4.1293\n",
            "F1@0.25: 2.8543\n",
            "F1@0.50: 1.5652\n",
            "EVALUATION AFTER EPOCH: 8\n",
            "Acc: 46.9973\n",
            "Edit: 4.5416\n",
            "F1@0.10: 3.3713\n",
            "F1@0.25: 2.1825\n",
            "F1@0.50: 1.1622\n",
            "RUNNING EPOCH: 9\n",
            "    Batch 0: combined loss = 9.346943855285645 , average loss: 2.336735963821411\n",
            "    Batch 10: combined loss = 4.798145771026611 , average loss: 1.1995364427566528\n",
            "    Batch 20: combined loss = 5.969387531280518 , average loss: 1.4923468828201294\n",
            "    Batch 30: combined loss = 5.433655738830566 , average loss: 1.3584139347076416\n",
            "    Batch 40: combined loss = 5.795887470245361 , average loss: 1.4489718675613403\n",
            "    Batch 50: combined loss = 6.277861595153809 , average loss: 1.5694653987884521\n",
            "    Batch 60: combined loss = 6.510230541229248 , average loss: 1.627557635307312\n",
            "    Batch 70: combined loss = 7.907109260559082 , average loss: 1.9767773151397705\n",
            "    Batch 80: combined loss = 5.760962963104248 , average loss: 1.440240740776062\n",
            "    Batch 90: combined loss = 7.679691314697266 , average loss: 1.9199228286743164\n",
            "    Batch 100: combined loss = 6.016523361206055 , average loss: 1.5041308403015137\n",
            "    Batch 110: combined loss = 6.531727313995361 , average loss: 1.6329318284988403\n",
            "    Batch 120: combined loss = 6.526968955993652 , average loss: 1.631742238998413\n",
            "    Batch 130: combined loss = 5.522724151611328 , average loss: 1.380681037902832\n",
            "    Batch 140: combined loss = 6.127266883850098 , average loss: 1.5318167209625244\n",
            "    Batch 150: combined loss = 6.715050220489502 , average loss: 1.6787625551223755\n",
            "    Batch 160: combined loss = 9.178009986877441 , average loss: 2.2945024967193604\n",
            "    Batch 170: combined loss = 5.542987823486328 , average loss: 1.385746955871582\n",
            "    Batch 180: combined loss = 4.671359539031982 , average loss: 1.1678398847579956\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 9\n",
            "Acc: 59.5255\n",
            "Edit: 31.6937\n",
            "F1@0.10: 4.1886\n",
            "F1@0.25: 2.7852\n",
            "F1@0.50: 1.3689\n",
            "EVALUATION AFTER EPOCH: 9\n",
            "Acc: 45.1232\n",
            "Edit: 4.2327\n",
            "F1@0.10: 3.0671\n",
            "F1@0.25: 1.7387\n",
            "F1@0.50: 0.6885\n",
            "RUNNING EPOCH: 10\n",
            "    Batch 0: combined loss = 7.430656433105469 , average loss: 1.8576641082763672\n",
            "    Batch 10: combined loss = 8.513991355895996 , average loss: 2.128497838973999\n",
            "    Batch 20: combined loss = 6.562076568603516 , average loss: 1.640519142150879\n",
            "    Batch 30: combined loss = 6.652453899383545 , average loss: 1.6631134748458862\n",
            "    Batch 40: combined loss = 5.8443922996521 , average loss: 1.461098074913025\n",
            "    Batch 50: combined loss = 5.897289752960205 , average loss: 1.4743224382400513\n",
            "    Batch 60: combined loss = 6.91402530670166 , average loss: 1.728506326675415\n",
            "    Batch 70: combined loss = 4.57114839553833 , average loss: 1.1427870988845825\n",
            "    Batch 80: combined loss = 4.48392915725708 , average loss: 1.12098228931427\n",
            "    Batch 90: combined loss = 4.135614395141602 , average loss: 1.0339035987854004\n",
            "    Batch 100: combined loss = 9.187807083129883 , average loss: 2.2969517707824707\n",
            "    Batch 110: combined loss = 5.941388130187988 , average loss: 1.485347032546997\n",
            "    Batch 120: combined loss = 8.032707214355469 , average loss: 2.008176803588867\n",
            "    Batch 130: combined loss = 7.2303972244262695 , average loss: 1.8075993061065674\n",
            "    Batch 140: combined loss = 6.848466396331787 , average loss: 1.7121165990829468\n",
            "    Batch 150: combined loss = 7.220653533935547 , average loss: 1.8051633834838867\n",
            "    Batch 160: combined loss = 7.94755220413208 , average loss: 1.98688805103302\n",
            "    Batch 170: combined loss = 4.450827121734619 , average loss: 1.1127067804336548\n",
            "    Batch 180: combined loss = 5.204633712768555 , average loss: 1.3011584281921387\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 10\n",
            "Acc: 62.9865\n",
            "Edit: 30.4834\n",
            "F1@0.10: 4.7704\n",
            "F1@0.25: 3.2966\n",
            "F1@0.50: 1.7049\n",
            "EVALUATION AFTER EPOCH: 10\n",
            "Acc: 51.0623\n",
            "Edit: 4.4752\n",
            "F1@0.10: 3.5295\n",
            "F1@0.25: 2.3072\n",
            "F1@0.50: 1.1307\n",
            "RUNNING EPOCH: 11\n",
            "    Batch 0: combined loss = 4.274561882019043 , average loss: 1.0686404705047607\n",
            "    Batch 10: combined loss = 5.288822174072266 , average loss: 1.3222055435180664\n",
            "    Batch 20: combined loss = 4.448226451873779 , average loss: 1.1120566129684448\n",
            "    Batch 30: combined loss = 5.507394313812256 , average loss: 1.376848578453064\n",
            "    Batch 40: combined loss = 4.187528610229492 , average loss: 1.046882152557373\n",
            "    Batch 50: combined loss = 6.621822357177734 , average loss: 1.6554555892944336\n",
            "    Batch 60: combined loss = 6.033238410949707 , average loss: 1.5083096027374268\n",
            "    Batch 70: combined loss = 5.957540512084961 , average loss: 1.4893851280212402\n",
            "    Batch 80: combined loss = 13.391328811645508 , average loss: 3.347832202911377\n",
            "    Batch 90: combined loss = 5.580292701721191 , average loss: 1.3950731754302979\n",
            "    Batch 100: combined loss = 4.769253253936768 , average loss: 1.192313313484192\n",
            "    Batch 110: combined loss = 5.716792583465576 , average loss: 1.429198145866394\n",
            "    Batch 120: combined loss = 5.077293395996094 , average loss: 1.2693233489990234\n",
            "    Batch 130: combined loss = 5.37672233581543 , average loss: 1.3441805839538574\n",
            "    Batch 140: combined loss = 5.127682209014893 , average loss: 1.2819205522537231\n",
            "    Batch 150: combined loss = 7.07579231262207 , average loss: 1.7689480781555176\n",
            "    Batch 160: combined loss = 7.292544364929199 , average loss: 1.8231360912322998\n",
            "    Batch 170: combined loss = 8.696590423583984 , average loss: 2.174147605895996\n",
            "    Batch 180: combined loss = 5.428462028503418 , average loss: 1.3571155071258545\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 11\n",
            "Acc: 60.8138\n",
            "Edit: 34.6236\n",
            "F1@0.10: 5.2813\n",
            "F1@0.25: 3.7829\n",
            "F1@0.50: 2.0829\n",
            "EVALUATION AFTER EPOCH: 11\n",
            "Acc: 50.6773\n",
            "Edit: 4.8695\n",
            "F1@0.10: 3.8067\n",
            "F1@0.25: 2.5822\n",
            "F1@0.50: 1.3843\n",
            "RUNNING EPOCH: 12\n",
            "    Batch 0: combined loss = 8.180580139160156 , average loss: 2.045145034790039\n",
            "    Batch 10: combined loss = 6.040615558624268 , average loss: 1.510153889656067\n",
            "    Batch 20: combined loss = 6.13157844543457 , average loss: 1.5328946113586426\n",
            "    Batch 30: combined loss = 5.036417484283447 , average loss: 1.2591043710708618\n",
            "    Batch 40: combined loss = 5.259217739105225 , average loss: 1.3148044347763062\n",
            "    Batch 50: combined loss = 8.07244873046875 , average loss: 2.0181121826171875\n",
            "    Batch 60: combined loss = 5.226215839385986 , average loss: 1.3065539598464966\n",
            "    Batch 70: combined loss = 4.627941608428955 , average loss: 1.1569854021072388\n",
            "    Batch 80: combined loss = 7.638865947723389 , average loss: 1.9097164869308472\n",
            "    Batch 90: combined loss = 7.1568145751953125 , average loss: 1.7892036437988281\n",
            "    Batch 100: combined loss = 7.111011028289795 , average loss: 1.7777527570724487\n",
            "    Batch 110: combined loss = 5.089598655700684 , average loss: 1.272399663925171\n",
            "    Batch 120: combined loss = 6.725430488586426 , average loss: 1.6813576221466064\n",
            "    Batch 130: combined loss = 6.666102409362793 , average loss: 1.6665256023406982\n",
            "    Batch 140: combined loss = 7.348466396331787 , average loss: 1.8371165990829468\n",
            "    Batch 150: combined loss = 6.22091007232666 , average loss: 1.555227518081665\n",
            "    Batch 160: combined loss = 5.966063976287842 , average loss: 1.4915159940719604\n",
            "    Batch 170: combined loss = 5.179302215576172 , average loss: 1.294825553894043\n",
            "    Batch 180: combined loss = 5.77921724319458 , average loss: 1.444804310798645\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 12\n",
            "Acc: 62.9085\n",
            "Edit: 45.8038\n",
            "F1@0.10: 5.1276\n",
            "F1@0.25: 3.7934\n",
            "F1@0.50: 2.1054\n",
            "EVALUATION AFTER EPOCH: 12\n",
            "Acc: 47.5170\n",
            "Edit: 5.5047\n",
            "F1@0.10: 3.4370\n",
            "F1@0.25: 2.4210\n",
            "F1@0.50: 1.2898\n",
            "RUNNING EPOCH: 13\n",
            "    Batch 0: combined loss = 6.151158332824707 , average loss: 1.5377895832061768\n",
            "    Batch 10: combined loss = 5.088418483734131 , average loss: 1.2721046209335327\n",
            "    Batch 20: combined loss = 6.358593463897705 , average loss: 1.5896483659744263\n",
            "    Batch 30: combined loss = 7.581294059753418 , average loss: 1.8953235149383545\n",
            "    Batch 40: combined loss = 5.4560041427612305 , average loss: 1.3640010356903076\n",
            "    Batch 50: combined loss = 4.890429496765137 , average loss: 1.2226073741912842\n",
            "    Batch 60: combined loss = 4.434133052825928 , average loss: 1.108533263206482\n",
            "    Batch 70: combined loss = 5.645151138305664 , average loss: 1.411287784576416\n",
            "    Batch 80: combined loss = 3.919867992401123 , average loss: 0.9799669981002808\n",
            "    Batch 90: combined loss = 4.9984211921691895 , average loss: 1.2496052980422974\n",
            "    Batch 100: combined loss = 6.472198009490967 , average loss: 1.6180495023727417\n",
            "    Batch 110: combined loss = 5.412182331085205 , average loss: 1.3530455827713013\n",
            "    Batch 120: combined loss = 4.848840236663818 , average loss: 1.2122100591659546\n",
            "    Batch 130: combined loss = 6.015965938568115 , average loss: 1.5039914846420288\n",
            "    Batch 140: combined loss = 5.164221286773682 , average loss: 1.2910553216934204\n",
            "    Batch 150: combined loss = 6.305018901824951 , average loss: 1.5762547254562378\n",
            "    Batch 160: combined loss = 6.5138349533081055 , average loss: 1.6284587383270264\n",
            "    Batch 170: combined loss = 4.223450183868408 , average loss: 1.055862545967102\n",
            "    Batch 180: combined loss = 5.4964752197265625 , average loss: 1.3741188049316406\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 13\n",
            "Acc: 58.9163\n",
            "Edit: 49.1982\n",
            "F1@0.10: 4.5992\n",
            "F1@0.25: 3.6159\n",
            "F1@0.50: 2.3308\n",
            "EVALUATION AFTER EPOCH: 13\n",
            "Acc: 39.3018\n",
            "Edit: 6.8667\n",
            "F1@0.10: 3.7705\n",
            "F1@0.25: 2.9206\n",
            "F1@0.50: 1.5067\n",
            "RUNNING EPOCH: 14\n",
            "    Batch 0: combined loss = 10.864555358886719 , average loss: 2.7161388397216797\n",
            "    Batch 10: combined loss = 5.055490493774414 , average loss: 1.2638726234436035\n",
            "    Batch 20: combined loss = 3.7870359420776367 , average loss: 0.9467589855194092\n",
            "    Batch 30: combined loss = 5.264828681945801 , average loss: 1.3162071704864502\n",
            "    Batch 40: combined loss = 5.489558219909668 , average loss: 1.372389554977417\n",
            "    Batch 50: combined loss = 4.265608787536621 , average loss: 1.0664021968841553\n",
            "    Batch 60: combined loss = 5.567636489868164 , average loss: 1.391909122467041\n",
            "    Batch 70: combined loss = 7.1918559074401855 , average loss: 1.7979639768600464\n",
            "    Batch 80: combined loss = 7.756377220153809 , average loss: 1.9390943050384521\n",
            "    Batch 90: combined loss = 5.863148212432861 , average loss: 1.4657870531082153\n",
            "    Batch 100: combined loss = 4.128660202026367 , average loss: 1.0321650505065918\n",
            "    Batch 110: combined loss = 3.9935202598571777 , average loss: 0.9983800649642944\n",
            "    Batch 120: combined loss = 5.387673854827881 , average loss: 1.3469184637069702\n",
            "    Batch 130: combined loss = 6.764454364776611 , average loss: 1.6911135911941528\n",
            "    Batch 140: combined loss = 6.023880481719971 , average loss: 1.5059701204299927\n",
            "    Batch 150: combined loss = 4.608075141906738 , average loss: 1.1520187854766846\n",
            "    Batch 160: combined loss = 5.011269569396973 , average loss: 1.2528173923492432\n",
            "    Batch 170: combined loss = 4.791631698608398 , average loss: 1.1979079246520996\n",
            "    Batch 180: combined loss = 5.871770858764648 , average loss: 1.467942714691162\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 14\n",
            "Acc: 62.4571\n",
            "Edit: 35.2678\n",
            "F1@0.10: 5.8474\n",
            "F1@0.25: 4.2571\n",
            "F1@0.50: 2.4644\n",
            "EVALUATION AFTER EPOCH: 14\n",
            "Acc: 52.3136\n",
            "Edit: 4.7317\n",
            "F1@0.10: 4.0931\n",
            "F1@0.25: 2.8982\n",
            "F1@0.50: 1.7746\n",
            "RUNNING EPOCH: 15\n",
            "    Batch 0: combined loss = 6.315730571746826 , average loss: 1.5789326429367065\n",
            "    Batch 10: combined loss = 5.408844470977783 , average loss: 1.3522111177444458\n",
            "    Batch 20: combined loss = 3.5220932960510254 , average loss: 0.8805233240127563\n",
            "    Batch 30: combined loss = 3.8155548572540283 , average loss: 0.9538887143135071\n",
            "    Batch 40: combined loss = 11.214365005493164 , average loss: 2.803591251373291\n",
            "    Batch 50: combined loss = 5.884377956390381 , average loss: 1.4710944890975952\n",
            "    Batch 60: combined loss = 2.6537623405456543 , average loss: 0.6634405851364136\n",
            "    Batch 70: combined loss = 5.441722869873047 , average loss: 1.3604307174682617\n",
            "    Batch 80: combined loss = 3.6763081550598145 , average loss: 0.9190770387649536\n",
            "    Batch 90: combined loss = 5.364156246185303 , average loss: 1.3410390615463257\n",
            "    Batch 100: combined loss = 6.0263471603393555 , average loss: 1.5065867900848389\n",
            "    Batch 110: combined loss = 6.888019561767578 , average loss: 1.7220048904418945\n",
            "    Batch 120: combined loss = 7.21206521987915 , average loss: 1.8030163049697876\n",
            "    Batch 130: combined loss = 6.763578414916992 , average loss: 1.690894603729248\n",
            "    Batch 140: combined loss = 4.887076377868652 , average loss: 1.221769094467163\n",
            "    Batch 150: combined loss = 5.05152702331543 , average loss: 1.2628817558288574\n",
            "    Batch 160: combined loss = 4.7074971199035645 , average loss: 1.1768742799758911\n",
            "    Batch 170: combined loss = 4.853407859802246 , average loss: 1.2133519649505615\n",
            "    Batch 180: combined loss = 6.333263397216797 , average loss: 1.5833158493041992\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 15\n",
            "Acc: 68.5473\n",
            "Edit: 44.5449\n",
            "F1@0.10: 6.1718\n",
            "F1@0.25: 4.8380\n",
            "F1@0.50: 2.8952\n",
            "EVALUATION AFTER EPOCH: 15\n",
            "Acc: 49.3816\n",
            "Edit: 6.1028\n",
            "F1@0.10: 4.1172\n",
            "F1@0.25: 3.0166\n",
            "F1@0.50: 1.6714\n",
            "RUNNING EPOCH: 16\n",
            "    Batch 0: combined loss = 6.341183185577393 , average loss: 1.5852957963943481\n",
            "    Batch 10: combined loss = 8.987264633178711 , average loss: 2.2468161582946777\n",
            "    Batch 20: combined loss = 6.850214958190918 , average loss: 1.7125537395477295\n",
            "    Batch 30: combined loss = 5.614631175994873 , average loss: 1.4036577939987183\n",
            "    Batch 40: combined loss = 7.1414690017700195 , average loss: 1.7853672504425049\n",
            "    Batch 50: combined loss = 5.519262790679932 , average loss: 1.379815697669983\n",
            "    Batch 60: combined loss = 5.205394744873047 , average loss: 1.3013486862182617\n",
            "    Batch 70: combined loss = 3.1864728927612305 , average loss: 0.7966182231903076\n",
            "    Batch 80: combined loss = 5.249871253967285 , average loss: 1.3124678134918213\n",
            "    Batch 90: combined loss = 5.544411659240723 , average loss: 1.3861029148101807\n",
            "    Batch 100: combined loss = 7.919939041137695 , average loss: 1.9799847602844238\n",
            "    Batch 110: combined loss = 5.164841175079346 , average loss: 1.2912102937698364\n",
            "    Batch 120: combined loss = 4.56278657913208 , average loss: 1.14069664478302\n",
            "    Batch 130: combined loss = 7.334028244018555 , average loss: 1.8335070610046387\n",
            "    Batch 140: combined loss = 5.922943592071533 , average loss: 1.4807358980178833\n",
            "    Batch 150: combined loss = 6.847420692443848 , average loss: 1.711855173110962\n",
            "    Batch 160: combined loss = 7.402482509613037 , average loss: 1.8506206274032593\n",
            "    Batch 170: combined loss = 5.87259578704834 , average loss: 1.468148946762085\n",
            "    Batch 180: combined loss = 3.903062105178833 , average loss: 0.9757655262947083\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 16\n",
            "Acc: 59.7052\n",
            "Edit: 34.7880\n",
            "F1@0.10: 5.4210\n",
            "F1@0.25: 3.7390\n",
            "F1@0.50: 2.1821\n",
            "EVALUATION AFTER EPOCH: 16\n",
            "Acc: 48.4189\n",
            "Edit: 4.1969\n",
            "F1@0.10: 3.9751\n",
            "F1@0.25: 2.6679\n",
            "F1@0.50: 1.4317\n",
            "RUNNING EPOCH: 17\n",
            "    Batch 0: combined loss = 6.337947845458984 , average loss: 1.584486961364746\n",
            "    Batch 10: combined loss = 3.6573758125305176 , average loss: 0.9143439531326294\n",
            "    Batch 20: combined loss = 5.604337215423584 , average loss: 1.401084303855896\n",
            "    Batch 30: combined loss = 4.780027389526367 , average loss: 1.1950068473815918\n",
            "    Batch 40: combined loss = 4.7088212966918945 , average loss: 1.1772053241729736\n",
            "    Batch 50: combined loss = 5.351813316345215 , average loss: 1.3379533290863037\n",
            "    Batch 60: combined loss = 3.0947837829589844 , average loss: 0.7736959457397461\n",
            "    Batch 70: combined loss = 3.9233853816986084 , average loss: 0.9808463454246521\n",
            "    Batch 80: combined loss = 5.804248809814453 , average loss: 1.4510622024536133\n",
            "    Batch 90: combined loss = 4.492266654968262 , average loss: 1.1230666637420654\n",
            "    Batch 100: combined loss = 5.694890022277832 , average loss: 1.423722505569458\n",
            "    Batch 110: combined loss = 4.893237113952637 , average loss: 1.2233092784881592\n",
            "    Batch 120: combined loss = 6.093505859375 , average loss: 1.52337646484375\n",
            "    Batch 130: combined loss = 2.684988498687744 , average loss: 0.671247124671936\n",
            "    Batch 140: combined loss = 5.540965557098389 , average loss: 1.3852413892745972\n",
            "    Batch 150: combined loss = 3.273315906524658 , average loss: 0.8183289766311646\n",
            "    Batch 160: combined loss = 4.951740741729736 , average loss: 1.237935185432434\n",
            "    Batch 170: combined loss = 6.046644687652588 , average loss: 1.511661171913147\n",
            "    Batch 180: combined loss = 6.659829616546631 , average loss: 1.6649574041366577\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 17\n",
            "Acc: 66.6120\n",
            "Edit: 40.3526\n",
            "F1@0.10: 5.8787\n",
            "F1@0.25: 4.4884\n",
            "F1@0.50: 2.7112\n",
            "EVALUATION AFTER EPOCH: 17\n",
            "Acc: 49.7712\n",
            "Edit: 4.9316\n",
            "F1@0.10: 3.5646\n",
            "F1@0.25: 2.6432\n",
            "F1@0.50: 1.5520\n",
            "RUNNING EPOCH: 18\n",
            "    Batch 0: combined loss = 6.516491889953613 , average loss: 1.6291229724884033\n",
            "    Batch 10: combined loss = 4.098698616027832 , average loss: 1.024674654006958\n",
            "    Batch 20: combined loss = 5.196765422821045 , average loss: 1.2991913557052612\n",
            "    Batch 30: combined loss = 4.804309844970703 , average loss: 1.2010774612426758\n",
            "    Batch 40: combined loss = 7.383713245391846 , average loss: 1.8459283113479614\n",
            "    Batch 50: combined loss = 4.496321678161621 , average loss: 1.1240804195404053\n",
            "    Batch 60: combined loss = 6.072714805603027 , average loss: 1.5181787014007568\n",
            "    Batch 70: combined loss = 5.387779235839844 , average loss: 1.346944808959961\n",
            "    Batch 80: combined loss = 5.287269592285156 , average loss: 1.321817398071289\n",
            "    Batch 90: combined loss = 7.085031032562256 , average loss: 1.771257758140564\n",
            "    Batch 100: combined loss = 4.062161445617676 , average loss: 1.015540361404419\n",
            "    Batch 110: combined loss = 6.173913955688477 , average loss: 1.5434784889221191\n",
            "    Batch 120: combined loss = 4.995704650878906 , average loss: 1.2489261627197266\n",
            "    Batch 130: combined loss = 5.689116477966309 , average loss: 1.4222791194915771\n",
            "    Batch 140: combined loss = 3.0265438556671143 , average loss: 0.7566359639167786\n",
            "    Batch 150: combined loss = 5.77132511138916 , average loss: 1.44283127784729\n",
            "    Batch 160: combined loss = 4.019805908203125 , average loss: 1.0049514770507812\n",
            "    Batch 170: combined loss = 6.074522018432617 , average loss: 1.5186305046081543\n",
            "    Batch 180: combined loss = 4.030603885650635 , average loss: 1.0076509714126587\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 18\n",
            "Acc: 69.7605\n",
            "Edit: 53.5012\n",
            "F1@0.10: 6.8083\n",
            "F1@0.25: 5.6018\n",
            "F1@0.50: 3.7326\n",
            "EVALUATION AFTER EPOCH: 18\n",
            "Acc: 49.0052\n",
            "Edit: 6.8032\n",
            "F1@0.10: 4.4726\n",
            "F1@0.25: 3.4647\n",
            "F1@0.50: 2.0248\n",
            "RUNNING EPOCH: 19\n",
            "    Batch 0: combined loss = 3.1593542098999023 , average loss: 0.7898385524749756\n",
            "    Batch 10: combined loss = 5.808443069458008 , average loss: 1.452110767364502\n",
            "    Batch 20: combined loss = 4.862020015716553 , average loss: 1.2155050039291382\n",
            "    Batch 30: combined loss = 4.695503234863281 , average loss: 1.1738758087158203\n",
            "    Batch 40: combined loss = 3.3914966583251953 , average loss: 0.8478741645812988\n",
            "    Batch 50: combined loss = 5.0953369140625 , average loss: 1.273834228515625\n",
            "    Batch 60: combined loss = 4.74704122543335 , average loss: 1.1867603063583374\n",
            "    Batch 70: combined loss = 2.855806589126587 , average loss: 0.7139516472816467\n",
            "    Batch 80: combined loss = 5.689445495605469 , average loss: 1.4223613739013672\n",
            "    Batch 90: combined loss = 4.767476558685303 , average loss: 1.1918691396713257\n",
            "    Batch 100: combined loss = 4.123233795166016 , average loss: 1.030808448791504\n",
            "    Batch 110: combined loss = 5.474286079406738 , average loss: 1.3685715198516846\n",
            "    Batch 120: combined loss = 5.657258987426758 , average loss: 1.4143147468566895\n",
            "    Batch 130: combined loss = 4.578160285949707 , average loss: 1.1445400714874268\n",
            "    Batch 140: combined loss = 4.931884765625 , average loss: 1.23297119140625\n",
            "    Batch 150: combined loss = 5.568997383117676 , average loss: 1.392249345779419\n",
            "    Batch 160: combined loss = 4.593146324157715 , average loss: 1.1482865810394287\n",
            "    Batch 170: combined loss = 4.191868305206299 , average loss: 1.0479670763015747\n",
            "    Batch 180: combined loss = 6.340925216674805 , average loss: 1.5852313041687012\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 19\n",
            "Acc: 69.9874\n",
            "Edit: 40.5610\n",
            "F1@0.10: 6.8557\n",
            "F1@0.25: 5.3111\n",
            "F1@0.50: 3.3308\n",
            "EVALUATION AFTER EPOCH: 19\n",
            "Acc: 52.8047\n",
            "Edit: 4.8214\n",
            "F1@0.10: 4.1162\n",
            "F1@0.25: 2.9138\n",
            "F1@0.50: 1.6500\n",
            "RUNNING EPOCH: 20\n",
            "    Batch 0: combined loss = 3.3878333568573 , average loss: 0.846958339214325\n",
            "    Batch 10: combined loss = 3.3798716068267822 , average loss: 0.8449679017066956\n",
            "    Batch 20: combined loss = 6.133975028991699 , average loss: 1.5334937572479248\n",
            "    Batch 30: combined loss = 5.263457298278809 , average loss: 1.3158643245697021\n",
            "    Batch 40: combined loss = 3.41522216796875 , average loss: 0.8538055419921875\n",
            "    Batch 50: combined loss = 4.622063636779785 , average loss: 1.1555159091949463\n",
            "    Batch 60: combined loss = 4.015583515167236 , average loss: 1.003895878791809\n",
            "    Batch 70: combined loss = 4.659435749053955 , average loss: 1.1648589372634888\n",
            "    Batch 80: combined loss = 4.115958213806152 , average loss: 1.028989553451538\n",
            "    Batch 90: combined loss = 3.9023079872131348 , average loss: 0.9755769968032837\n",
            "    Batch 100: combined loss = 6.023298740386963 , average loss: 1.5058246850967407\n",
            "    Batch 110: combined loss = 3.6274027824401855 , average loss: 0.9068506956100464\n",
            "    Batch 120: combined loss = 5.0707292556762695 , average loss: 1.2676823139190674\n",
            "    Batch 130: combined loss = 3.4721364974975586 , average loss: 0.8680341243743896\n",
            "    Batch 140: combined loss = 4.457239151000977 , average loss: 1.1143097877502441\n",
            "    Batch 150: combined loss = 3.9876410961151123 , average loss: 0.9969102740287781\n",
            "    Batch 160: combined loss = 5.136928558349609 , average loss: 1.2842321395874023\n",
            "    Batch 170: combined loss = 4.102433204650879 , average loss: 1.0256083011627197\n",
            "    Batch 180: combined loss = 5.646210670471191 , average loss: 1.4115526676177979\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 20\n",
            "Acc: 69.7942\n",
            "Edit: 55.1862\n",
            "F1@0.10: 7.1608\n",
            "F1@0.25: 5.8114\n",
            "F1@0.50: 3.7180\n",
            "EVALUATION AFTER EPOCH: 20\n",
            "Acc: 48.5997\n",
            "Edit: 6.3279\n",
            "F1@0.10: 4.5920\n",
            "F1@0.25: 3.4324\n",
            "F1@0.50: 1.9945\n",
            "RUNNING EPOCH: 21\n",
            "    Batch 0: combined loss = 3.9368412494659424 , average loss: 0.9842103123664856\n",
            "    Batch 10: combined loss = 6.718654632568359 , average loss: 1.6796636581420898\n",
            "    Batch 20: combined loss = 5.693278789520264 , average loss: 1.423319697380066\n",
            "    Batch 30: combined loss = 5.0355730056762695 , average loss: 1.2588932514190674\n",
            "    Batch 40: combined loss = 5.126292705535889 , average loss: 1.2815731763839722\n",
            "    Batch 50: combined loss = 3.8293354511260986 , average loss: 0.9573338627815247\n",
            "    Batch 60: combined loss = 5.103081703186035 , average loss: 1.2757704257965088\n",
            "    Batch 70: combined loss = 4.566230773925781 , average loss: 1.1415576934814453\n",
            "    Batch 80: combined loss = 2.2024424076080322 , average loss: 0.5506106019020081\n",
            "    Batch 90: combined loss = 3.0671730041503906 , average loss: 0.7667932510375977\n",
            "    Batch 100: combined loss = 3.0912351608276367 , average loss: 0.7728087902069092\n",
            "    Batch 110: combined loss = 5.158900737762451 , average loss: 1.2897251844406128\n",
            "    Batch 120: combined loss = 4.4670515060424805 , average loss: 1.1167628765106201\n",
            "    Batch 130: combined loss = 4.79203987121582 , average loss: 1.198009967803955\n",
            "    Batch 140: combined loss = 6.0276923179626465 , average loss: 1.5069230794906616\n",
            "    Batch 150: combined loss = 5.435122013092041 , average loss: 1.3587805032730103\n",
            "    Batch 160: combined loss = 6.192385673522949 , average loss: 1.5480964183807373\n",
            "    Batch 170: combined loss = 4.471246719360352 , average loss: 1.117811679840088\n",
            "    Batch 180: combined loss = 4.515951156616211 , average loss: 1.1289877891540527\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 21\n",
            "Acc: 71.4289\n",
            "Edit: 50.4728\n",
            "F1@0.10: 6.4051\n",
            "F1@0.25: 5.3168\n",
            "F1@0.50: 3.5095\n",
            "EVALUATION AFTER EPOCH: 21\n",
            "Acc: 49.6620\n",
            "Edit: 5.4822\n",
            "F1@0.10: 3.7812\n",
            "F1@0.25: 2.9284\n",
            "F1@0.50: 1.7780\n",
            "RUNNING EPOCH: 22\n",
            "    Batch 0: combined loss = 3.8160951137542725 , average loss: 0.9540237784385681\n",
            "    Batch 10: combined loss = 5.656406879425049 , average loss: 1.4141017198562622\n",
            "    Batch 20: combined loss = 4.056404113769531 , average loss: 1.0141010284423828\n",
            "    Batch 30: combined loss = 2.813239336013794 , average loss: 0.7033098340034485\n",
            "    Batch 40: combined loss = 4.062188625335693 , average loss: 1.0155471563339233\n",
            "    Batch 50: combined loss = 4.351025104522705 , average loss: 1.0877562761306763\n",
            "    Batch 60: combined loss = 4.826600551605225 , average loss: 1.2066501379013062\n",
            "    Batch 70: combined loss = 3.7294838428497314 , average loss: 0.9323709607124329\n",
            "    Batch 80: combined loss = 5.120388031005859 , average loss: 1.2800970077514648\n",
            "    Batch 90: combined loss = 6.142036437988281 , average loss: 1.5355091094970703\n",
            "    Batch 100: combined loss = 2.959850788116455 , average loss: 0.7399626970291138\n",
            "    Batch 110: combined loss = 5.124634265899658 , average loss: 1.2811585664749146\n",
            "    Batch 120: combined loss = 3.946023464202881 , average loss: 0.9865058660507202\n",
            "    Batch 130: combined loss = 4.906193733215332 , average loss: 1.226548433303833\n",
            "    Batch 140: combined loss = 4.888470649719238 , average loss: 1.2221176624298096\n",
            "    Batch 150: combined loss = 4.384258270263672 , average loss: 1.096064567565918\n",
            "    Batch 160: combined loss = 4.037217617034912 , average loss: 1.009304404258728\n",
            "    Batch 170: combined loss = 5.867506504058838 , average loss: 1.4668766260147095\n",
            "    Batch 180: combined loss = 4.0867486000061035 , average loss: 1.0216871500015259\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 22\n",
            "Acc: 74.3342\n",
            "Edit: 59.5627\n",
            "F1@0.10: 7.6145\n",
            "F1@0.25: 6.2902\n",
            "F1@0.50: 4.1999\n",
            "EVALUATION AFTER EPOCH: 22\n",
            "Acc: 50.9486\n",
            "Edit: 5.8458\n",
            "F1@0.10: 4.2322\n",
            "F1@0.25: 3.2699\n",
            "F1@0.50: 1.8176\n",
            "RUNNING EPOCH: 23\n",
            "    Batch 0: combined loss = 3.552218437194824 , average loss: 0.888054609298706\n",
            "    Batch 10: combined loss = 3.7163166999816895 , average loss: 0.9290791749954224\n",
            "    Batch 20: combined loss = 4.161139488220215 , average loss: 1.0402848720550537\n",
            "    Batch 30: combined loss = 6.573172092437744 , average loss: 1.643293023109436\n",
            "    Batch 40: combined loss = 4.135005950927734 , average loss: 1.0337514877319336\n",
            "    Batch 50: combined loss = 5.065255641937256 , average loss: 1.266313910484314\n",
            "    Batch 60: combined loss = 5.156461715698242 , average loss: 1.2891154289245605\n",
            "    Batch 70: combined loss = 7.065546989440918 , average loss: 1.7663867473602295\n",
            "    Batch 80: combined loss = 5.760219573974609 , average loss: 1.4400548934936523\n",
            "    Batch 90: combined loss = 6.921496868133545 , average loss: 1.7303742170333862\n",
            "    Batch 100: combined loss = 6.841424942016602 , average loss: 1.7103562355041504\n",
            "    Batch 110: combined loss = 4.039052963256836 , average loss: 1.009763240814209\n",
            "    Batch 120: combined loss = 3.4163970947265625 , average loss: 0.8540992736816406\n",
            "    Batch 130: combined loss = 5.07012939453125 , average loss: 1.2675323486328125\n",
            "    Batch 140: combined loss = 5.805807590484619 , average loss: 1.4514518976211548\n",
            "    Batch 150: combined loss = 5.036111354827881 , average loss: 1.2590278387069702\n",
            "    Batch 160: combined loss = 4.168581962585449 , average loss: 1.0421454906463623\n",
            "    Batch 170: combined loss = 4.391017913818359 , average loss: 1.0977544784545898\n",
            "    Batch 180: combined loss = 4.328979015350342 , average loss: 1.0822447538375854\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 23\n",
            "Acc: 73.0309\n",
            "Edit: 56.9760\n",
            "F1@0.10: 7.1737\n",
            "F1@0.25: 5.9125\n",
            "F1@0.50: 4.0128\n",
            "EVALUATION AFTER EPOCH: 23\n",
            "Acc: 52.9048\n",
            "Edit: 5.7920\n",
            "F1@0.10: 4.1363\n",
            "F1@0.25: 3.1902\n",
            "F1@0.50: 1.8421\n",
            "RUNNING EPOCH: 24\n",
            "    Batch 0: combined loss = 3.404042959213257 , average loss: 0.8510107398033142\n",
            "    Batch 10: combined loss = 4.297214984893799 , average loss: 1.0743037462234497\n",
            "    Batch 20: combined loss = 4.042121887207031 , average loss: 1.0105304718017578\n",
            "    Batch 30: combined loss = 4.364644527435303 , average loss: 1.0911611318588257\n",
            "    Batch 40: combined loss = 3.0848166942596436 , average loss: 0.7712041735649109\n",
            "    Batch 50: combined loss = 3.9390869140625 , average loss: 0.984771728515625\n",
            "    Batch 60: combined loss = 4.417160511016846 , average loss: 1.1042901277542114\n",
            "    Batch 70: combined loss = 6.194526195526123 , average loss: 1.5486315488815308\n",
            "    Batch 80: combined loss = 4.510909080505371 , average loss: 1.1277272701263428\n",
            "    Batch 90: combined loss = 3.3655121326446533 , average loss: 0.8413780331611633\n",
            "    Batch 100: combined loss = 4.967851161956787 , average loss: 1.2419627904891968\n",
            "    Batch 110: combined loss = 6.447722911834717 , average loss: 1.6119307279586792\n",
            "    Batch 120: combined loss = 3.939128875732422 , average loss: 0.9847822189331055\n",
            "    Batch 130: combined loss = 3.8944296836853027 , average loss: 0.9736074209213257\n",
            "    Batch 140: combined loss = 5.121423244476318 , average loss: 1.2803558111190796\n",
            "    Batch 150: combined loss = 3.9293622970581055 , average loss: 0.9823405742645264\n",
            "    Batch 160: combined loss = 3.2893059253692627 , average loss: 0.8223264813423157\n",
            "    Batch 170: combined loss = 4.400271892547607 , average loss: 1.1000679731369019\n",
            "    Batch 180: combined loss = 3.9421279430389404 , average loss: 0.9855319857597351\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 24\n",
            "Acc: 70.7775\n",
            "Edit: 63.7173\n",
            "F1@0.10: 6.7304\n",
            "F1@0.25: 5.6071\n",
            "F1@0.50: 3.8245\n",
            "EVALUATION AFTER EPOCH: 24\n",
            "Acc: 47.7598\n",
            "Edit: 6.5990\n",
            "F1@0.10: 3.8612\n",
            "F1@0.25: 3.1022\n",
            "F1@0.50: 1.7821\n",
            "RUNNING EPOCH: 25\n",
            "    Batch 0: combined loss = 5.093381881713867 , average loss: 1.2733454704284668\n",
            "    Batch 10: combined loss = 4.939437389373779 , average loss: 1.2348593473434448\n",
            "    Batch 20: combined loss = 3.0743587017059326 , average loss: 0.7685896754264832\n",
            "    Batch 30: combined loss = 4.920746803283691 , average loss: 1.2301867008209229\n",
            "    Batch 40: combined loss = 4.260628700256348 , average loss: 1.065157175064087\n",
            "    Batch 50: combined loss = 3.093635320663452 , average loss: 0.773408830165863\n",
            "    Batch 60: combined loss = 3.3954336643218994 , average loss: 0.8488584160804749\n",
            "    Batch 70: combined loss = 3.534976005554199 , average loss: 0.8837440013885498\n",
            "    Batch 80: combined loss = 3.50872802734375 , average loss: 0.8771820068359375\n",
            "    Batch 90: combined loss = 3.3253188133239746 , average loss: 0.8313297033309937\n",
            "    Batch 100: combined loss = 4.671720504760742 , average loss: 1.1679301261901855\n",
            "    Batch 110: combined loss = 5.627133369445801 , average loss: 1.4067833423614502\n",
            "    Batch 120: combined loss = 4.4530229568481445 , average loss: 1.1132557392120361\n",
            "    Batch 130: combined loss = 4.157223224639893 , average loss: 1.0393058061599731\n",
            "    Batch 140: combined loss = 5.381239891052246 , average loss: 1.3453099727630615\n",
            "    Batch 150: combined loss = 4.505209922790527 , average loss: 1.1263024806976318\n",
            "    Batch 160: combined loss = 4.830786228179932 , average loss: 1.207696557044983\n",
            "    Batch 170: combined loss = 5.1732497215271 , average loss: 1.293312430381775\n",
            "    Batch 180: combined loss = 4.990962028503418 , average loss: 1.2477405071258545\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 25\n",
            "Acc: 74.5255\n",
            "Edit: 46.7489\n",
            "F1@0.10: 7.2969\n",
            "F1@0.25: 6.0127\n",
            "F1@0.50: 3.9958\n",
            "EVALUATION AFTER EPOCH: 25\n",
            "Acc: 51.3555\n",
            "Edit: 5.1307\n",
            "F1@0.10: 3.8151\n",
            "F1@0.25: 2.9428\n",
            "F1@0.50: 1.7141\n",
            "RUNNING EPOCH: 26\n",
            "    Batch 0: combined loss = 3.6760430335998535 , average loss: 0.9190107583999634\n",
            "    Batch 10: combined loss = 3.8613429069519043 , average loss: 0.9653357267379761\n",
            "    Batch 20: combined loss = 2.859902858734131 , average loss: 0.7149757146835327\n",
            "    Batch 30: combined loss = 5.473240375518799 , average loss: 1.3683100938796997\n",
            "    Batch 40: combined loss = 3.8286855220794678 , average loss: 0.9571713805198669\n",
            "    Batch 50: combined loss = 5.951555252075195 , average loss: 1.4878888130187988\n",
            "    Batch 60: combined loss = 3.280081033706665 , average loss: 0.8200202584266663\n",
            "    Batch 70: combined loss = 3.1455934047698975 , average loss: 0.7863983511924744\n",
            "    Batch 80: combined loss = 4.072959899902344 , average loss: 1.018239974975586\n",
            "    Batch 90: combined loss = 3.667600393295288 , average loss: 0.916900098323822\n",
            "    Batch 100: combined loss = 4.391605854034424 , average loss: 1.097901463508606\n",
            "    Batch 110: combined loss = 5.396001815795898 , average loss: 1.3490004539489746\n",
            "    Batch 120: combined loss = 3.7662556171417236 , average loss: 0.9415639042854309\n",
            "    Batch 130: combined loss = 3.950380563735962 , average loss: 0.9875951409339905\n",
            "    Batch 140: combined loss = 3.9726972579956055 , average loss: 0.9931743144989014\n",
            "    Batch 150: combined loss = 2.6698708534240723 , average loss: 0.6674677133560181\n",
            "    Batch 160: combined loss = 3.4922690391540527 , average loss: 0.8730672597885132\n",
            "    Batch 170: combined loss = 2.509531259536743 , average loss: 0.6273828148841858\n",
            "    Batch 180: combined loss = 5.5406928062438965 , average loss: 1.3851732015609741\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 26\n",
            "Acc: 73.6691\n",
            "Edit: 47.0166\n",
            "F1@0.10: 7.1932\n",
            "F1@0.25: 5.7614\n",
            "F1@0.50: 3.7693\n",
            "EVALUATION AFTER EPOCH: 26\n",
            "Acc: 53.4018\n",
            "Edit: 5.3774\n",
            "F1@0.10: 4.1351\n",
            "F1@0.25: 3.1711\n",
            "F1@0.50: 1.6236\n",
            "RUNNING EPOCH: 27\n",
            "    Batch 0: combined loss = 4.801525115966797 , average loss: 1.2003812789916992\n",
            "    Batch 10: combined loss = 4.318053722381592 , average loss: 1.079513430595398\n",
            "    Batch 20: combined loss = 4.445229530334473 , average loss: 1.1113073825836182\n",
            "    Batch 30: combined loss = 4.785239219665527 , average loss: 1.1963098049163818\n",
            "    Batch 40: combined loss = 3.932955503463745 , average loss: 0.9832388758659363\n",
            "    Batch 50: combined loss = 7.417785167694092 , average loss: 1.854446291923523\n",
            "    Batch 60: combined loss = 3.5589118003845215 , average loss: 0.8897279500961304\n",
            "    Batch 70: combined loss = 4.863837718963623 , average loss: 1.2159594297409058\n",
            "    Batch 80: combined loss = 5.048789978027344 , average loss: 1.262197494506836\n",
            "    Batch 90: combined loss = 3.854321002960205 , average loss: 0.9635802507400513\n",
            "    Batch 100: combined loss = 3.4812097549438477 , average loss: 0.8703024387359619\n",
            "    Batch 110: combined loss = 5.090524196624756 , average loss: 1.272631049156189\n",
            "    Batch 120: combined loss = 5.003147125244141 , average loss: 1.2507867813110352\n",
            "    Batch 130: combined loss = 3.8686323165893555 , average loss: 0.9671580791473389\n",
            "    Batch 140: combined loss = 5.083695888519287 , average loss: 1.2709239721298218\n",
            "    Batch 150: combined loss = 3.2012712955474854 , average loss: 0.8003178238868713\n",
            "    Batch 160: combined loss = 5.3705878257751465 , average loss: 1.3426469564437866\n",
            "    Batch 170: combined loss = 4.712494373321533 , average loss: 1.1781235933303833\n",
            "    Batch 180: combined loss = 5.123162269592285 , average loss: 1.2807905673980713\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 27\n",
            "Acc: 74.2269\n",
            "Edit: 57.5706\n",
            "F1@0.10: 6.9436\n",
            "F1@0.25: 5.8830\n",
            "F1@0.50: 3.9872\n",
            "EVALUATION AFTER EPOCH: 27\n",
            "Acc: 49.7875\n",
            "Edit: 5.6719\n",
            "F1@0.10: 4.0095\n",
            "F1@0.25: 3.0289\n",
            "F1@0.50: 1.8110\n",
            "RUNNING EPOCH: 28\n",
            "    Batch 0: combined loss = 4.107293128967285 , average loss: 1.0268232822418213\n",
            "    Batch 10: combined loss = 4.214838027954102 , average loss: 1.0537095069885254\n",
            "    Batch 20: combined loss = 2.9989442825317383 , average loss: 0.7497360706329346\n",
            "    Batch 30: combined loss = 4.405476093292236 , average loss: 1.101369023323059\n",
            "    Batch 40: combined loss = 4.535957336425781 , average loss: 1.1339893341064453\n",
            "    Batch 50: combined loss = 3.374666452407837 , average loss: 0.8436666131019592\n",
            "    Batch 60: combined loss = 6.83519983291626 , average loss: 1.708799958229065\n",
            "    Batch 70: combined loss = 3.374993085861206 , average loss: 0.8437482714653015\n",
            "    Batch 80: combined loss = 4.388756275177002 , average loss: 1.0971890687942505\n",
            "    Batch 90: combined loss = 3.612922191619873 , average loss: 0.9032305479049683\n",
            "    Batch 100: combined loss = 3.5500664710998535 , average loss: 0.8875166177749634\n",
            "    Batch 110: combined loss = 4.9719743728637695 , average loss: 1.2429935932159424\n",
            "    Batch 120: combined loss = 2.6963136196136475 , average loss: 0.6740784049034119\n",
            "    Batch 130: combined loss = 5.252557754516602 , average loss: 1.3131394386291504\n",
            "    Batch 140: combined loss = 3.5370535850524902 , average loss: 0.8842633962631226\n",
            "    Batch 150: combined loss = 4.4380574226379395 , average loss: 1.1095143556594849\n",
            "    Batch 160: combined loss = 4.8683762550354 , average loss: 1.21709406375885\n",
            "    Batch 170: combined loss = 6.226466178894043 , average loss: 1.5566165447235107\n",
            "    Batch 180: combined loss = 3.8255703449249268 , average loss: 0.9563925862312317\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 28\n",
            "Acc: 69.2999\n",
            "Edit: 59.2751\n",
            "F1@0.10: 6.8223\n",
            "F1@0.25: 5.7140\n",
            "F1@0.50: 3.9015\n",
            "EVALUATION AFTER EPOCH: 28\n",
            "Acc: 47.5482\n",
            "Edit: 6.2934\n",
            "F1@0.10: 4.1011\n",
            "F1@0.25: 3.2381\n",
            "F1@0.50: 2.0194\n",
            "RUNNING EPOCH: 29\n",
            "    Batch 0: combined loss = 5.319628715515137 , average loss: 1.3299071788787842\n",
            "    Batch 10: combined loss = 3.8352112770080566 , average loss: 0.9588028192520142\n",
            "    Batch 20: combined loss = 4.105589866638184 , average loss: 1.026397466659546\n",
            "    Batch 30: combined loss = 2.876840114593506 , average loss: 0.7192100286483765\n",
            "    Batch 40: combined loss = 3.841031551361084 , average loss: 0.960257887840271\n",
            "    Batch 50: combined loss = 4.2536940574646 , average loss: 1.06342351436615\n",
            "    Batch 60: combined loss = 3.6250524520874023 , average loss: 0.9062631130218506\n",
            "    Batch 70: combined loss = 3.6358776092529297 , average loss: 0.9089694023132324\n",
            "    Batch 80: combined loss = 4.400164604187012 , average loss: 1.100041151046753\n",
            "    Batch 90: combined loss = 5.634669303894043 , average loss: 1.4086673259735107\n",
            "    Batch 100: combined loss = 3.2711644172668457 , average loss: 0.8177911043167114\n",
            "    Batch 110: combined loss = 2.706760883331299 , average loss: 0.6766902208328247\n",
            "    Batch 120: combined loss = 4.232608318328857 , average loss: 1.0581520795822144\n",
            "    Batch 130: combined loss = 3.7984864711761475 , average loss: 0.9496216177940369\n",
            "    Batch 140: combined loss = 4.763784408569336 , average loss: 1.190946102142334\n",
            "    Batch 150: combined loss = 4.341789245605469 , average loss: 1.0854473114013672\n",
            "    Batch 160: combined loss = 2.733509063720703 , average loss: 0.6833772659301758\n",
            "    Batch 170: combined loss = 4.049437999725342 , average loss: 1.0123594999313354\n",
            "    Batch 180: combined loss = 4.011556625366211 , average loss: 1.0028891563415527\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 29\n",
            "Acc: 74.1659\n",
            "Edit: 57.0693\n",
            "F1@0.10: 6.6612\n",
            "F1@0.25: 5.5703\n",
            "F1@0.50: 3.7669\n",
            "EVALUATION AFTER EPOCH: 29\n",
            "Acc: 38.7083\n",
            "Edit: 5.1038\n",
            "F1@0.10: 3.0819\n",
            "F1@0.25: 2.3900\n",
            "F1@0.50: 1.3900\n",
            "RUNNING EPOCH: 30\n",
            "    Batch 0: combined loss = 2.799159049987793 , average loss: 0.6997897624969482\n",
            "    Batch 10: combined loss = 3.662285804748535 , average loss: 0.9155714511871338\n",
            "    Batch 20: combined loss = 4.9442338943481445 , average loss: 1.2360584735870361\n",
            "    Batch 30: combined loss = 2.746506452560425 , average loss: 0.6866266131401062\n",
            "    Batch 40: combined loss = 2.798015594482422 , average loss: 0.6995038986206055\n",
            "    Batch 50: combined loss = 5.371076583862305 , average loss: 1.3427691459655762\n",
            "    Batch 60: combined loss = 3.805950164794922 , average loss: 0.9514875411987305\n",
            "    Batch 70: combined loss = 6.644872188568115 , average loss: 1.6612180471420288\n",
            "    Batch 80: combined loss = 4.48177433013916 , average loss: 1.12044358253479\n",
            "    Batch 90: combined loss = 3.81015944480896 , average loss: 0.95253986120224\n",
            "    Batch 100: combined loss = 7.014475345611572 , average loss: 1.753618836402893\n",
            "    Batch 110: combined loss = 4.563891887664795 , average loss: 1.1409729719161987\n",
            "    Batch 120: combined loss = 3.402369260787964 , average loss: 0.850592315196991\n",
            "    Batch 130: combined loss = 4.005804061889648 , average loss: 1.001451015472412\n",
            "    Batch 140: combined loss = 2.841385841369629 , average loss: 0.7103464603424072\n",
            "    Batch 150: combined loss = 3.9531843662261963 , average loss: 0.9882960915565491\n",
            "    Batch 160: combined loss = 3.8783857822418213 , average loss: 0.9695964455604553\n",
            "    Batch 170: combined loss = 3.6876964569091797 , average loss: 0.9219241142272949\n",
            "    Batch 180: combined loss = 3.9506449699401855 , average loss: 0.9876612424850464\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 30\n",
            "Acc: 77.5315\n",
            "Edit: 63.0600\n",
            "F1@0.10: 7.8836\n",
            "F1@0.25: 6.6981\n",
            "F1@0.50: 4.6031\n",
            "EVALUATION AFTER EPOCH: 30\n",
            "Acc: 47.8219\n",
            "Edit: 5.3000\n",
            "F1@0.10: 3.8330\n",
            "F1@0.25: 3.0143\n",
            "F1@0.50: 1.6969\n",
            "RUNNING EPOCH: 31\n",
            "    Batch 0: combined loss = 3.6197850704193115 , average loss: 0.9049462676048279\n",
            "    Batch 10: combined loss = 3.786355495452881 , average loss: 0.9465888738632202\n",
            "    Batch 20: combined loss = 3.1908085346221924 , average loss: 0.7977021336555481\n",
            "    Batch 30: combined loss = 3.4054718017578125 , average loss: 0.8513679504394531\n",
            "    Batch 40: combined loss = 3.196042537689209 , average loss: 0.7990106344223022\n",
            "    Batch 50: combined loss = 4.286112308502197 , average loss: 1.0715280771255493\n",
            "    Batch 60: combined loss = 2.867861747741699 , average loss: 0.7169654369354248\n",
            "    Batch 70: combined loss = 5.289373397827148 , average loss: 1.322343349456787\n",
            "    Batch 80: combined loss = 4.001615047454834 , average loss: 1.0004037618637085\n",
            "    Batch 90: combined loss = 4.156248092651367 , average loss: 1.0390620231628418\n",
            "    Batch 100: combined loss = 3.1930861473083496 , average loss: 0.7982715368270874\n",
            "    Batch 110: combined loss = 6.049015045166016 , average loss: 1.512253761291504\n",
            "    Batch 120: combined loss = 5.486900329589844 , average loss: 1.371725082397461\n",
            "    Batch 130: combined loss = 4.618083953857422 , average loss: 1.1545209884643555\n",
            "    Batch 140: combined loss = 4.117236137390137 , average loss: 1.0293090343475342\n",
            "    Batch 150: combined loss = 3.6525192260742188 , average loss: 0.9131298065185547\n",
            "    Batch 160: combined loss = 7.280116558074951 , average loss: 1.8200291395187378\n",
            "    Batch 170: combined loss = 3.747211217880249 , average loss: 0.9368028044700623\n",
            "    Batch 180: combined loss = 3.1461915969848633 , average loss: 0.7865478992462158\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 31\n",
            "Acc: 77.7316\n",
            "Edit: 63.3319\n",
            "F1@0.10: 7.4756\n",
            "F1@0.25: 6.3521\n",
            "F1@0.50: 4.3977\n",
            "EVALUATION AFTER EPOCH: 31\n",
            "Acc: 47.0105\n",
            "Edit: 5.7933\n",
            "F1@0.10: 3.6819\n",
            "F1@0.25: 2.8613\n",
            "F1@0.50: 1.6776\n",
            "RUNNING EPOCH: 32\n",
            "    Batch 0: combined loss = 3.3375144004821777 , average loss: 0.8343786001205444\n",
            "    Batch 10: combined loss = 4.035440444946289 , average loss: 1.0088601112365723\n",
            "    Batch 20: combined loss = 3.380488872528076 , average loss: 0.845122218132019\n",
            "    Batch 30: combined loss = 3.4356400966644287 , average loss: 0.8589100241661072\n",
            "    Batch 40: combined loss = 4.417596340179443 , average loss: 1.1043990850448608\n",
            "    Batch 50: combined loss = 4.118122100830078 , average loss: 1.0295305252075195\n",
            "    Batch 60: combined loss = 4.098851680755615 , average loss: 1.0247129201889038\n",
            "    Batch 70: combined loss = 3.613701820373535 , average loss: 0.9034254550933838\n",
            "    Batch 80: combined loss = 1.9600720405578613 , average loss: 0.49001801013946533\n",
            "    Batch 90: combined loss = 2.518550395965576 , average loss: 0.629637598991394\n",
            "    Batch 100: combined loss = 2.4059650897979736 , average loss: 0.6014912724494934\n",
            "    Batch 110: combined loss = 5.593177318572998 , average loss: 1.3982943296432495\n",
            "    Batch 120: combined loss = 3.180609703063965 , average loss: 0.7951524257659912\n",
            "    Batch 130: combined loss = 3.902899742126465 , average loss: 0.9757249355316162\n",
            "    Batch 140: combined loss = 4.1647515296936035 , average loss: 1.0411878824234009\n",
            "    Batch 150: combined loss = 5.758150577545166 , average loss: 1.4395376443862915\n",
            "    Batch 160: combined loss = 6.1378068923950195 , average loss: 1.5344517230987549\n",
            "    Batch 170: combined loss = 3.4660449028015137 , average loss: 0.8665112257003784\n",
            "    Batch 180: combined loss = 5.267480850219727 , average loss: 1.3168702125549316\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 32\n",
            "Acc: 75.3478\n",
            "Edit: 68.8961\n",
            "F1@0.10: 8.4438\n",
            "F1@0.25: 7.1983\n",
            "F1@0.50: 4.9932\n",
            "EVALUATION AFTER EPOCH: 32\n",
            "Acc: 52.3793\n",
            "Edit: 5.5448\n",
            "F1@0.10: 4.1735\n",
            "F1@0.25: 3.1806\n",
            "F1@0.50: 2.0447\n",
            "RUNNING EPOCH: 33\n",
            "    Batch 0: combined loss = 3.3278214931488037 , average loss: 0.8319553732872009\n",
            "    Batch 10: combined loss = 2.7502403259277344 , average loss: 0.6875600814819336\n",
            "    Batch 20: combined loss = 4.194279193878174 , average loss: 1.0485697984695435\n",
            "    Batch 30: combined loss = 3.449770450592041 , average loss: 0.8624426126480103\n",
            "    Batch 40: combined loss = 4.056606292724609 , average loss: 1.0141515731811523\n",
            "    Batch 50: combined loss = 3.6119296550750732 , average loss: 0.9029824137687683\n",
            "    Batch 60: combined loss = 2.6771976947784424 , average loss: 0.6692994236946106\n",
            "    Batch 70: combined loss = 2.67006778717041 , average loss: 0.6675169467926025\n",
            "    Batch 80: combined loss = 2.2626826763153076 , average loss: 0.5656706690788269\n",
            "    Batch 90: combined loss = 2.631457567214966 , average loss: 0.6578643918037415\n",
            "    Batch 100: combined loss = 2.5644431114196777 , average loss: 0.6411107778549194\n",
            "    Batch 110: combined loss = 4.372509002685547 , average loss: 1.0931272506713867\n",
            "    Batch 120: combined loss = 2.8338284492492676 , average loss: 0.7084571123123169\n",
            "    Batch 130: combined loss = 4.2821221351623535 , average loss: 1.0705305337905884\n",
            "    Batch 140: combined loss = 2.3787200450897217 , average loss: 0.5946800112724304\n",
            "    Batch 150: combined loss = 4.862378120422363 , average loss: 1.2155945301055908\n",
            "    Batch 160: combined loss = 3.7346351146698 , average loss: 0.93365877866745\n",
            "    Batch 170: combined loss = 3.8906548023223877 , average loss: 0.9726637005805969\n",
            "    Batch 180: combined loss = 3.3714523315429688 , average loss: 0.8428630828857422\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 33\n",
            "Acc: 81.1284\n",
            "Edit: 71.1602\n",
            "F1@0.10: 9.6447\n",
            "F1@0.25: 8.4220\n",
            "F1@0.50: 6.1691\n",
            "EVALUATION AFTER EPOCH: 33\n",
            "Acc: 50.3833\n",
            "Edit: 6.2867\n",
            "F1@0.10: 4.2449\n",
            "F1@0.25: 3.3643\n",
            "F1@0.50: 1.9355\n",
            "RUNNING EPOCH: 34\n",
            "    Batch 0: combined loss = 3.4396724700927734 , average loss: 0.8599181175231934\n",
            "    Batch 10: combined loss = 4.217061519622803 , average loss: 1.0542653799057007\n",
            "    Batch 20: combined loss = 1.961879014968872 , average loss: 0.490469753742218\n",
            "    Batch 30: combined loss = 3.7589402198791504 , average loss: 0.9397350549697876\n",
            "    Batch 40: combined loss = 4.840170860290527 , average loss: 1.2100427150726318\n",
            "    Batch 50: combined loss = 4.0569562911987305 , average loss: 1.0142390727996826\n",
            "    Batch 60: combined loss = 3.9610040187835693 , average loss: 0.9902510046958923\n",
            "    Batch 70: combined loss = 4.325782299041748 , average loss: 1.081445574760437\n",
            "    Batch 80: combined loss = 2.3130297660827637 , average loss: 0.5782574415206909\n",
            "    Batch 90: combined loss = 3.5297775268554688 , average loss: 0.8824443817138672\n",
            "    Batch 100: combined loss = 3.7206647396087646 , average loss: 0.9301661849021912\n",
            "    Batch 110: combined loss = 2.5954861640930176 , average loss: 0.6488715410232544\n",
            "    Batch 120: combined loss = 3.2932066917419434 , average loss: 0.8233016729354858\n",
            "    Batch 130: combined loss = 3.756730794906616 , average loss: 0.939182698726654\n",
            "    Batch 140: combined loss = 2.3296523094177246 , average loss: 0.5824130773544312\n",
            "    Batch 150: combined loss = 3.243236780166626 , average loss: 0.8108091950416565\n",
            "    Batch 160: combined loss = 5.08509635925293 , average loss: 1.2712740898132324\n",
            "    Batch 170: combined loss = 2.9011390209198 , average loss: 0.72528475522995\n",
            "    Batch 180: combined loss = 3.3963584899902344 , average loss: 0.8490896224975586\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 34\n",
            "Acc: 75.5727\n",
            "Edit: 68.2884\n",
            "F1@0.10: 8.1397\n",
            "F1@0.25: 6.8325\n",
            "F1@0.50: 4.6721\n",
            "EVALUATION AFTER EPOCH: 34\n",
            "Acc: 50.0779\n",
            "Edit: 5.5590\n",
            "F1@0.10: 4.1807\n",
            "F1@0.25: 3.1355\n",
            "F1@0.50: 1.7111\n",
            "RUNNING EPOCH: 35\n",
            "    Batch 0: combined loss = 5.762851238250732 , average loss: 1.440712809562683\n",
            "    Batch 10: combined loss = 3.169921875 , average loss: 0.79248046875\n",
            "    Batch 20: combined loss = 5.11010217666626 , average loss: 1.277525544166565\n",
            "    Batch 30: combined loss = 4.504244804382324 , average loss: 1.126061201095581\n",
            "    Batch 40: combined loss = 5.022041320800781 , average loss: 1.2555103302001953\n",
            "    Batch 50: combined loss = 4.04885196685791 , average loss: 1.0122129917144775\n",
            "    Batch 60: combined loss = 3.310741424560547 , average loss: 0.8276853561401367\n",
            "    Batch 70: combined loss = 1.9319570064544678 , average loss: 0.48298925161361694\n",
            "    Batch 80: combined loss = 2.8920395374298096 , average loss: 0.7230098843574524\n",
            "    Batch 90: combined loss = 2.6584315299987793 , average loss: 0.6646078824996948\n",
            "    Batch 100: combined loss = 2.7614831924438477 , average loss: 0.6903707981109619\n",
            "    Batch 110: combined loss = 4.7963666915893555 , average loss: 1.1990916728973389\n",
            "    Batch 120: combined loss = 3.524705410003662 , average loss: 0.8811763525009155\n",
            "    Batch 130: combined loss = 4.355955600738525 , average loss: 1.0889889001846313\n",
            "    Batch 140: combined loss = 3.4739513397216797 , average loss: 0.8684878349304199\n",
            "    Batch 150: combined loss = 7.073825359344482 , average loss: 1.7684563398361206\n",
            "    Batch 160: combined loss = 3.9027810096740723 , average loss: 0.9756952524185181\n",
            "    Batch 170: combined loss = 2.4756040573120117 , average loss: 0.6189010143280029\n",
            "    Batch 180: combined loss = 3.84061861038208 , average loss: 0.96015465259552\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 35\n",
            "Acc: 75.9233\n",
            "Edit: 74.9340\n",
            "F1@0.10: 7.3954\n",
            "F1@0.25: 6.3102\n",
            "F1@0.50: 4.4441\n",
            "EVALUATION AFTER EPOCH: 35\n",
            "Acc: 45.8670\n",
            "Edit: 6.2376\n",
            "F1@0.10: 3.8332\n",
            "F1@0.25: 3.0291\n",
            "F1@0.50: 1.7019\n",
            "RUNNING EPOCH: 36\n",
            "    Batch 0: combined loss = 5.199704170227051 , average loss: 1.2999260425567627\n",
            "    Batch 10: combined loss = 3.8896987438201904 , average loss: 0.9724246859550476\n",
            "    Batch 20: combined loss = 3.3224024772644043 , average loss: 0.8306006193161011\n",
            "    Batch 30: combined loss = 2.3104238510131836 , average loss: 0.5776059627532959\n",
            "    Batch 40: combined loss = 3.9804041385650635 , average loss: 0.9951010346412659\n",
            "    Batch 50: combined loss = 3.4209017753601074 , average loss: 0.8552254438400269\n",
            "    Batch 60: combined loss = 3.442370653152466 , average loss: 0.8605926632881165\n",
            "    Batch 70: combined loss = 4.132475852966309 , average loss: 1.0331189632415771\n",
            "    Batch 80: combined loss = 3.061192512512207 , average loss: 0.7652981281280518\n",
            "    Batch 90: combined loss = 3.665599822998047 , average loss: 0.9163999557495117\n",
            "    Batch 100: combined loss = 2.1290411949157715 , average loss: 0.5322602987289429\n",
            "    Batch 110: combined loss = 2.6029584407806396 , average loss: 0.6507396101951599\n",
            "    Batch 120: combined loss = 6.905599117279053 , average loss: 1.7263997793197632\n",
            "    Batch 130: combined loss = 4.255491256713867 , average loss: 1.0638728141784668\n",
            "    Batch 140: combined loss = 4.144503593444824 , average loss: 1.036125898361206\n",
            "    Batch 150: combined loss = 3.591092109680176 , average loss: 0.897773027420044\n",
            "    Batch 160: combined loss = 2.5090837478637695 , average loss: 0.6272709369659424\n",
            "    Batch 170: combined loss = 3.326673984527588 , average loss: 0.831668496131897\n",
            "    Batch 180: combined loss = 3.838670015335083 , average loss: 0.9596675038337708\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 36\n",
            "Acc: 81.1020\n",
            "Edit: 75.7529\n",
            "F1@0.10: 8.8538\n",
            "F1@0.25: 7.7418\n",
            "F1@0.50: 5.6629\n",
            "EVALUATION AFTER EPOCH: 36\n",
            "Acc: 46.0917\n",
            "Edit: 6.1221\n",
            "F1@0.10: 4.1127\n",
            "F1@0.25: 3.3511\n",
            "F1@0.50: 1.9379\n",
            "RUNNING EPOCH: 37\n",
            "    Batch 0: combined loss = 2.9816770553588867 , average loss: 0.7454192638397217\n",
            "    Batch 10: combined loss = 2.5614991188049316 , average loss: 0.6403747797012329\n",
            "    Batch 20: combined loss = 2.865323066711426 , average loss: 0.7163307666778564\n",
            "    Batch 30: combined loss = 2.8190207481384277 , average loss: 0.7047551870346069\n",
            "    Batch 40: combined loss = 3.9685730934143066 , average loss: 0.9921432733535767\n",
            "    Batch 50: combined loss = 2.011969804763794 , average loss: 0.5029924511909485\n",
            "    Batch 60: combined loss = 5.526654243469238 , average loss: 1.3816635608673096\n",
            "    Batch 70: combined loss = 3.404290199279785 , average loss: 0.8510725498199463\n",
            "    Batch 80: combined loss = 2.4954628944396973 , average loss: 0.6238657236099243\n",
            "    Batch 90: combined loss = 3.089121103286743 , average loss: 0.7722802758216858\n",
            "    Batch 100: combined loss = 2.3513526916503906 , average loss: 0.5878381729125977\n",
            "    Batch 110: combined loss = 3.271827459335327 , average loss: 0.8179568648338318\n",
            "    Batch 120: combined loss = 6.220473289489746 , average loss: 1.5551183223724365\n",
            "    Batch 130: combined loss = 4.392870903015137 , average loss: 1.0982177257537842\n",
            "    Batch 140: combined loss = 3.1072981357574463 , average loss: 0.7768245339393616\n",
            "    Batch 150: combined loss = 4.184211254119873 , average loss: 1.0460528135299683\n",
            "    Batch 160: combined loss = 2.1315598487854004 , average loss: 0.5328899621963501\n",
            "    Batch 170: combined loss = 2.374551296234131 , average loss: 0.5936378240585327\n",
            "    Batch 180: combined loss = 5.370167255401611 , average loss: 1.3425418138504028\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 37\n",
            "Acc: 78.3633\n",
            "Edit: 60.2319\n",
            "F1@0.10: 7.8700\n",
            "F1@0.25: 6.6402\n",
            "F1@0.50: 4.7662\n",
            "EVALUATION AFTER EPOCH: 37\n",
            "Acc: 44.9021\n",
            "Edit: 6.0669\n",
            "F1@0.10: 3.4298\n",
            "F1@0.25: 2.7115\n",
            "F1@0.50: 1.6480\n",
            "RUNNING EPOCH: 38\n",
            "    Batch 0: combined loss = 3.0220541954040527 , average loss: 0.7555135488510132\n",
            "    Batch 10: combined loss = 2.1831226348876953 , average loss: 0.5457806587219238\n",
            "    Batch 20: combined loss = 3.083554744720459 , average loss: 0.7708886861801147\n",
            "    Batch 30: combined loss = 2.72025465965271 , average loss: 0.6800636649131775\n",
            "    Batch 40: combined loss = 2.9589147567749023 , average loss: 0.7397286891937256\n",
            "    Batch 50: combined loss = 2.7708888053894043 , average loss: 0.6927222013473511\n",
            "    Batch 60: combined loss = 3.5857694149017334 , average loss: 0.8964423537254333\n",
            "    Batch 70: combined loss = 3.024153709411621 , average loss: 0.7560384273529053\n",
            "    Batch 80: combined loss = 5.307690620422363 , average loss: 1.3269226551055908\n",
            "    Batch 90: combined loss = 2.801788806915283 , average loss: 0.7004472017288208\n",
            "    Batch 100: combined loss = 4.2619218826293945 , average loss: 1.0654804706573486\n",
            "    Batch 110: combined loss = 2.7845163345336914 , average loss: 0.6961290836334229\n",
            "    Batch 120: combined loss = 3.1411261558532715 , average loss: 0.7852815389633179\n",
            "    Batch 130: combined loss = 2.5035102367401123 , average loss: 0.6258775591850281\n",
            "    Batch 140: combined loss = 3.040938377380371 , average loss: 0.7602345943450928\n",
            "    Batch 150: combined loss = 2.5449814796447754 , average loss: 0.6362453699111938\n",
            "    Batch 160: combined loss = 4.823141574859619 , average loss: 1.2057853937149048\n",
            "    Batch 170: combined loss = 3.0894789695739746 , average loss: 0.7723697423934937\n",
            "    Batch 180: combined loss = 3.710498809814453 , average loss: 0.9276247024536133\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 38\n",
            "Acc: 81.1442\n",
            "Edit: 65.0030\n",
            "F1@0.10: 8.9623\n",
            "F1@0.25: 7.7544\n",
            "F1@0.50: 5.4078\n",
            "EVALUATION AFTER EPOCH: 38\n",
            "Acc: 47.3525\n",
            "Edit: 4.6635\n",
            "F1@0.10: 3.6489\n",
            "F1@0.25: 2.6147\n",
            "F1@0.50: 1.4130\n",
            "RUNNING EPOCH: 39\n",
            "    Batch 0: combined loss = 2.8730852603912354 , average loss: 0.7182713150978088\n",
            "    Batch 10: combined loss = 4.128690242767334 , average loss: 1.0321725606918335\n",
            "    Batch 20: combined loss = 1.6559529304504395 , average loss: 0.41398823261260986\n",
            "    Batch 30: combined loss = 3.8870227336883545 , average loss: 0.9717556834220886\n",
            "    Batch 40: combined loss = 2.644627809524536 , average loss: 0.661156952381134\n",
            "    Batch 50: combined loss = 3.9648211002349854 , average loss: 0.9912052750587463\n",
            "    Batch 60: combined loss = 4.01564884185791 , average loss: 1.0039122104644775\n",
            "    Batch 70: combined loss = 3.273207426071167 , average loss: 0.8183018565177917\n",
            "    Batch 80: combined loss = 3.0565185546875 , average loss: 0.764129638671875\n",
            "    Batch 90: combined loss = 3.3879363536834717 , average loss: 0.8469840884208679\n",
            "    Batch 100: combined loss = 2.6743719577789307 , average loss: 0.6685929894447327\n",
            "    Batch 110: combined loss = 3.6371688842773438 , average loss: 0.9092922210693359\n",
            "    Batch 120: combined loss = 1.5335453748703003 , average loss: 0.3833863437175751\n",
            "    Batch 130: combined loss = 3.972548007965088 , average loss: 0.993137001991272\n",
            "    Batch 140: combined loss = 2.1207375526428223 , average loss: 0.5301843881607056\n",
            "    Batch 150: combined loss = 4.339892387390137 , average loss: 1.0849730968475342\n",
            "    Batch 160: combined loss = 4.000643730163574 , average loss: 1.0001609325408936\n",
            "    Batch 170: combined loss = 6.693746566772461 , average loss: 1.6734366416931152\n",
            "    Batch 180: combined loss = 4.997504234313965 , average loss: 1.2493760585784912\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 39\n",
            "Acc: 81.7587\n",
            "Edit: 69.4079\n",
            "F1@0.10: 8.6103\n",
            "F1@0.25: 7.4498\n",
            "F1@0.50: 5.3932\n",
            "EVALUATION AFTER EPOCH: 39\n",
            "Acc: 44.3915\n",
            "Edit: 5.0126\n",
            "F1@0.10: 3.5319\n",
            "F1@0.25: 2.8398\n",
            "F1@0.50: 1.6910\n",
            "RUNNING EPOCH: 40\n",
            "    Batch 0: combined loss = 2.103292465209961 , average loss: 0.5258231163024902\n",
            "    Batch 10: combined loss = 3.1408002376556396 , average loss: 0.7852000594139099\n",
            "    Batch 20: combined loss = 2.8858489990234375 , average loss: 0.7214622497558594\n",
            "    Batch 30: combined loss = 4.657466888427734 , average loss: 1.1643667221069336\n",
            "    Batch 40: combined loss = 2.8117311000823975 , average loss: 0.7029327750205994\n",
            "    Batch 50: combined loss = 1.8823778629302979 , average loss: 0.47059446573257446\n",
            "    Batch 60: combined loss = 4.042074680328369 , average loss: 1.0105186700820923\n",
            "    Batch 70: combined loss = 3.2461485862731934 , average loss: 0.8115371465682983\n",
            "    Batch 80: combined loss = 2.214874744415283 , average loss: 0.5537186861038208\n",
            "    Batch 90: combined loss = 4.260153770446777 , average loss: 1.0650384426116943\n",
            "    Batch 100: combined loss = 3.6510674953460693 , average loss: 0.9127668738365173\n",
            "    Batch 110: combined loss = 2.5906167030334473 , average loss: 0.6476541757583618\n",
            "    Batch 120: combined loss = 2.972245216369629 , average loss: 0.7430613040924072\n",
            "    Batch 130: combined loss = 3.5742909908294678 , average loss: 0.8935727477073669\n",
            "    Batch 140: combined loss = 3.080963373184204 , average loss: 0.770240843296051\n",
            "    Batch 150: combined loss = 3.3515546321868896 , average loss: 0.8378886580467224\n",
            "    Batch 160: combined loss = 2.615969181060791 , average loss: 0.6539922952651978\n",
            "    Batch 170: combined loss = 2.9545676708221436 , average loss: 0.7386419177055359\n",
            "    Batch 180: combined loss = 2.825485944747925 , average loss: 0.7063714861869812\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 40\n",
            "Acc: 83.3922\n",
            "Edit: 78.8135\n",
            "F1@0.10: 9.7404\n",
            "F1@0.25: 8.6522\n",
            "F1@0.50: 6.4220\n",
            "EVALUATION AFTER EPOCH: 40\n",
            "Acc: 45.2990\n",
            "Edit: 6.0200\n",
            "F1@0.10: 3.8248\n",
            "F1@0.25: 3.0223\n",
            "F1@0.50: 1.7399\n",
            "RUNNING EPOCH: 41\n",
            "    Batch 0: combined loss = 3.0187299251556396 , average loss: 0.7546824812889099\n",
            "    Batch 10: combined loss = 3.774698257446289 , average loss: 0.9436745643615723\n",
            "    Batch 20: combined loss = 2.0485968589782715 , average loss: 0.5121492147445679\n",
            "    Batch 30: combined loss = 3.9564270973205566 , average loss: 0.9891067743301392\n",
            "    Batch 40: combined loss = 3.218613862991333 , average loss: 0.8046534657478333\n",
            "    Batch 50: combined loss = 3.7498011589050293 , average loss: 0.9374502897262573\n",
            "    Batch 60: combined loss = 2.445366144180298 , average loss: 0.6113415360450745\n",
            "    Batch 70: combined loss = 3.119858741760254 , average loss: 0.7799646854400635\n",
            "    Batch 80: combined loss = 1.9620245695114136 , average loss: 0.4905061423778534\n",
            "    Batch 90: combined loss = 2.9856395721435547 , average loss: 0.7464098930358887\n",
            "    Batch 100: combined loss = 2.6994166374206543 , average loss: 0.6748541593551636\n",
            "    Batch 110: combined loss = 4.532975196838379 , average loss: 1.1332437992095947\n",
            "    Batch 120: combined loss = 3.1356308460235596 , average loss: 0.7839077115058899\n",
            "    Batch 130: combined loss = 3.5638933181762695 , average loss: 0.8909733295440674\n",
            "    Batch 140: combined loss = 2.637939691543579 , average loss: 0.6594849228858948\n",
            "    Batch 150: combined loss = 2.5289101600646973 , average loss: 0.6322275400161743\n",
            "    Batch 160: combined loss = 3.281363010406494 , average loss: 0.8203407526016235\n",
            "    Batch 170: combined loss = 3.8018531799316406 , average loss: 0.9504632949829102\n",
            "    Batch 180: combined loss = 3.915886878967285 , average loss: 0.9789717197418213\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 41\n",
            "Acc: 81.8325\n",
            "Edit: 69.4611\n",
            "F1@0.10: 9.4937\n",
            "F1@0.25: 8.3486\n",
            "F1@0.50: 6.0228\n",
            "EVALUATION AFTER EPOCH: 41\n",
            "Acc: 51.6644\n",
            "Edit: 4.9001\n",
            "F1@0.10: 4.0335\n",
            "F1@0.25: 3.1463\n",
            "F1@0.50: 1.9141\n",
            "RUNNING EPOCH: 42\n",
            "    Batch 0: combined loss = 3.1212689876556396 , average loss: 0.7803172469139099\n",
            "    Batch 10: combined loss = 2.414295196533203 , average loss: 0.6035737991333008\n",
            "    Batch 20: combined loss = 1.6919283866882324 , average loss: 0.4229820966720581\n",
            "    Batch 30: combined loss = 2.6077356338500977 , average loss: 0.6519339084625244\n",
            "    Batch 40: combined loss = 1.9581571817398071 , average loss: 0.4895392954349518\n",
            "    Batch 50: combined loss = 3.016667366027832 , average loss: 0.754166841506958\n",
            "    Batch 60: combined loss = 5.10422945022583 , average loss: 1.2760573625564575\n",
            "    Batch 70: combined loss = 3.5120394229888916 , average loss: 0.8780098557472229\n",
            "    Batch 80: combined loss = 3.9085566997528076 , average loss: 0.9771391749382019\n",
            "    Batch 90: combined loss = 2.979113817214966 , average loss: 0.7447784543037415\n",
            "    Batch 100: combined loss = 3.1432948112487793 , average loss: 0.7858237028121948\n",
            "    Batch 110: combined loss = 2.580556869506836 , average loss: 0.645139217376709\n",
            "    Batch 120: combined loss = 3.4389421939849854 , average loss: 0.8597355484962463\n",
            "    Batch 130: combined loss = 3.337167978286743 , average loss: 0.8342919945716858\n",
            "    Batch 140: combined loss = 2.3866989612579346 , average loss: 0.5966747403144836\n",
            "    Batch 150: combined loss = 4.119884490966797 , average loss: 1.0299711227416992\n",
            "    Batch 160: combined loss = 2.5942015647888184 , average loss: 0.6485503911972046\n",
            "    Batch 170: combined loss = 1.610670566558838 , average loss: 0.4026676416397095\n",
            "    Batch 180: combined loss = 1.9443528652191162 , average loss: 0.48608821630477905\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 42\n",
            "Acc: 84.0805\n",
            "Edit: 72.6329\n",
            "F1@0.10: 10.3568\n",
            "F1@0.25: 9.2089\n",
            "F1@0.50: 6.7824\n",
            "EVALUATION AFTER EPOCH: 42\n",
            "Acc: 47.5229\n",
            "Edit: 5.0753\n",
            "F1@0.10: 3.7402\n",
            "F1@0.25: 2.9785\n",
            "F1@0.50: 1.8173\n",
            "RUNNING EPOCH: 43\n",
            "    Batch 0: combined loss = 2.9363198280334473 , average loss: 0.7340799570083618\n",
            "    Batch 10: combined loss = 2.3561105728149414 , average loss: 0.5890276432037354\n",
            "    Batch 20: combined loss = 3.2947654724121094 , average loss: 0.8236913681030273\n",
            "    Batch 30: combined loss = 2.9219000339508057 , average loss: 0.7304750084877014\n",
            "    Batch 40: combined loss = 3.490222692489624 , average loss: 0.872555673122406\n",
            "    Batch 50: combined loss = 2.1562373638153076 , average loss: 0.5390593409538269\n",
            "    Batch 60: combined loss = 2.408722162246704 , average loss: 0.602180540561676\n",
            "    Batch 70: combined loss = 3.8645436763763428 , average loss: 0.9661359190940857\n",
            "    Batch 80: combined loss = 3.03194260597229 , average loss: 0.7579856514930725\n",
            "    Batch 90: combined loss = 1.952122449874878 , average loss: 0.4880306124687195\n",
            "    Batch 100: combined loss = 1.89034104347229 , average loss: 0.4725852608680725\n",
            "    Batch 110: combined loss = 2.8728597164154053 , average loss: 0.7182149291038513\n",
            "    Batch 120: combined loss = 3.0004632472991943 , average loss: 0.7501158118247986\n",
            "    Batch 130: combined loss = 5.21213436126709 , average loss: 1.3030335903167725\n",
            "    Batch 140: combined loss = 2.6492156982421875 , average loss: 0.6623039245605469\n",
            "    Batch 150: combined loss = 1.8934910297393799 , average loss: 0.47337275743484497\n",
            "    Batch 160: combined loss = 1.3965308666229248 , average loss: 0.3491327166557312\n",
            "    Batch 170: combined loss = 2.118112087249756 , average loss: 0.529528021812439\n",
            "    Batch 180: combined loss = 1.799281120300293 , average loss: 0.44982028007507324\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 43\n",
            "Acc: 85.6067\n",
            "Edit: 106.9063\n",
            "F1@0.10: 11.8557\n",
            "F1@0.25: 10.7852\n",
            "F1@0.50: 8.4197\n",
            "EVALUATION AFTER EPOCH: 43\n",
            "Acc: 49.4065\n",
            "Edit: 7.2179\n",
            "F1@0.10: 4.7329\n",
            "F1@0.25: 3.6505\n",
            "F1@0.50: 2.1738\n",
            "RUNNING EPOCH: 44\n",
            "    Batch 0: combined loss = 2.6348438262939453 , average loss: 0.6587109565734863\n",
            "    Batch 10: combined loss = 2.223515748977661 , average loss: 0.5558789372444153\n",
            "    Batch 20: combined loss = 1.250051498413086 , average loss: 0.3125128746032715\n",
            "    Batch 30: combined loss = 1.8271160125732422 , average loss: 0.45677900314331055\n",
            "    Batch 40: combined loss = 2.8055689334869385 , average loss: 0.7013922333717346\n",
            "    Batch 50: combined loss = 1.6460918188095093 , average loss: 0.4115229547023773\n",
            "    Batch 60: combined loss = 1.997907042503357 , average loss: 0.49947676062583923\n",
            "    Batch 70: combined loss = 2.51869535446167 , average loss: 0.6296738386154175\n",
            "    Batch 80: combined loss = 1.9195913076400757 , average loss: 0.4798978269100189\n",
            "    Batch 90: combined loss = 1.6548185348510742 , average loss: 0.41370463371276855\n",
            "    Batch 100: combined loss = 1.87886643409729 , average loss: 0.4697166085243225\n",
            "    Batch 110: combined loss = 2.374277353286743 , average loss: 0.5935693383216858\n",
            "    Batch 120: combined loss = 2.104684829711914 , average loss: 0.5261712074279785\n",
            "    Batch 130: combined loss = 1.7560038566589355 , average loss: 0.4390009641647339\n",
            "    Batch 140: combined loss = 3.0038676261901855 , average loss: 0.7509669065475464\n",
            "    Batch 150: combined loss = 2.36521053314209 , average loss: 0.5913026332855225\n",
            "    Batch 160: combined loss = 3.405851125717163 , average loss: 0.8514627814292908\n",
            "    Batch 170: combined loss = 2.6311521530151367 , average loss: 0.6577880382537842\n",
            "    Batch 180: combined loss = 2.9532108306884766 , average loss: 0.7383027076721191\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 44\n",
            "Acc: 84.4771\n",
            "Edit: 91.0022\n",
            "F1@0.10: 12.6382\n",
            "F1@0.25: 11.4848\n",
            "F1@0.50: 8.8581\n",
            "EVALUATION AFTER EPOCH: 44\n",
            "Acc: 53.3796\n",
            "Edit: 6.5347\n",
            "F1@0.10: 4.5692\n",
            "F1@0.25: 3.8169\n",
            "F1@0.50: 2.3213\n",
            "RUNNING EPOCH: 45\n",
            "    Batch 0: combined loss = 1.5409479141235352 , average loss: 0.3852369785308838\n",
            "    Batch 10: combined loss = 3.848966598510742 , average loss: 0.9622416496276855\n",
            "    Batch 20: combined loss = 2.5289742946624756 , average loss: 0.6322435736656189\n",
            "    Batch 30: combined loss = 3.608912944793701 , average loss: 0.9022282361984253\n",
            "    Batch 40: combined loss = 2.6980130672454834 , average loss: 0.6745032668113708\n",
            "    Batch 50: combined loss = 2.4724762439727783 , average loss: 0.6181190609931946\n",
            "    Batch 60: combined loss = 2.150733232498169 , average loss: 0.5376833081245422\n",
            "    Batch 70: combined loss = 1.8471758365631104 , average loss: 0.4617939591407776\n",
            "    Batch 80: combined loss = 3.243318557739258 , average loss: 0.8108296394348145\n",
            "    Batch 90: combined loss = 2.443220853805542 , average loss: 0.6108052134513855\n",
            "    Batch 100: combined loss = 3.7621593475341797 , average loss: 0.9405398368835449\n",
            "    Batch 110: combined loss = 2.53513503074646 , average loss: 0.633783757686615\n",
            "    Batch 120: combined loss = 2.9466817378997803 , average loss: 0.7366704344749451\n",
            "    Batch 130: combined loss = 2.6797192096710205 , average loss: 0.6699298024177551\n",
            "    Batch 140: combined loss = 2.5969078540802 , average loss: 0.64922696352005\n",
            "    Batch 150: combined loss = 3.6390233039855957 , average loss: 0.9097558259963989\n",
            "    Batch 160: combined loss = 4.136617183685303 , average loss: 1.0341542959213257\n",
            "    Batch 170: combined loss = 2.7124292850494385 , average loss: 0.6781073212623596\n",
            "    Batch 180: combined loss = 2.491783618927002 , average loss: 0.6229459047317505\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 45\n",
            "Acc: 80.4867\n",
            "Edit: 67.4466\n",
            "F1@0.10: 9.1817\n",
            "F1@0.25: 7.9341\n",
            "F1@0.50: 5.6234\n",
            "EVALUATION AFTER EPOCH: 45\n",
            "Acc: 43.5969\n",
            "Edit: 5.8387\n",
            "F1@0.10: 3.5911\n",
            "F1@0.25: 2.6843\n",
            "F1@0.50: 1.4177\n",
            "RUNNING EPOCH: 46\n",
            "    Batch 0: combined loss = 8.06268310546875 , average loss: 2.0156707763671875\n",
            "    Batch 10: combined loss = 2.6821224689483643 , average loss: 0.6705306172370911\n",
            "    Batch 20: combined loss = 4.096926689147949 , average loss: 1.0242316722869873\n",
            "    Batch 30: combined loss = 1.6427719593048096 , average loss: 0.4106929898262024\n",
            "    Batch 40: combined loss = 4.424775123596191 , average loss: 1.1061937808990479\n",
            "    Batch 50: combined loss = 2.55670428276062 , average loss: 0.639176070690155\n",
            "    Batch 60: combined loss = 1.3804426193237305 , average loss: 0.3451106548309326\n",
            "    Batch 70: combined loss = 3.463456630706787 , average loss: 0.8658641576766968\n",
            "    Batch 80: combined loss = 2.893266201019287 , average loss: 0.7233165502548218\n",
            "    Batch 90: combined loss = 4.144256591796875 , average loss: 1.0360641479492188\n",
            "    Batch 100: combined loss = 3.1580300331115723 , average loss: 0.7895075082778931\n",
            "    Batch 110: combined loss = 2.8557534217834473 , average loss: 0.7139383554458618\n",
            "    Batch 120: combined loss = 2.3908135890960693 , average loss: 0.5977033972740173\n",
            "    Batch 130: combined loss = 1.9950159788131714 , average loss: 0.49875399470329285\n",
            "    Batch 140: combined loss = 4.926504135131836 , average loss: 1.231626033782959\n",
            "    Batch 150: combined loss = 2.167210340499878 , average loss: 0.5418025851249695\n",
            "    Batch 160: combined loss = 3.416445732116699 , average loss: 0.8541114330291748\n",
            "    Batch 170: combined loss = 3.132412910461426 , average loss: 0.7831032276153564\n",
            "    Batch 180: combined loss = 3.8673884868621826 , average loss: 0.9668471217155457\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 46\n",
            "Acc: 81.8673\n",
            "Edit: 70.7771\n",
            "F1@0.10: 9.5968\n",
            "F1@0.25: 8.3266\n",
            "F1@0.50: 6.0383\n",
            "EVALUATION AFTER EPOCH: 46\n",
            "Acc: 49.3685\n",
            "Edit: 7.2030\n",
            "F1@0.10: 3.9743\n",
            "F1@0.25: 3.1972\n",
            "F1@0.50: 1.8698\n",
            "RUNNING EPOCH: 47\n",
            "    Batch 0: combined loss = 4.276909351348877 , average loss: 1.0692273378372192\n",
            "    Batch 10: combined loss = 5.219706058502197 , average loss: 1.3049265146255493\n",
            "    Batch 20: combined loss = 3.4700965881347656 , average loss: 0.8675241470336914\n",
            "    Batch 30: combined loss = 3.8655593395233154 , average loss: 0.9663898348808289\n",
            "    Batch 40: combined loss = 2.207568883895874 , average loss: 0.5518922209739685\n",
            "    Batch 50: combined loss = 3.368894100189209 , average loss: 0.8422235250473022\n",
            "    Batch 60: combined loss = 3.188795328140259 , average loss: 0.7971988320350647\n",
            "    Batch 70: combined loss = 2.959341287612915 , average loss: 0.7398353219032288\n",
            "    Batch 80: combined loss = 4.06248140335083 , average loss: 1.0156203508377075\n",
            "    Batch 90: combined loss = 3.7731809616088867 , average loss: 0.9432952404022217\n",
            "    Batch 100: combined loss = 2.260331153869629 , average loss: 0.5650827884674072\n",
            "    Batch 110: combined loss = 2.8214924335479736 , average loss: 0.7053731083869934\n",
            "    Batch 120: combined loss = 1.639600396156311 , average loss: 0.40990009903907776\n",
            "    Batch 130: combined loss = 3.57908296585083 , average loss: 0.8947707414627075\n",
            "    Batch 140: combined loss = 3.05905818939209 , average loss: 0.7647645473480225\n",
            "    Batch 150: combined loss = 2.9858055114746094 , average loss: 0.7464513778686523\n",
            "    Batch 160: combined loss = 3.668687105178833 , average loss: 0.9171717762947083\n",
            "    Batch 170: combined loss = 3.0969696044921875 , average loss: 0.7742424011230469\n",
            "    Batch 180: combined loss = 4.077242851257324 , average loss: 1.019310712814331\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 47\n",
            "Acc: 87.0719\n",
            "Edit: 99.6310\n",
            "F1@0.10: 12.6349\n",
            "F1@0.25: 11.5501\n",
            "F1@0.50: 9.0428\n",
            "EVALUATION AFTER EPOCH: 47\n",
            "Acc: 51.8207\n",
            "Edit: 6.0144\n",
            "F1@0.10: 4.1475\n",
            "F1@0.25: 3.3212\n",
            "F1@0.50: 1.9307\n",
            "RUNNING EPOCH: 48\n",
            "    Batch 0: combined loss = 2.0027737617492676 , average loss: 0.5006934404373169\n",
            "    Batch 10: combined loss = 1.9727215766906738 , average loss: 0.49318039417266846\n",
            "    Batch 20: combined loss = 2.723076343536377 , average loss: 0.6807690858840942\n",
            "    Batch 30: combined loss = 1.3999744653701782 , average loss: 0.34999361634254456\n",
            "    Batch 40: combined loss = 2.7808926105499268 , average loss: 0.6952231526374817\n",
            "    Batch 50: combined loss = 2.963658332824707 , average loss: 0.7409145832061768\n",
            "    Batch 60: combined loss = 2.0942471027374268 , average loss: 0.5235617756843567\n",
            "    Batch 70: combined loss = 4.208315849304199 , average loss: 1.0520789623260498\n",
            "    Batch 80: combined loss = 2.7581467628479004 , average loss: 0.6895366907119751\n",
            "    Batch 90: combined loss = 3.039914608001709 , average loss: 0.7599786520004272\n",
            "    Batch 100: combined loss = 2.4162065982818604 , average loss: 0.6040516495704651\n",
            "    Batch 110: combined loss = 1.4575821161270142 , average loss: 0.36439552903175354\n",
            "    Batch 120: combined loss = 2.7656915187835693 , average loss: 0.6914228796958923\n",
            "    Batch 130: combined loss = 2.9575746059417725 , average loss: 0.7393936514854431\n",
            "    Batch 140: combined loss = 2.310253381729126 , average loss: 0.5775633454322815\n",
            "    Batch 150: combined loss = 2.540527582168579 , average loss: 0.6351318955421448\n",
            "    Batch 160: combined loss = 3.2898950576782227 , average loss: 0.8224737644195557\n",
            "    Batch 170: combined loss = 3.143808364868164 , average loss: 0.785952091217041\n",
            "    Batch 180: combined loss = 3.097665548324585 , average loss: 0.7744163870811462\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 48\n",
            "Acc: 86.2562\n",
            "Edit: 101.9884\n",
            "F1@0.10: 12.1765\n",
            "F1@0.25: 11.1563\n",
            "F1@0.50: 8.8651\n",
            "EVALUATION AFTER EPOCH: 48\n",
            "Acc: 53.6324\n",
            "Edit: 6.0432\n",
            "F1@0.10: 4.6145\n",
            "F1@0.25: 3.7471\n",
            "F1@0.50: 2.2639\n",
            "RUNNING EPOCH: 49\n",
            "    Batch 0: combined loss = 1.555770754814148 , average loss: 0.388942688703537\n",
            "    Batch 10: combined loss = 4.1177263259887695 , average loss: 1.0294315814971924\n",
            "    Batch 20: combined loss = 2.215939998626709 , average loss: 0.5539849996566772\n",
            "    Batch 30: combined loss = 1.9855587482452393 , average loss: 0.4963896870613098\n",
            "    Batch 40: combined loss = 2.049903392791748 , average loss: 0.512475848197937\n",
            "    Batch 50: combined loss = 1.8440507650375366 , average loss: 0.46101269125938416\n",
            "    Batch 60: combined loss = 1.7240664958953857 , average loss: 0.43101662397384644\n",
            "    Batch 70: combined loss = 1.4626481533050537 , average loss: 0.3656620383262634\n",
            "    Batch 80: combined loss = 1.5002975463867188 , average loss: 0.3750743865966797\n",
            "    Batch 90: combined loss = 3.707083225250244 , average loss: 0.926770806312561\n",
            "    Batch 100: combined loss = 1.2665553092956543 , average loss: 0.3166388273239136\n",
            "    Batch 110: combined loss = 2.573197364807129 , average loss: 0.6432993412017822\n",
            "    Batch 120: combined loss = 2.288447141647339 , average loss: 0.5721117854118347\n",
            "    Batch 130: combined loss = 2.6547443866729736 , average loss: 0.6636860966682434\n",
            "    Batch 140: combined loss = 3.5508780479431152 , average loss: 0.8877195119857788\n",
            "    Batch 150: combined loss = 2.9889814853668213 , average loss: 0.7472453713417053\n",
            "    Batch 160: combined loss = 5.105803489685059 , average loss: 1.2764508724212646\n",
            "    Batch 170: combined loss = 2.267883539199829 , average loss: 0.5669708847999573\n",
            "    Batch 180: combined loss = 2.040783166885376 , average loss: 0.510195791721344\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 49\n",
            "Acc: 85.0545\n",
            "Edit: 118.2179\n",
            "F1@0.10: 11.4482\n",
            "F1@0.25: 10.5550\n",
            "F1@0.50: 8.5537\n",
            "EVALUATION AFTER EPOCH: 49\n",
            "Acc: 49.4156\n",
            "Edit: 6.9475\n",
            "F1@0.10: 4.7735\n",
            "F1@0.25: 3.8756\n",
            "F1@0.50: 2.4646\n",
            "RUNNING EPOCH: 50\n",
            "    Batch 0: combined loss = 2.6262378692626953 , average loss: 0.6565594673156738\n",
            "    Batch 10: combined loss = 1.95358407497406 , average loss: 0.488396018743515\n",
            "    Batch 20: combined loss = 1.914829969406128 , average loss: 0.478707492351532\n",
            "    Batch 30: combined loss = 1.9500609636306763 , average loss: 0.48751524090766907\n",
            "    Batch 40: combined loss = 1.923591136932373 , average loss: 0.48089778423309326\n",
            "    Batch 50: combined loss = 2.8967251777648926 , average loss: 0.7241812944412231\n",
            "    Batch 60: combined loss = 2.4370815753936768 , average loss: 0.6092703938484192\n",
            "    Batch 70: combined loss = 1.6546802520751953 , average loss: 0.41367006301879883\n",
            "    Batch 80: combined loss = 1.5187640190124512 , average loss: 0.3796910047531128\n",
            "    Batch 90: combined loss = 2.636871337890625 , average loss: 0.6592178344726562\n",
            "    Batch 100: combined loss = 2.4883995056152344 , average loss: 0.6220998764038086\n",
            "    Batch 110: combined loss = 2.6871275901794434 , average loss: 0.6717818975448608\n",
            "    Batch 120: combined loss = 2.3805837631225586 , average loss: 0.5951459407806396\n",
            "    Batch 130: combined loss = 2.642644166946411 , average loss: 0.6606610417366028\n",
            "    Batch 140: combined loss = 2.2349014282226562 , average loss: 0.5587253570556641\n",
            "    Batch 150: combined loss = 2.599273681640625 , average loss: 0.6498184204101562\n",
            "    Batch 160: combined loss = 3.292510986328125 , average loss: 0.8231277465820312\n",
            "    Batch 170: combined loss = 1.530015468597412 , average loss: 0.382503867149353\n",
            "    Batch 180: combined loss = 2.6558618545532227 , average loss: 0.6639654636383057\n",
            "ACCURACY ON TRAINING AFTER EPOCH: 50\n",
            "Acc: 71.9759\n",
            "Edit: 78.0401\n",
            "F1@0.10: 6.6124\n",
            "F1@0.25: 5.7824\n",
            "F1@0.50: 4.3523\n",
            "EVALUATION AFTER EPOCH: 50\n",
            "Acc: 31.5206\n",
            "Edit: 5.2022\n",
            "F1@0.10: 3.2208\n",
            "F1@0.25: 2.5824\n",
            "F1@0.50: 1.5814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f169920d"
      },
      "source": [
        "torch.save(parallel_TCNs, \"./parallel_tcn\")"
      ],
      "id": "f169920d",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dslDrLbzmTGD"
      },
      "source": [
        "# conclusion for this sheet\n",
        "\n",
        "The model is clearly able to learn something about the classes in the video, as a performance reaching 50% exceeds by far an expected random guess accuracy of 2% for 48 classes. However, we are unable to match the results in the paper.\n",
        "\n",
        "Some factors that can contribute to this:\n",
        "- Possible differences in the dataset. The model is deep and has a large capacity. It has large data needs.\n",
        "- The huge difference in the dilation factor between what used in the paper (exponential) and here (linear). 10 is much smaller that 2^10, which means the perceptive field of the later layer is much smaller.\n",
        "- Not using smoothing loss to avoid oversegmentation.\n",
        "- Overfitting: The accuracy on the training set grows disproportionately to the accuracy on the testing set (nearing a 35% difference in some iterations, like epochs 29 and 36). This also can be a good argument for needing more data, and for  investigating  proper regulerization techniques. \n",
        "\n"
      ],
      "id": "dslDrLbzmTGD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSSB9W4zp086"
      },
      "source": [
        ""
      ],
      "id": "xSSB9W4zp086",
      "execution_count": null,
      "outputs": []
    }
  ]
}